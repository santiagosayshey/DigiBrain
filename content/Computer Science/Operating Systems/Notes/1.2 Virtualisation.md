> [!motivation] The Need for Process Abstraction
> Early computer systems could only **run one program at a time**, leading to inefficient use of resources. As computing needs grew, several challenges emerged:
> 
> - Running **multiple** programs simultaneously
> - Efficiently **sharing** limited system resources
> - Protecting **programs** from interfering with each other
> - Maximizing CPU utilization
> 
> These challenges drove the development of more sophisticated ways to manage program execution, laying the groundwork for modern **process management** in operating systems.

> [!idea] Process
> A process is **a program in execution**, encompassing:
> 
> - **Execution Stream**: The sequence of instructions being executed
> - **Process State**: The current status of the process, including:
>   - Program Counter (PC): Points to the next instruction to execute
>   - Register values: Holds intermediate computation results
>   - Memory allocation: Stack and heap for program data
>   - I/O status information: Open files, network connections
> 
> Process Lifecycle:
> - New: Process is being created
> - Ready: Waiting to be assigned to a processor
> - Running: Instructions are being executed
> - Waiting: Process is waiting for some event to occur
> - Terminated: Process has finished execution
> 
> Visualize: In our traffic control analogy, a process is like a train on the railway system:
> - The train represents the program in execution
> - Its current position on the track is the Program Counter
> - The cargo it carries represents the data in memory
> - Stations along the route represent different states in the process lifecycle
> - The traffic controller (OS) manages multiple trains, ensuring they all progress efficiently without colliding
> 
> The operating system, like a skilled traffic controller, manages these processes, switching between them to create the illusion of concurrent movement on a limited track system.

