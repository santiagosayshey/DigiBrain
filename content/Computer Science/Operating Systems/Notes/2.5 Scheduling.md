
> [!idea] Scheduling: Deciding Which Process Runs Next
> Scheduling is the **strategy used to determine which process should be dispatched to run next**. It involves:
> 
> - Maintaining a **queue of ready-to-run processes**
> - **Selecting the next process** based on a scheduling algorithm
> - **Balancing system objectives** (e.g., fairness, throughput, response time, turnaround time, waiting time, utilisation, overhead)
> 
> Key concepts:
> 1. **Scheduling Algorithms**: Methods for selecting the next process (e.g., Round Robin, Priority Scheduling)
> 2. **Preemption**: Ability to interrupt a running process to schedule another
> 
> Scheduling aims to **optimize system performance and ensure fair allocation** of CPU time among processes.

> [!example] General Scheduling
> Consider three processes: A, B, and C, with a Round Robin scheduler
> 
> 1. Scheduler **starts with A**, gives it a time slice
> 2. After time slice expires, **A is preempted, B is scheduled**
> 3. B runs for its time slice, then **C is scheduled**
> 4. After C's time slice, the **cycle repeats with A**
> 
> This ensures each process gets regular CPU time, preventing any single process from monopolizing the processor.

> [!idea] State Transitions in Process Scheduling
> State transitions refer to the changes in the status of a process as it moves through different stages of its lifecycle. This includes:
> 
> - **Ready State**: Process is ready to run but waiting for CPU time
> - **Running State**: Process is currently being executed by the CPU
> - **Blocked State**: Process is waiting for an event (e.g., I/O completion)
> - **Terminated State**: Process has finished execution
> 
> These transitions are crucial for efficient process management and scheduling.

> [!idea] Key Scheduling Concepts
> 
> 1. **Workload**: The set of processes that need to be scheduled
> 2. **Job**: A single unit of work that needs to be processed
> 3. **Scheduler**: The algorithm or mechanism that decides which job runs next
> 4. **Metric**: Criteria used to evaluate the performance of the scheduling algorithm (e.g., turnaround time, response time, waiting time)
>
> - **Turnaround Time**: Time from job submission to job completion
> - **Response Time**: Time from job submission to first response
> - **Waiting Time**: Total time a job spends in the ready queue
> - **Throughput**: Number of jobs completed per unit time
> - **Resource Utilization**: Percentage of time resources are busy
> - **Overhead**: Extra time consumed in managing the processes
> - **Fairness**: Equal distribution of CPU time among processes

> [!consider] Evaluating Scheduling Algorithms
> When evaluating scheduling algorithms, we consider:
> 
> - **Arrival Time**: When a job arrives in the system
> - **Run Time**: How long a job needs to run
> 
> We use various schedulers like FIFO, SJK, STCF, and RR, comparing the turnaround and response times for each job under each scheduler.
> 
> **Assumptions**:
> - Same running time for each job
> - All jobs arrive at the same time
> - No I/O operations
> - Determined run time

> [!example] Evaluating Scheduling Algorithms
> This example illustrates how different scheduling algorithms perform under various conditions.
> 
> **FIFO (First-In-First-Out)**
> - Description: Jobs executed in the order they arrive.
> - Scenario: Jobs A, B, C with run times 10, 10, 10 units, arriving simultaneously.
> 
> ![[Pasted image 20240804232600.png]]
> 
> **FIFO with Different Running Times**
> - Removed Assumption: Jobs have the same running time.
> - Issue: Convoy Effect â€“ Short jobs wait for long jobs to complete.
> - Scenario: Jobs A, B, C with run times 100, 10, 10 units, arriving simultaneously.
> 
> ![[Pasted image 20240804232643.png]]
> 
> **SJF (Shortest Job First)**
> - Description: Jobs executed in order of their length, shortest job first.
> - Scenario: Jobs A, B, C with run times 100, 10, 10 units, arriving simultaneously.
>   
> ![[Pasted image 20240804232706.png]]
> 
> **SJF with Different Arrival Times**
> - Removed Assumption: All jobs arrive at the same time.
> - Issue: Smaller jobs arriving after a larger job face delays.
> - Scenario: Jobs A, B, C with run times 80, 10, 20 units. A arrives at 0, B at 10, C at 20.
>   
> ![[Pasted image 20240804232726.png]]
> 
> **STCF (Shortest Time-to-Completion First)**
> - Description: Preempts longer jobs when shorter jobs arrive.
> - Removed Assumptions: All jobs arrive at the same time, jobs cannot be preempted.
> - Scenario: Jobs A, B, C with run times 100, 10, 10 units. A arrives at 0, B at 10, C at 20.
> 
> ![[Pasted image 20240804232754.png]]
> 
> **RR (Round Robin)**
> - Description: Each job gets a fixed time slice (quantum) in cyclic order.
> - Focus: Improved response time compared to STCF.
> - Scenario: Jobs A, B, C with run times 100, 20, 30 units. All jobs arrive at time 0. Quantum = 10 units.
> - Response Times: A: 0, B: 10, C: 20 units
> - Average Response Time: (0 + 10 + 20) / 3 = 10 units
> 
> ![[Pasted image 20240804233056.png]]
> 
> **RR with I/O Operations**
> - Description: Round Robin scheduling with jobs that perform I/O operations.
> - Scenario: Jobs A, B, C with run times 50, 50, 50 units. A and C have I/O operations.
> - I/O occurs every 10 units of CPU time and takes 10 units to complete.
> - Quantum = 10 units
> 
> ![[Pasted image 20240804233424.png|500]]
> 
> - Note: The scheduler can switch to another job during I/O wait, improving overall CPU utilization.
> - Response Times: A: 0, B: 10, C: 20 units
> - Turnaround Times: A: 140, B: 110, C: 150 units (including I/O time)
> 
> **MLFQ (Multi-Level Feedback Queue)**
> - Description: Uses multiple queues with different priority levels, adjusting job priorities based on behavior.
> - Scenario: Jobs A (I/O-bound), B (CPU-bound), C (mixed) arrive simultaneously.
> - Rules:
>   1. Higher priority queues run first.
>   2. Jobs at the same priority level are scheduled round-robin.
>   3. When a job enters the system, it's placed at the highest priority.
>   4. If a job uses up its time quantum, its priority is reduced.
>   5. After a certain time period, move all jobs to the highest priority queue.
> 
> ```image_goes_here
> A diagram showing multiple queues with different priority levels. Job A frequently yields the CPU for I/O and stays in higher priority queues. Job B, being CPU-bound, moves to lower priority queues. Job C alternates between higher and lower queues based on its mixed behavior.
> ```
> 
> - Benefits:
>   - Adapts to different job types without prior knowledge of their behavior.
>   - Provides good response time for short and I/O-bound jobs.
>   - Ensures long-running CPU-bound jobs eventually make progress.

> [!consider] Removing Preemptive Assumptions
> When we remove preemptive scheduling, algorithms like STCF and standard RR become less effective. MLFQ can be adapted to work in a non-preemptive environment:
> 
> **Non-Preemptive MLFQ**
> - Jobs run to completion once started, but their next queue assignment is based on their previous behavior.
> - Considerations:
>   - Jobs that yield the CPU voluntarily (e.g., for I/O) are more likely to be scheduled again soon.
>   - Long-running jobs will eventually complete but may significantly delay shorter jobs.
>   - The system becomes less responsive to changes in job behavior.
> 
> **Challenges**
> - Priority Inversion: High-priority tasks may wait for low-priority ones to complete.
> - Starvation: Short jobs arriving after a long job starts may face significant delays.
> - Reduced Adaptability: The scheduler can't quickly respond to changes in system load or job characteristics.
> 
> **Potential Solutions**
> - Cooperative Multitasking: Encourage jobs to voluntarily yield the CPU at appropriate intervals.
> - Time Limits: Implement maximum run times for jobs, after which they're forced to yield.
> - Dynamic Priority Adjustment: Adjust priorities of waiting jobs based on their wait time.
> 
> While non-preemptive scheduling simplifies implementation, it significantly impacts system responsiveness and fairness. In practice, most modern systems use preemptive scheduling to balance efficiency, fairness, and responsiveness.

This revision incorporates I/O operations into the example callout, demonstrating how RR handles I/O-bound and CPU-bound jobs. It also introduces MLFQ as a more adaptive scheduling algorithm. The consideration callout then discusses the implications of removing preemptive scheduling, focusing on how MLFQ can be adapted and the challenges that arise in a non-preemptive environment.


> [!summary] Comparison of Scheduling Algorithms
> - **FIFO**: Simple to implement, but can lead to poor performance with varying job lengths.
> - **SJF**: Optimal for minimizing average turnaround time when all jobs are available simultaneously, but impractical in real systems due to unknown job lengths.
> - **STCF**: Improves on SJF by allowing preemption, but may lead to starvation of longer jobs.
> - **RR**: Provides fair CPU time distribution and good response times, but may increase average turnaround time.
> 
> **Best Use Cases**:
> - **FIFO**: Suitable for batch systems where simplicity is prioritized over performance.
> - **SJF/STCF**: Ideal for systems where job lengths are known or can be estimated accurately, and minimizing average turnaround time is crucial.
> - **STCF with I/O**: Beneficial in I/O-bound systems, as it can efficiently utilize CPU time during I/O waits.
> - **RR**: Best for time-sharing systems and interactive environments where quick response times are essential.
> - **RR without Preemption**: Useful in specific real-time systems where context switching overhead must be minimized.
> 
> In practice, modern operating systems often use hybrid approaches, combining elements of multiple algorithms to balance various performance metrics and adapt to different workloads. The choice of algorithm depends on system requirements, workload characteristics, and specific performance goals.

