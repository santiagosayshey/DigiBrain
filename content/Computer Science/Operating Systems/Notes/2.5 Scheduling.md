
> [!idea] Scheduling: Deciding Which Process Runs Next
> Scheduling is the **strategy used to determine which process should be dispatched to run next**. It involves:
> 
> - Maintaining a **queue of ready-to-run processes**
> - **Selecting the next process** based on a scheduling algorithm
> - **Balancing system objectives** (e.g., fairness, throughput, response time, turnaround time, waiting time, utilisation, overhead)
> 
> Key concepts:
> 1. **Scheduling Algorithms**: Methods for selecting the next process (e.g., Round Robin, Priority Scheduling)
> 2. **Preemption**: Ability to interrupt a running process to schedule another
> 
> Scheduling aims to **optimize system performance and ensure fair allocation** of CPU time among processes.

> [!example] General Scheduling
> Consider three processes: A, B, and C, with a Round Robin scheduler
> 
> 1. Scheduler **starts with A**, gives it a time slice
> 2. After time slice expires, **A is preempted, B is scheduled**
> 3. B runs for its time slice, then **C is scheduled**
> 4. After C's time slice, the **cycle repeats with A**
> 
> This ensures each process gets regular CPU time, preventing any single process from monopolizing the processor.

> [!idea] State Transitions in Process Scheduling
> State transitions refer to the changes in the status of a process as it moves through different stages of its lifecycle. This includes:
> 
> - **Ready State**: Process is ready to run but waiting for CPU time
> - **Running State**: Process is currently being executed by the CPU
> - **Blocked State**: Process is waiting for an event (e.g., I/O completion)
> - **Terminated State**: Process has finished execution
> 
> These transitions are crucial for efficient process management and scheduling.

> [!idea] Key Scheduling Concepts
> 
> 1. **Workload**: The set of processes that need to be scheduled
> 2. **Job**: A single unit of work that needs to be processed
> 3. **Scheduler**: The algorithm or mechanism that decides which job runs next
> 4. **Metric**: Criteria used to evaluate the performance of the scheduling algorithm (e.g., turnaround time, response time, waiting time)
>
> - **Turnaround Time**: Time from job submission to job completion
> - **Response Time**: Time from job submission to first response
> - **Waiting Time**: Total time a job spends in the ready queue
> - **Throughput**: Number of jobs completed per unit time
> - **Resource Utilization**: Percentage of time resources are busy
> - **Overhead**: Extra time consumed in managing the processes
> - **Fairness**: Equal distribution of CPU time among processes

> [!consider] Evaluating Scheduling Algorithms
> When evaluating scheduling algorithms, we consider:
> 
> - **Arrival Time**: When a job arrives in the system
> - **Run Time**: How long a job needs to run
> 
> We use various schedulers like FIFO, SJK, STCF, and RR, comparing the turnaround and response times for each job under each scheduler.
> 
> **Assumptions**:
> - Same running time for each job
> - All jobs arrive at the same time
> - No I/O operations
> - Determined run time

> [!example] Example: Evaluating Scheduling Algorithms
> 
> - **FIFO (First In, First Out)**:
>   - Issue: **Convoy Effect** â€“ Short jobs waiting for long jobs to complete.
> - **Shortest Job First (SJF)**:
>   - Solution to Convoy Effect: Prioritize shorter jobs.
> - **Next Step**: Consider non-simultaneous arrivals:
>   - **Challenge**: Smaller jobs arriving after a larger job may still face delays.
> - **Preemptive Schedulers** (e.g., STCF, RR):
>   - Allows interrupting a running process to schedule another, improving overall efficiency and responsiveness.
