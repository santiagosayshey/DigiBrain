

> [!idea]+ Hash Tables
> 
> A hash table is a dynamic data structure that allows for **efficient insertion, deletion, and searching** of elements using a **unique key**. It achieves **constant average time $O(1)$** for these basic operations by using a **hash function** to map keys to indices in an underlying array. This makes hash tables **highly useful for maintaining and manipulating sets of data** where quick access is essential.
>
>
> > [!consider] Consider a Phone Book
> >
> > Imagine storing phone numbers in an array, where the index corresponds to the person's name (an integer). While this allows for immediate access $O(1)$, it becomes impractical for large ranges of names. For example, if the highest name is "1,000,000", you would need an array of size 1,000,001, even if only a few people are listed, resulting in wasted space.
> >
> > Hash tables solve this issue by using a hash function to map keys (e.g., strings) to indices in a smaller array, providing space-efficient storage and retrieval. This makes hash tables versatile and powerful, handling large key ranges without excessive memory overhead.
>
> <br>

> [!idea] Hash Functions
>
> A hash function is a crucial component of a hash table that **maps a given key to an index in the underlying array**. The goal is to distribute the keys evenly across the array. A well-designed hash function should be efficient to compute and provide a uniform distribution of keys.
>
> When a key is passed through the hash function, it generates a hash code, which is then mapped to an index within the bounds of the array. This allows for **direct access to the desired element without the need to search through the entire array**.
>
> **Example: Modulo Function**
>
> - The modulo function is a simple hash function that takes the remainder of the key divided by the size of the array.
> - Formula: `hash(key) = key % array_size`
> - Example: If the key is 42 and the array size is 10, the hash function would map the key to index 2 (42 % 10 = 2).
> 
> ![[Hash table.png]]


> [!consider] Collisions and Hashing Techniques
>
> Hash **collisions** occur when multiple keys map to the same array index. There are two main approaches to handle collisions: open hashing and closed hashing.
>
> 1. **Open Hashing (Chaining)**  - Storing all elements with the same hash as 1 entry. 
> 	- Ensures referential integrity by maintaining a correct and navigable link for each key-value pair, despite collisions.
> 	
> 1. **Closed Hashing (Probing)** - Storing elements with the same hash in different table entries

> [!idea] Open Hashing - Chaining
>
> Each array index points to a linked list.
> - When a collision happens, the key-value pair is **appended to the linked list** at that index, allowing multiple pairs to be stored.
> - Searching for a key involves **traversing the linked list** at the corresponding index to find the desired value.
> - Deleting a value requires adjusting the pointers in the linkedlist
>
> ![[Group 2.png]]

> [!idea] Closed Hashing - Probing
>
> In closed hashing, when a collision occurs, **probing** is used to find an alternative empty slot in the array. ⊥ is used to indicate empty slots that values can be placed in.
> - Common probing techniques include:
>   - Linear Probing: Incrementally search for the next empty slot.
>   - Quadratic Probing: Use quadratic function to determine the next slot.
>   - Double Hashing: Use a secondary hash function to calculate the step size for probing.
>
>**Insertion in Linear Probing:**
>- Start at the initial index obtained by applying the hash function.
>- If the slot is occupied, increment the the next available slot and place the key there.
>
> ![[Group 10.png]]
>
> **Search in Linear Probing:**
>
> - To search for a key in a hash table using linear probing, we start at the initial index obtained by applying the hash function to the key.
> - We compare the key at the current index with the key we are searching for.
> - If the keys match, we have found the desired key-value pair.
> - If the keys don't match, we linearly probe to the next index.
> 
> ![[Group 12.png]]
>
> **Deletion in Linear Probing:**
> 
When deleting a key-value pair in a hash table using linear probing, the process involves shifting elements to maintain the integrity of the probing sequence. Here's how the deletion process works:
>1. Get the index `i` by applying the hash function `h` to the key `k`.
>2. If the slot at index `i` is empty (denoted by `⊥`), the key is not present in the hash table, so we return.
>3. If the element `e` at index `i` has a key different from `k`, we linearly probe to the next slot by incrementing `i` by 1 and go back to step 2.
>4. If the key at index `i` matches `k`, we have found the key-value pair to be deleted. We set the slot at index `i` to `⊥` to mark it as empty.
>5. We set the index `j` to `i+1` to start shifting elements.
>6. If the slot at index `j` is empty (`⊥`), we have finished shifting and can return.
>7. If the hash value of the element at index `j` is greater than `i`, it means the element at `j` was not probed to its current position and should not be shifted. We increment `j` by 1 and go back to step 6.
>8. If the hash value of the element at index `j` is less than or equal to `i`, it means the element at `j` was probed to its current position and needs to be shifted. We move the element from index `j` to index `i` and set the slot at index `j` to `⊥`.
>9. We update the index `i` to `j` and go back to step 5 to continue shifting elements.
>
>![[Group 13 1.png]]




 > [!idea]+ Hash Table Complexity
 > 
> | Operation | Average Time Complexity | Worst Case Time Complexity |
> |-----------|-------------------------|----------------------------|
> | Insertion | O(1)                    | O(n)                       |
> | Deletion  | O(1)                    | O(n)                       |
> | Search    | O(1)                    | O(n)                       |
>
> In the worst case, when all keys map to the same index (i.e., high number of collisions), the time complexity degrades to $O(n)$ as the linked list at that index needs to be traversed. However, with a well-designed hash function and appropriate collision resolution technique (e.g., chaining), the average case performance remains $O(1)$.

> [!application] Application: 2-SUM Problem
>
> - **Input**: An unsorted array `A` of `n` integers and a target sum `T`.
> - **Goal**: Determine whether or not there are two numbers `x` and `y` in `A` such that `x + y = T`.
> - **Naive solution**: Exhaustive search, which has a time complexity of $O(n^2)$.
> - **Better solution**: Sort the array `A` $O(n \cdot log n)$ and use binary search $O(\log n)$ to find the complement of each number.
> - **Best solution**: Use a hash table. For each element in the array, search for the difference of the target minus the current number. This operation takes constant time. By iterating through each number in the array, the overall time complexity becomes $O(n)$.



