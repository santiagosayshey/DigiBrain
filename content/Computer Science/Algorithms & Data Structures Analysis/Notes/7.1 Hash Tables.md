

> [!idea]+ Hash Tables
> 
> A hash table is a dynamic data structure that allows for **efficient insertion, deletion, and searching** of elements using a **unique key**. It achieves **constant average time $O(1)$** for these basic operations by using a **hash function** to map keys to indices in an underlying array. This makes hash tables **highly useful for maintaining and manipulating sets of data** <font color="#ffc000">where quick access is essential</font>.
>
>
> > [!consider] Consider a Phone Book
> >
> > Imagine storing phone numbers in an array, where the index corresponds to the person's name (an integer). While this allows for immediate access $O(1)$, it becomes impractical for large ranges of names. For example, if the highest name is "1,000,000", you would need an array of size 1,000,001, even if only a few people are listed, resulting in wasted space.
> >
> > Hash tables solve this issue by using a hash function to map keys (e.g., strings) to indices in a smaller array, providing space-efficient storage and retrieval. This makes hash tables versatile and powerful, handling large key ranges without excessive memory overhead.
>
> <br>

> [!application] Application: 2-SUM Problem
>
> - **Input**: An unsorted array `A` of `n` integers and a target sum `T`.
> - **Goal**: Determine whether or not there are two numbers `x` and `y` in `A` such that `x + y = T`.
> - **Naive solution**: Exhaustive search, which has a time complexity of $O(n^2)$.
> - **Better solution**: Sort the array `A` $O(n \cdot log n)$ and use binary search $O(\log n)$ to find the complement of each number.
> - **Best solution**: Use a hash table. For each element in the array, search for the difference of the target minus the current number. This operation takes constant time. By iterating through each number in the array, the overall time complexity becomes $O(n)$.


