> [!idea]+ Hash Tables
> 
> A hash table is a dynamic data structure that allows for **efficient insertion, deletion, and searching** of elements using a **unique key**. It achieves **constant time $O(1)$** for these basic operations by using a **hash function** to map keys to indices in an underlying array. This makes hash tables **highly useful for maintaining and manipulating sets of data** where quick access is essential.
>
> | Operation | Time Complexity |
> |-----------|----------------|
> | Insertion | O(1)           |
> | Deletion  | O(1)           |
> | Search    | O(1)           |
![[hash-table.png]]
> 
> 

> [!consider] Consider a Phone Book
>
> Imagine your parents' friends are incredibly unimaginative and decide to name their children using integers. In this scenario, you can easily store and retrieve their phone numbers using an **array**, where the **index corresponds to the child's name**. For example, to find the phone number of the child named "15," you simply look at index 15 in the array, achieving **immediate access $O(1)$**.
>
> However, this approach has a significant drawback in terms of space efficiency. If the range of possible names (integers) is large, the array would need to be very large as well, even if only a few children are named. For instance, if the highest named child is "1,000,000," you would need an array of size 1,000,001 to store all the phone numbers, even if there are only a handful of children. This results in a lot of wasted space and is not practical for large ranges of keys.
>
> Hash tables address this issue by providing a more space-efficient way to store and retrieve data. Instead of using only integers as keys, you can **use any data type**, such as strings for names. The hash function maps the keys to indices in a smaller underlying array, allowing for **efficient storage and retrieval of various types of data**. This makes hash tables a **versatile and powerful tool** in computer science, as they can handle large ranges of keys without requiring excessive memory like arrays would in this scenario.


> [!idea] Hash Functions
>
> A hash function is a crucial component of a hash table that **maps a given key to an index in the underlying array**. The goal is to distribute the keys evenly across the array. A well-designed hash function should be efficient to compute and provide a uniform distribution of keys.
>
> When a key is passed through the hash function, it generates a hash code, which is then mapped to an index within the bounds of the array. This allows for **direct access to the desired element without the need to search through the entire array**.
>
> **Example: Modulo Function**
>
> - The modulo function is a simple hash function that takes the remainder of the key divided by the size of the array.
> - Formula: `hash(key) = key % array_size`
> - Example: If the key is 42 and the array size is 10, the hash function would map the key to index 2 (42 % 10 = 2).

> [!consider] Collisions and Chaining
>
> Hash functions are subject to collisions: when two or more keys map to the same index in the underlying array. **To handle collisions, we use chaining with linked lists.**
>
> In chaining, **each element of the array is a linked list.** **When a collision occurs, instead of directly storing the value at the mapped index, it is appended to the linked list at that index.** This allows multiple key-value pairs to be stored at the same index.
>
> When searching for a key, the hash function is applied to determine the index, and then the linked list at that index is traversed to find the corresponding value. If multiple keys map to the same index, they will be stored in the same linked list, and the search will require traversing the list to find the desired key.
>
> **Example: Collision Resolution with Chaining**
>
> Suppose we have a hash table with an array size of 5 and the following key-value pairs to insert:
>
> | Key | Value |
> |-----|-------|
> | "apple" | 1 |
> | "banana" | 2 |
> | "cherry" | 3 |
> | "date" | 4 |
>
> Let's assume the hash function maps "apple" and "date" to index 0, "banana" to index 2, and "cherry" to index 3.
>
> After inserting the key-value pairs, the hash table would look like this:
>
> | Index | Linked List |
> |-------|-------------|
> | 0     | ("apple", 1) -> ("date", 4) |
> | 1     | empty |
> | 2     | ("banana", 2) |
> | 3     | ("cherry", 3) |
> | 4     | empty |
>
> When searching for the value associated with "date", the hash function will map it to index 0, and then the linked list at index 0 will be traversed to find the key-value pair ("date", 4).

In this updated version, the "Hash Functions" callout focuses on the purpose and functionality of hash functions without mentioning collisions. The "Collisions and Chaining" callout introduces collisions and explains how chaining with linked lists is used to handle them. The example illustrates how collisions are resolved using chaining in a specific scenario.

> [!application] Application: De-Duplication
>
> - **Given**: A stream of objects (linear scan through a file line by line, or objects arriving in real-time, such as packets in a router).
> - **Goal**: Remove duplicates and keep track of unique objects.
> - **Solution**: When a new object `x` arrives, look up `x` in a hash table. If it exists, ignore it. Otherwise, add it to the hash table.

> [!application] Application: 2-SUM Problem
>
> - **Input**: An unsorted array `A` of `n` integers and a target sum `T`.
> - **Goal**: Determine whether or not there are two numbers `x` and `y` in `A` such that `x + y = T`.
> - **Naive solution**: Exhaustive search, which has a time complexity of $O(n^2)$.
> - **Better solution**: Sort the array `A` $O(n \cdot log n)$ and use binary search $O(\log n)$ to find the complement of each number.
> - **Best solution**: Use a hash table. For each element in the array, search for the difference of the target minus the current number. This operation takes constant time. By iterating through each number in the array, the overall time complexity becomes $O(n)$.


