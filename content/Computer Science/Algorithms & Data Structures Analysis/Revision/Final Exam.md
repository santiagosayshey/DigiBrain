# Asymptotic Analysis
  
| Notation              | Meaning                                                                                 |
| --------------------- | --------------------------------------------------------------------------------------- |
| $f(n) = O(g(n))$      | Highest degree term of $f(n)$ is less than or equal to highest degree term of $g(n)$    |
| $f(n) = \Omega(g(n))$ | Highest degree term of $f(n)$ is greater than or equal to highest degree term of $g(n)$ |
| $f(n) = \Theta(g(n))$ | Highest degree terms of $f(n)$ and $g(n)$ are equal                                     |
| $f(n) = o(g(n))$      | Highest degree term of $f(n)$ is strictly less than highest degree term of $g(n)$       |
| $f(n) = \omega(g(n))$ | Highest degree term of $f(n)$ is strictly greater than highest degree term of $g(n)$    |
|                       |                                                                                         |
# Induction

| Step                    | Description                                                                                                                                           |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1. Base Case            | Prove that the statement holds for the smallest value of $n$, usually $n = 0$ or $n = 1$, depending on the problem.                                   |
| 2. Inductive Hypothesis | Assume that the statement holds for some arbitrary value $k$, i.e., assume $P(k)$ is true for some $k \geq n$, where $n$ is the base case value.      |
| 3. Inductive Step       | Prove that if the statement holds for $k$, then it must also hold for $k + 1$, i.e., show that $P(k) \implies P(k + 1)$.                              |
| 4. Conclusion           | Therefore, by the principle of mathematical induction, the statement $P(n)$ holds for all $n \geq n_0$, where $n_0$ is the base case value. $\square$ |



# AVL Rotations

| Imbalance Type   | Condition                              | Balance Factor of Node | Balance Factor of Node's Child    | Rotations Needed                                          |
| ---------------- | -------------------------------------- | ---------------------- | --------------------------------- | --------------------------------------------------------- |
| LL (Left-Left)   | Left subtree of left child is deeper   | Balance Factor: +2     | Balance Factor of Left Child: +1  | Single Right Rotation at Node                             |
| RR (Right-Right) | Right subtree of right child is deeper | Balance Factor: -2     | Balance Factor of Right Child: -1 | Single Left Rotation at Node                              |
| LR (Left-Right)  | Right subtree of left child is deeper  | Balance Factor: +2     | Balance Factor of Left Child: -1  | Left Rotation at Left Child, then Right Rotation at Node  |
| RL (Right-Left)  | Left subtree of right child is deeper  | Balance Factor: -2     | Balance Factor of Right Child: +1 | Right Rotation at Right Child, then Left Rotation at Node |
**NOTE:** When performing a x rotation, if a child node has two children, then the x child becomes the child of the root, where x can be left or right. 

# Algorithms

| Algorithm                         | Description                                                                               | Complexity                               | Key                                                                                                                   | General Process                                                                                                                    | Special Considerations                                                             |
| --------------------------------- | ----------------------------------------------------------------------------------------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |
| Recursive Multiplication          | Recursive multiplication algorithm that breaks the problem into smaller subproblems       | $O(n^2)$                                 | $n$: number of digits                                                                                                 | Split numbers into halves, recursively calculate four partial products, add the partial products                                   | Requires combining four partial products, less efficient than Karatsuba's method   |
| Karatsuba's Algorithm             | Efficient algorithm for multiplying two n-digit numbers                                   | $O(n^{\log_2(3)})$                       | $n$: number of digits                                                                                                 | Split numbers into halves, find partial 3 products, add partial products                                                           | Uses 3 partial products instead of 4                                               |
| Counting Sort                     | Sorting algorithm that counts the number of objects having distinct key values            | $O(n+k)$                                 | $n$: number of elements, $k$: maximum value of the input range (e.g., for input range [0, 10], $k$ = 10)              | Count the occurrences of each distinct element, then use the counts to determine the positions of each element in the sorted array | Only works for integer keys with a small range                                     |
| Radix Sort                        | Sorting algorithm that sorts data with integer keys by grouping keys by individual digits | $O(d(n+k))$                              | $n$: number of elements, $k$: range of each digit (e.g., for decimal digits, $k$ = 10), $d$: maximum number of digits | Sort elements by each digit, starting from the least significant digit to the most significant                                     | Only works for integer keys                                                        |
| Randomised Selection Algorithm    | Selects the k-th smallest element from an unsorted list                                   | $O(n)$ average case, $O(n^2)$ worst case | $n$: number of elements                                                                                               | Partition the list around a randomly selected pivot, recursively search the appropriate sublist                                    | Worst case is extremely unlikely                                                   |
| Deterministic Selection Algorithm | Selects the k-th smallest element from an unsorted list                                   | $O(n)$                                   | $n$: number of elements                                                                                               | Divide the list into groups of 5, find the median of medians, partition the list around the median of medians, recursively search  | Guaranteed $O(n)$ worst case, but more complex to implement and mostly theoretical |
| Kosaraju's Algorithm              | Finds strongly connected components in a directed graph                                   | $O(V+E)$                                 | $V$: number of vertices, $E$: number of edges                                                                         | Perform DFS on the graph and its transpose, using the finishing times of the first DFS as the starting order for the second        | -                                                                                  |
| Dijkstra's Algorithm              | Finds the shortest path from a single source to all other nodes                           | $O((V+E)\log V)$                         | $V$: number of vertices, $E$: number of edges                                                                         | Maintain a priority queue of vertices, greedily select the vertex with the smallest distance                                       | Cannot handle negative edge weights                                                |
| Bellman-Ford Algorithm            | Finds the shortest path from a single source to all other nodes (handles negative edges)  | $O(VE)$                                  | $V$: number of vertices, $E$: number of edges                                                                         | Relax all edges $V-1$ times                                                                                                        | Can detect negative cycles                                                         |
| Floyd-Warshall Algorithm          | Finds the shortest path between all pairs of nodes                                        | $O(V^3)$                                 | $V$: number of vertices                                                                                               | Dynamic programming approach, update the shortest path matrix in phases                                                            | Finds shortest paths between all pairs                                             |
| Kruskal's Algorithm               | Finds a minimum spanning tree in a weighted, connected graph                              | $O(E \log E)$                            | $E$: number of edges                                                                                                  | Sort edges by weight, greedily add edges to the MST that don't create cycles using UF Data structure                               | Better for sparse graphs with fewer edges                                          |
| Prim's Algorithm                  | Finds a minimum spanning tree in a weighted, connected graph                              | $O(E \log V)$                            | $V$: number of vertices, $E$: number of edges                                                                         | Maintain a priority queue of vertices, greedily add the vertex with the smallest edge weight to the MST                            | Better for dense graphs with more edges                                            |

# Data Structures

| Data Structure      | Operation | Average Case | Worst Case  | Best Case   | Special Considerations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| ------------------- | --------- | ------------ | ----------- | ----------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Binary Search Trees | Search    | $O(\log n)$  | $O(n)$      | $O(\log n)$ | Worst case occurs when the tree is unbalanced, resembling a linked list. Balancing techniques like AVL trees and Red-Black trees can maintain $O(\log n)$ height, ensuring optimal search, insertion, and deletion times in the worst case.                                                                                                                                                                                                                                                                                                                                                         |
|                     | Insertion | $O(\log n)$  | $O(n)$      | $O(\log n)$ |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
|                     | Deletion  | $O(\log n)$  | $O(n)$      | $O(\log n)$ |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| AVL Trees           | Search    | $O(\log n)$  | $O(\log n)$ | $O(\log n)$ | AVL trees are self-balancing binary search trees that maintain a height difference of at most 1 between the left and right subtrees of any node. This self-balancing property ensures a height of $O(\log n)$ in the worst case, providing optimal search, insertion, and deletion times.                                                                                                                                                                                                                                                                                                           |
|                     | Insertion | $O(\log n)$  | $O(\log n)$ | $O(\log n)$ |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
|                     | Deletion  | $O(\log n)$  | $O(\log n)$ | $O(\log n)$ |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| Skip Lists          | Search    | $O(\log n)$  | $O(n)$      | $O(\log n)$ | Skip lists are probabilistic data structures that maintain a hierarchy of linked lists, with each higher level being a "skip" of the lower levels. The number of levels for each element is determined randomly, with a probability of 1/2 for each level. This random balancing ensures an expected $O(\log n)$ height, providing efficient search, insertion, and deletion operations. However, the worst-case height can be $O(n)$ with a low probability. Skip lists are useful in scenarios where the simplicity and ease of implementation are prioritized over strict worst-case guarantees. |
|                     | Insertion | $O(\log n)$  | $O(n)$      | $O(\log n)$ |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
|                     | Deletion  | $O(\log n)$  | $O(n)$      | $O(\log n)$ |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| Hash Tables         | Search    | $O(1)$       | $O(n)$      | $O(1)$      | Hash tables provide constant-time average-case operations by using a hash function to map keys to array indices. Collisions occur when multiple keys hash to the same index.<br><br>Hash tables resolve collisions using either:<br><br>1. Separate chaining: Colliding elements are stored in linked lists at each index. <br>2. Linear probing: Probes the next sequential element until an empty slot is found.<br><br>Worst case: All keys hash to the same index, resulting in $O(n)$ time complexity.                                                                                         |
|                     | Insertion | $O(1)$       | $O(n)$      | $O(1)$      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
|                     | Deletion  | $O(1)$       | $O(n)$      | $O(1)$      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
# Graphs

| Type                         | Description                                                                                                                                 | Space Complexity   | Time Complexity                                                             | Advantages                                                                        | Disadvantages                                                         | Examples of Use                                                                                      |
| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ------------------ | --------------------------------------------------------------------------- | --------------------------------------------------------------------------------- | --------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| Adjacency List               | Represents a graph using a list or array of lists. Each vertex has a list of its adjacent vertices.                                         | $O(\|V\| + \|E\|)$ | - Add Edge: $O(1)$<br>- Remove Edge: $O(\|V\|)$<br>- Check Edge: $O(\|V\|)$ | - Space-efficient for sparse graphs<br>- Faster for iterating over edges          | - Slower for checking edge existence<br>- Slower for dense graphs     | - Social networks (e.g., friends list)<br>- Web crawlers (links between web pages)                   |
| Adjacency Matrix             | Represents a graph using a matrix. The element at index (i, j) represents an edge from vertex i to vertex j.                                | $O(\|V\|^2)$       | - Add Edge: $O(1)$<br>- Remove Edge: $O(1)$<br>- Check Edge: $O(1)$         | - Faster for checking edge existence<br>- Easier to implement                     | - Consumes more space<br>- Slower for iterating over edges            | - Storing distances between cities<br>- Representing a chessboard (edges between squares)            |
| Adjacency Array (Unweighted) | Represents a graph using an array of integers. Each vertex is assigned an index, and the array stores the indices of its adjacent vertices. | $O(\|V\| + \|E\|)$ | - Add Edge: $O(1)$<br>- Remove Edge: $O(\|E\|)$<br>- Check Edge: $O(\|E\|)$ | - Space-efficient<br>- Fast for iterating over edges                              | - Slower for checking edge existence<br>- Requires contiguous memory  | - Game maps (e.g., adjacent rooms)<br>- Character relationships in a story                           |
| Adjacency Array (Weighted)   | Similar to unweighted adjacency array, but each vertex has an additional array to store edge weights.                                       | $O(\|V\| + \|E\|)$ | - Add Edge: $O(1)$<br>- Remove Edge: $O(\|E\|)$<br>- Check Edge: $O(\|E\|)$ | - Space-efficient<br>- Fast for iterating over edges<br>- Supports weighted edges | - Slower for checking edge existence<br>- Requires contiguous memory  | - Road networks with distances<br>- Flight routes with costs                                         |
| Linked List                  | Represents a graph using a linked list of vertices. Each vertex contains a pointer to a linked list of its adjacent vertices.               | $O(\|V\| + \|E\|)$ | - Add Edge: $O(1)$<br>- Remove Edge: $O(\|V\|)$<br>- Check Edge: $O(\|V\|)$ | - Dynamic memory allocation<br>- Efficient for adding/removing vertices           | - Slower for checking edge existence<br>- More complex implementation | - Family trees (adding/removing family members)<br>- Version control systems (branching and merging) |
# P & NP

| Concept                                | Description                                                                                                                                                                     | Examples                                                                                                                                                     | Implications                                                                                                                         |
| -------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------ |
| P (Polynomial Time)                    | Problems solvable in polynomial time, i.e., time complexity is $O(n^k)$, where $k$ is a constant.                                                                               | - Linear search<br>- Euler path<br>- Shortest path (Dijkstra's algorithm)<br>- Maximum flow (Ford-Fulkerson algorithm)                                       | - Efficiently solvable<br>- Deterministic algorithms exist                                                                           |
| NP (Non-deterministic Polynomial Time) | Problems verifiable in polynomial time, but not necessarily solvable in polynomial time.                                                                                        | - Traveling Salesman Problem<br>- Subset Sum<br>- Graph Coloring<br>- Boolean Satisfiability (SAT)                                                           | - No known polynomial-time solution<br>- Brute-force may be required                                                                 |
| NP-Hard                                | Problems at least as hard as the hardest problems in NP. A problem is NP-Hard if all other NP problems can be reduced to it in polynomial time, but it may not be in NP itself. | - Halting Problem (undecidable)<br>- Integer Factorization<br>- Traveling Salesman Problem (optimization version)<br>- Graph Coloring (optimization version) | - Solving an NP-Hard problem efficiently would mean $P = NP$<br>- NP-Hard problems may not have polynomial-time verification         |
| NP-Complete                            | Hardest problems in NP. A problem is NP-Complete if it is in NP and all other NP problems can be reduced to it in polynomial time.                                              | - Boolean Satisfiability (SAT)<br>- Knapsack Problem<br>- Hamiltonian Cycle<br>- Vertex Cover                                                                | - Solving an NP-Complete problem efficiently would mean $P = NP$<br>- No polynomial-time algorithm known for any NP-Complete problem |

- $P \subseteq NP$: All problems in P are also in NP, but it is unknown whether $P = NP$.
- If $P = NP$, all problems in NP would be solvable in polynomial time, which would have significant implications for cryptography, optimization, and algorithm design.
- Boolean Satisfiability (SAT) is the first problem proven to be NP-Complete. It asks whether a Boolean expression can be satisfied by some assignment of Boolean values to its variables.
