### Question 1 (5 marks): 

```
Has OpenAI's **latest** version of ChatGPT sourced all of its training data ethically? You must support your answer with clear explanations, sound logic, and referenced evidence. (Also, make sure you identify which version you're talking about. You will be using 3.5, as noted below, but is this the latest version?)
```

While the advancements made by AI models such as GPT-3 and GPT-4 undeniably bring numerous benefits, drawing from the evidence available, it can be argued that the method in which data is sourced for these models is not entirely ethical. However, understanding the full scope of this assertion requires an exploration of both the sourcing methods and the broader implications of their deployment. This involves grappling with the intricate relationship between intent, impact, and the inherent challenges tied to the vast and diverse data on which these models are trained.

As per Brown et al. (2020), GPT-3's primary training sources included web scraping from the Common Crawl & WebText datasets, and online book collections such as Books1, Books2, and Wikipedia.

As for the latest model GPT-4, while exact details about its training sources are not publicly disclosed, the significant jump in parameters from GPT-3's 175 billion to GPT-4's 100 trillion, as highlighted in [this article](https://simplified.com/blog/ai-writing/chatgpt-vs-gpt-3/), suggests it might have utilized a more diverse range of sources.

Furthermore, OpenAI's own [privacy policy](https://openai.com/policies/privacy-policy) reveals that user interactions also play a role in refining the model. An opt-out for users who don't want their data to be used is provided, however, it's worth noting that while this opt-out option exists, many users might not be aware of it.

OpenAI's proactive approach could be questioned here: if they genuinely prioritise ethical considerations, should they not actively inform users of their right to opt-out? Is simply having an opt-out clause buried somewhere in the terms and conditions sufficient?

As these datasets are massive compilations of online content, there are inherent challenges in ensuring every piece of information is ethically sourced, free of bias, or completely accurate.

The process of refining training data to remove bias is an intricate endeavour. No matter how advanced the refining methods are, there will always be nuances, subtleties, and cultural contexts that can introduce biases in the results. It's akin to filtering water: while larger contaminants can be removed, microscopic elements may still permeate. This raises a critical question: Can a model ever truly be unbiased, given the vast and diverse nature of the data it's trained on?

Regardless, we must question the value of intent for such a complex debate. Does any of this matter in the context of OpenAI's goal? 

Consider education. ChatGPT and similar models have revolutionized the way we learn. They offer instant access to knowledge, facilitate dynamic interactions tailored to individual learning paces, and, in many cases, trivialise education by providing valuable resources to those who might not have access to traditional educational tools. The impact on professional training, self-guided learning, and even early education is profound.

But it begs the question: Is the potential compromise on data privacy a price worth paying for these educational advancements? Do we prioritise the personal sanctity of our data, or do we value the collective progress that such tools offer? Is there a middle ground where data privacy and technological advancement can coexist harmoniously?

In the grand scheme, these ethical debates aren't merely black or white. They prompt us to reassess our values, determine our priorities, and decide what we're willing to sacrifice for the larger good. The balance between individual privacy and collective benefit remains a tightrope walk, one that we, as a society, are still learning to navigate.

Drawing from the evidence and discussions presented, it can be concluded that the method in which data is sourced for these models is *not* ethical. Yet, this conclusion propels us into an even more fundamental territory: Does it matter if it's ethical or not? If the advancements derived from such technologies dramatically benefit humanity as a whole, should we reconsider our traditional ethical boundaries? Or should we adhere to a strict moral code, even if it means potentially hindering progress? These questions, rooted in the essence of what it means to progress responsibly, will undoubtedly shape the trajectory of future technological developments.


**References**
**[Brown, T, Mann, B, Ryder, N, Subbiah, M, Kaplan, JD, Dhariwal, P, Neelakantan, A, Shyam, P, Sastry, G, Askell, A & Agarwal, S 2020]**, ‘Language models are few-shot learners’, Advances in neural information processing systems, 33, pp. 1877–1901.

**[OpenAI OpCo, LLC 2023]**, Privacy policy, OpenAI, viewed 23 October 2023, [https://openai.com/policies/privacy-policy](https://openai.com/policies/privacy-policy).

Yadav, A 2023, 'A Complete Comparison of ChatGPT, GPT-3, and GPT-4: What’s the Real Difference?', _AI Writing_, blog post, 21 May, viewed 28 October 2023, [https://simplified.com/blog/ai-writing/chatgpt-vs-gpt-3/](https://simplified.com/blog/ai-writing/chatgpt-vs-gpt-3/).
### Question 2 (5 marks)

```
You should create an account and connect to ChatGPT. The free access plan allows you to use ChatGPT 3.5, which is the version that we wish you to use for this assignment. Find a short poem in the public domain, 8 lines long, and type/paste the first 6 lines into ChatGPT. What does ChatGPT do when you do this? 

Ask ChatGPT to add two more lines that are as different as possible from the first six. 

Analyse the two lines you have been given and propose an explanation for why those lines were produced.

You should include either an image or the text of your interaction with ChatGPT.
```

> **"Masks" by Shel Silverstein**

*She had blue skin,
And so did he.
He kept it hid
And so did she.
They searched for blue
Their whole life through.
Then passed right by–
And never knew.*

![](docs/Images/Pasted%20image%2020231028111536.png)

The two lines were generated based on the context and theme of the original poem. They offer a contrasting resolution that emphasises discovery and the celebration of diversity. The production of these lines is influenced by the model's understanding of poetic structure and its ability to continue a narrative in a complementary manner. 

This capability stems from LLMs' proficiency in predicting the next most likely word by analysing vast amounts of text data. Given a series of words, the model references the patterns it's learned to produce a coherent continuation. While it doesn't truly "understand" like humans, it mimics understanding by leveraging these patterns in context. 

This scenario is intriguing as it beckons us to question the essence of understanding itself. Can the billions or trillions of parameters used by such a model, drawing upon myriad patterns and data, be equated to a human brain forming conclusions based on *true* understanding and personal experiences?
### Question 3 (5 marks)

```
Find out from ChatGPT 3.5 how current its information is. List at least two things that might be incorrect or incomplete. You may need to ask it several questions to get these answers.
```

![](docs/Images/Pasted%20image%2020231029064653.png)

- This information varies. According to some OpenAI help threads online, this cut-off date has been extended to April 2023 in some regions. The original cut-off date was January 2021 (When ChatGPT first released in November 2022)

![](docs/Images/Pasted%20image%2020231028112849.png)
- This is really interesting. It comprehends that it's cut-off date is January 2022, yet still provides an (incorrect) answer for the 2022 Champion but not the 2023 Champion. 

![](docs/Images/Pasted%20image%2020231029064824.png)
- Interesting that this answer actually indicates the possibility of incorrect information (Damian Lillard currently plays for the Milwaukee Bucks and *not* the Portland Trail Blazers)

![](docs/Images/Pasted%20image%2020231029065540.png)

- Another interesting answer. I think it shows that there can exist unaccounted for ambiguity when answering more complex questions that struggles to account for any possible future change. I've found that ChatGPT often prioritises more recent events when there is some sort of duplicity, and of course it fails to know that I was actually talking about the most recent Spider-Man 2 video game released October 20, 2023 by Insomniac Games. 

![](docs/Images/Pasted%20image%2020231029065803.png)
- A more straightforward answer that actually acknowledges the possibility of any games made after it's cut off date.

![](docs/Images/Pasted%20image%2020231029071011.png)
- A really interesting response. It says "Indie Cindy (2014) was indeed a Pixies album released after my cut-off date in January 2022", which is pretty hilarious.
- It mentions *Beneath the Eyrie* in the explanation, despite me not mentioning it in the follow up response.
- *Doggerel* (2022) is left out and was clearly accounted for when mentioning that it was possible for more albums to be released after it's cut-off date
- There is some clear incorrect information for *Come On Pilgrim*. It's widely accepted that it is indeed an EP, and not an album but the Pixies themselves consider it to be their debut album and not just an EP. 
### Question 4 (10 marks)

```
By default, ChatGPT just gives you answers, with no indication of the degree to which the answer is supported by evidence, nor whether there is disagreement over the answer. In this question we want you to:

- Propose a scale for how much a claim is supported by evidence
- Propose a scale for how much disagreement there is over a particular claim
- Use conversational interaction with ChatGPT to get it to provide answers on both scales whenever it answers you

Your submitted answer should include a clear statement of both scales, why you have chosen them, and both the frame you used to get ChatGPT to use the scales and clear evidence of the frames in action. You may find [this reference](https://www.cuemath.com/measurement/scales-of-measurement/)

[Links to an external site.](https://www.cuemath.com/measurement/scales-of-measurement/) useful for a quick introduction to statistical scales of measurement. Think carefully about how you would use this scale, and even how detailed it has to be.
```

1. **Evidence Support Scale (ESS)**: How much a claim is supported by evidence.

The Evidence Support Scale (ESS) is based on the _Interval Scale_, as it denotes meaningful divisions between levels of evidence support, with each point on the scale having a specific, consistent meaning. This allows for a systematic and interpretable evaluation of the strength of evidence backing a claim.

- **0**: No evidence available or claim is based on speculation.
- **1**: Limited evidence; some anecdotal or non-peer-reviewed sources might support the claim.
- **2**: Moderate evidence; a mix of peer-reviewed and non-peer-reviewed sources support the claim.
- **3**: Strong evidence; predominantly peer-reviewed sources support the claim.
- **4**: Overwhelming evidence; consensus in the field and robust peer-reviewed research support the claim.

1. **Disagreement Level Scale (DLS)**: How much disagreement there is over a particular claim.

The Disagreement Level Scale (DLS) employs an _Ordinal Scale_ as it orders levels of disagreement without assuming consistent differences between levels. This captures the nature of disagreements in a nuanced manner, reflecting how contentious a topic might be without insisting on equidistant divisions.

- **1**: Consensus; virtually no disagreement in the field.
- **2**: Minor disagreement; a small minority questions the prevailing view.
- **3**: Split views; the field is divided, with multiple valid perspectives.
- **4**: Major disagreement; no clear prevailing view exists, and debates are ongoing.
- **5**: Total contention; the topic is highly controversial with no signs of reaching consensus.

![](docs/Images/Pasted%20image%2020231029082029.png)

![](docs/Images/Pasted%20image%2020231029082428.png)

![](docs/Images/Pasted%20image%2020231029083219.png)