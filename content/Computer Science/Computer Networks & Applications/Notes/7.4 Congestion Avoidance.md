> [!consider]+ What Happens When a Network Router Is Overwhelmed by Data?
> Imagine a scenario where a client sends data at a rate that exceeds the processing capacity of a network router. This overload can lead to significant network issues: the **router's buffer may fill up**, resulting in **dropped packets**, and as the queue lengthens, it causes **delays to increase**. 
> 
> This is **congestion**: **a state where the network resources are pushed beyond their limits**, disrupting the smooth flow of data.

> [!consider]+ Reasons to Avoid Network Congestion
> Network congestion not only slows down data transmission but also has broader implications for network performance:
> - **Limited Throughput**: Throughput is capped at **routers**. Sending data at rates higher than what the router can handle doesn't increase throughput; instead, it causes a bottleneck.
> - **Increased Delay**: Congestion significantly increases the average **delay**. As more packets are queued, the time taken for a packet to move through the network increases.
> - **Wasted Resources**: Retransmission of packets—whether dropped or delayed—adds unnecessary overhead to the network. If a packet is dropped, all the effort and resources used to transmit it thus far, including the efforts of earlier routers, are wasted.
> - **Degraded Performance**: As the level of congestion approaches the network's capacity, performance degrades exponentially. Avoiding congestion is essential to maintain the efficiency and reliability of network communication.

> [!idea]+ Approaches to Avoiding Congestion
> There are two primary strategies for tackling network congestion:
> 
> 1. **Network Layer Assisted**:
>    - Routers actively monitor traffic and provide explicit feedback on congestion levels and available data rates.
>    - Mechanisms like Explicit Congestion Notification (ECN), as proposed in RFC 3168, allow routers to flag packets to indicate congestion without dropping them.
> 
> 2. **End-Systems**:
>    - End systems, such as computers and servers, deduce congestion indirectly through packet acknowledgments and round-trip times.
>    - TCP/IP implementations often adjust their sending rate based on these cues, increasing the rate cautiously to avoid causing congestion.
> 
> **Which is better?** While network-assisted approaches can increase the complexity of router design, they provide accurate congestion signals. Conversely, end-system strategies rely on inferences that can be incorrect, especially in networks with variable conditions like mobile networks. Both methods play a role in modern networks, often complementing each other to provide robust congestion management.


> [!idea]+ TCP Congestion Control: Tahoe Algorithm
> TCP employs algorithms like Tahoe to manage congestion control by adjusting the size of the congestion window (`CongWin`). 
> 
> ```
> Initialize CongWin = 1 MSS
> Initialize ssthresh = 65535 bytes
> 
> // Slow Start Phase
> While CongWin < ssthresh:
>   On ACK received:
>     CongWin = CongWin + MSS
>   On timeout:
>     ssthresh = CongWin / 2
>     CongWin = 1 MSS
> 
> // Congestion Avoidance Phase
> While CongWin >= ssthresh:
>   On ACK received:
>     CongWin = CongWin + (MSS * MSS) / CongWin
>   On timeout:
>     ssthresh = CongWin / 2
>     CongWin = 1 MSS
> ```
> 
> This routine controls the sending rate based on network feedback. During the **Slow Start** phase, `CongWin` grows rapidly with each acknowledgment received. If a timeout occurs, indicating possible congestion, the `ssthresh` is lowered, and `CongWin` is reset to 1 MSS. Once the `CongWin` exceeds `ssthresh`, the algorithm enters the **Congestion Avoidance** phase, where `CongWin` grows more gradually. This helps to probe for the available capacity while trying to avoid inducing further congestion.