> A compiler is a program that translates programs from a source language *Jack* into a target language *Hack VM*

- We parse code syntax to understand it’s semantics and reveal intent

## Background
- Compilation consists of two stages:
	1. Syntax Analysis - understanding the semantics implied by the source code (divided into two more stages)
		1. Tokenising - grouping input characters into a stream of tokens
		2. Parsing - Matching token stream with language grammar
	2. Code Generation - reconstructing the semantics in VM code

![[docs/Images/Pasted image 20231002234954.png]]
### Tokenising
- Jack has a set of *tokens* or words that form the *lexicon*
	- Keywords - `class, while, for, etc`
	- Symbols - `+, <, etc`
	- Integer Constants - `17, 214, etc`
	- String Constants - `”FAQ”, “NAME”, etc`
	- Identifiers -  textual labels for naming variables, classes, functions
- These tokens are treated as the simplest elements in a program and are fed 1 by 1 into the compiler for code generation
- Essentially, we turn a stream of characters into a stream of tokens

![[docs/Images/Pasted image 20231003002309.png]]

- There are specific XML entities for some special characters:

```
<  :  &lt;
>  :  &gt;
'  :  &apost;
"  :  &quot;
&  :  &amp;
```
#### Grammar
- A set of rules that describe legal examples of a language, each consisting of a left and a right side
	- Left side specifies the rule’s name and is not part of the language itself
	- Right side describes the pattern of tokens that the rule specifies
		- This pattern goes from left to right and consists of `terminals, non terminals and qualifiers`
			- Terminals are tokens
			- Nonterminals are other rules
			- Qualifiers are represented by `|, *, ?, (, )`

![[docs/Images/Pasted image 20231003003608.png]]

- `|` means or
- `*` denotes something happens multiple times
- `?` means 0 or 1 times

#### Parsing
- Grammar is recursive. Rules can contain more rules, the result of which affects the rule before it.
- This correspondence can be represented with a data structure called a *parse tree*

![](docs/Images/Pasted%20image%2020231003014724.png)

- Parse output (this tree) is denoted in XML, kinda like HTML markup

![](docs/Images/Pasted%20image%2020231003014855.png)

#### Parser
- Accepts a stream of tokens as input and outputs a parse tree (XML)
- Algorithms used to create parse trees - *recursive descent parsing*
	- For each rule, there exists routines to compile those tokens into a parse tree
- Each `compilexxx` routine should get from the input, and handle, all the tokens that make up xxx, advance the tokenizer exactly beyond these tokens, and output the parse tree of xxx.

##### Example - Parsing `while`

- `while ( expression ) { statement* )`

![](docs/Images/Pasted%20image%2020231003015251.png)



## Jack Specification

### Grammar

![](docs/Images/figure_10.5.png)

```
'xxx' : represents language tokens that appear verbatim
xxx   : represents names of terminal and nonterminal elements
( )   : used for grouping
x | y : either x or y
x y   : x is followed by y
x ?   : x appears 0 or 1 times
x *   : x appears 0 or more times
```

### Syntax Analyser
- Performs tokenising and parsing
- Accepts a single command line arg

```bash
$ JackAnalyzer xxx.jack
```

## Jack Implementation
- Based on three modules
	- `JackAnalyzer`: main program that sets up and invokes the other modules
	- `JackTokenizer`: tokenizer
	- `CompilationEngine`: recursive top down parser

### JackTokenizer
- Ignores comments / whitespace
- Allows parser to access input stream one token at a time
- Parses and provides the *type* of each token

![](docs/Images/figure_wo_caption_10.7.png)

### CompilationEngine
- Emits a structured representation of the input source code wrapped in XML tags
- Once code generation has been introduced, instead of XML tags it will become VM code
- Gets input from the `JackTokenizer` and emits output to an XML file
	- Output is generated by a series of `compilexxx` routines, each of which are designed to handle of specific language constructs `xxx`
	- `compilexxx` is only called if the current token is `xxx`
- Some grammar rules don't have a corresponding compilation model
	- `type, className, subroutineName, varName, statement, subroutineCall`

#### Token Lookahead
- For each `compilexxx` behavior, the maximum recursive depth is 1, meaning the current token can indicate which routine to call next.
- **Exception**: Parsing a "term" in an expression or a subroutine call. Here, only the current token is often insufficient.

- **`y`**:
    - Recognize "y" as an identifier.
    - Peek at next token (it's "+").
    - Determine "y" is a standalone variable.

- `arr[5]`:
    - Recognize "arr" as an identifier.
    - Peek at next token (it's `[`).
    - Determine `arr[5]` is an array element.

- **`p.get(row)`**:
    - Recognize "p" as an identifier.
    - Peek at next token (it's ".").
    - Parse further to determine "`p.get(row)`" is a method call on the object "p"

- **`count()`**:
    - Recognize "count" as an identifier.
    - Peek at next token (it's "(").
    - Determine "count()" is a method call.

- **`Math.sqrt(dist)`**:
    - Recognize "Math" as an identifier.
    - Peek at next token (it's ".").
    - Parse further to determine "`Math.sqrt(dist)`" is a method call.

- **`2`**:
    - Recognize "2" as a constant. No ambiguity, so no lookahead needed.

- By peeping one token ahead, the parser can easily determine the nature and function of the current token within the expression.

![](docs/Images/figure_wo_caption_10.8.png)

### JackAnalyzer
- Main program that drives the syntax analysis process
	- Calls `JackTokenizer` and `CompilationEngine`
- For each `xxx.jack` file:
	1. Create a `JackTokenizer` from the `xxx.jack` input file
	2. Create an output file `xxx.xml`
	3. Uses the `JackTokenizer` and `CompilationEngine` to parse the input and write the parsed code to the output


##### Examples

![](docs/Images/Pasted%20image%2020231024182824.png)

![](docs/Images/Pasted%20image%2020231024183304.png)

