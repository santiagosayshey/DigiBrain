> [!motivation] The Search for Moral Evaluation
> 
> A fundamental challenge in ethics is determining **how to evaluate our actions**. We constantly make choices that affect ourselves and others, but what framework should guide these decisions? How can we objectively determine if an action is "good" or "right"? This question is essential because it underpins moral reasoning and ethical decision-making.
> 
> Key questions this framework addresses:
> 
> - How do we measure the moral worth of our actions?
> - What criteria should determine whether an action is ethically justified?
> - Is there an objective way to evaluate competing ethical claims?

> [!idea] Utilitarianism
> 
> Utilitarianism **evaluates actions based solely on their consequences**, specifically the amount of happiness or utility they produce. An action is right if it produces the greatest amount of good for the greatest number of people.
> 
> Core principles:
> 
> - **Consequentialism**: Only the outcomes of actions matter morally
> - **Welfarism**: The only relevant outcome is human welfare or happiness
> - **Impartiality**: Everyone's happiness counts equally
> 
> |Key Figures|Core Contribution|
> |---|---|
> |Jeremy Bentham|Original formulation focusing on quantity of pleasure|
> |John Stuart Mill|Quality distinction between "higher" and "lower" pleasures|
> |Peter Singer|Applied utilitarianism to modern ethical problems|

> [!idea] Extreme Utilitarianism
> 
> Extreme (or act) utilitarianism **evaluates each individual action solely on whether it maximizes utility in that specific instance**, regardless of rules, rights, or other considerations.
> 
> Characteristics:
> 
> - No action is inherently wrong; even traditionally immoral acts could be justified if producing maximum utility
> - Requires constant calculation of consequences for every decision
> - Can lead to counter-intuitive conclusions where individual rights are sacrificed for greater utility
> 
> Challenges:
> 
> - Practical difficulty in calculating all consequences
> - May justify actions most consider deeply immoral if they produce sufficient utility
> - Cannot account for special obligations (family, promises, etc.)

> [!idea] Restricted Utilitarianism
> 
> Restricted (or rule) utilitarianism **evaluates rules rather than individual actions**, advocating for following rules that tend to promote the greatest happiness when generally observed.
> 
> Key features:
> 
> - Focuses on rules that maximize utility when followed consistently
> - Acknowledges practical limitations in calculating consequences of every action
> - Preserves common moral intuitions about rights and duties
> 
> Benefits:
> 
> - More practical for everyday decision-making
> - Better aligns with common moral intuitions
> - Provides stable guidelines that protect individual rights while still focusing on well-being

> [!example] Promise-Keeping Dilemma
> 
> Imagine you've promised to meet a friend for coffee, but on your way, you encounter someone in need of immediate assistance that would make you miss your appointment.
> 
> Act utilitarian analysis:
> 
> - Evaluates this specific instance only
> - Breaking the promise is justified if helping the person in need produces more overall happiness
> - No inherent value in promise-keeping itself beyond its consequences
> 
> Rule utilitarian analysis:
> 
> - Considers the utility of following the rule "keep your promises" in society
> - While breaking the promise might maximize utility in this case, a society where promises are routinely broken would decrease overall happiness
> - Might justify keeping the promise unless the emergency is severe enough
> 
> This example highlights the key distinction: **act utilitarianism focuses on maximizing utility in each individual case, while rule utilitarianism considers what rules, when generally followed, would maximize utility across society.**

> [!consider] Optimism vs. Pessimism in Utilitarian Approaches
> 
> The divide between act and rule utilitarianism reveals differing assumptions about human moral capacity:
> 
> **Act Utilitarianism: The Optimistic View**
> 
> - Treats the moral world as "glass half full"
> - Trusts individuals to calculate consequences objectively in each situation
> - Assumes moral agents can recognize and pursue maximum utility without bias
> - Places faith in situational judgment over fixed principles
> 
> **Rule Utilitarianism: The Cautious View**
> 
> - Treats the moral world as "glass half empty"
> - Skeptical about humans' ability to calculate all consequences accurately
> - Acknowledges cognitive biases and limitations in moral reasoning
> - Provides standardized rules to compensate for flawed individual judgment
> 
> This distinction raises important questions about how much we should trust individual moral reasoning versus established principles, and whether human nature is fundamentally capable of consistent utilitarian calculation without the structure of rules.

> [!consider] Rule-Breaking for Greater Utility
> 
> A fundamental tension within utilitarianism emerges when following an established rule produces less utility than breaking it in a specific instance:
> 
> **The Rule-Breaking Dilemma**
> 
> - What happens when violating a generally beneficial rule would maximize happiness in a particular case?
> - Example: Lying is generally harmful, but what about a "white lie" that prevents significant suffering?
> - This tension exposes a potential inconsistency in rule utilitarianism's commitment to maximizing happiness
> 
> **Why Some Philosophers Favor Extreme (Act) Utilitarianism**
> 
> - Act utilitarianism avoids this contradiction by focusing solely on consequences in each specific case
> - It maintains philosophical consistency by never prioritizing rules over actual outcomes
> - Offers more flexibility to respond to unique circumstances where rules become counterproductive
> 
> This consideration highlights why philosophers like J.J.C Smart advocate for versions of act utilitarianismâ€”it provides a more consistent application of the core utilitarian principle of maximizing happiness without being constrained by rules that might, in some cases, work against that very goal.


