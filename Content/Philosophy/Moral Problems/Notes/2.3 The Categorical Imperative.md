> [!motivation] The Foundation of Morality
> 
> Why do we consider certain actions good or bad? Kant observed that traditional approaches to ethics failed to provide a reliable foundation:
> 
> - **Consequentialism** judges actions by their outcomes, but identical results can come from different moral intentions
> - **Emotivism** bases morality on feelings, but emotions vary between people and cultures
> - **Divine command** relies on religious authority, but this doesn't help those seeking rational justification
> 
> Kant sought a moral system based on reason alone - one that would apply to all rational beings and provide objective standards for judging actions regardless of their consequences or the actor's feelings.

> [!consider] Maxims and Imperatives
> 
> Kant's ethics centers on two key concepts that work together to determine moral worth:
> 
> - **Maxims**: The subjective principles behind our actions
>     - Your personal rule for what you're doing and why
>     - Examples: "I will lie when it benefits me" or "I will help others who need assistance"
>     - Maxims reveal the true moral character of an action
> - **Imperatives**: The commands that guide our actions
>     - **Hypothetical imperatives**: Conditional commands ("If you want X, do Y")
>     - **Categorical imperative**: Unconditional command that applies regardless of desires
> 
> The relationship between these concepts is crucial: The categorical imperative tests your maxims to determine if they're morally permissible. A moral action is one done from a maxim that passes the categorical imperative test.

> [!idea] The Categorical Imperative and Maxim Testing
> 
> Kant's categorical imperative provides a method for testing maxims:
> 
> **"Act only according to that maxim by which you can at the same time will that it should become a universal law."**
> 
> This means we test our maxims through two key questions:
> 
> 1. **Could my maxim work as a universal law?** A moral maxim must be logically consistent when universalized.
>     
> 2. **Would I rationally want my maxim to be universal?** A moral maxim should create a world we could rationally desire.
>     
> 
> For example, consider the maxim "I will make false promises when I need money":
> 
> - If universalized: Everyone makes false promises when they need money
> - Result: The practice of promising would collapse (contradiction)
> - Therefore: This maxim is immoral
> 
> Through this process, Kant provides an objective test of maxims that doesn't depend on outcomes or subjective feelings.

> [!example] Applying the Maxim Test
> 
> Let's examine how different maxims fare when subjected to the categorical imperative test:
> 
> |Maxim|If Universalized|Result|Why|
> |---|---|---|---|
> |"I will lie whenever convenient"|Everyone lies when convenient|Fails|Communication itself would break down|
> |"I will help others only when it benefits me"|Everyone helps others only when self-benefiting|Fails|Creates a world where help is unavailable when most needed|
> |"I will develop my talents only when profitable"|Everyone develops talents only when profitable|Fails|Contradicts our nature as rational beings with potential|
> |"I will respect others' autonomy"|Everyone respects others' autonomy|Passes|Creates a consistent world of mutual respect|
> 
> This test provides a powerful tool for distinguishing truly moral maxims from those that merely appear moral but cannot be consistently universalized. Unlike consequentialist approaches, Kant's framework evaluates the principle behind the action, not just its effects.