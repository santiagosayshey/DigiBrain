> [!motivation] Selecting Between Explanations
> A detective has three possible suspects for a crime. A scientist examines multiple hypotheses about climate change. A doctor considers different diagnoses for a set of symptoms.
> 
> These situations share a common challenge: **how do we choose between competing explanations?** When multiple explanations could account for our observations, we need systematic criteria to evaluate them.

> [!idea] Criteria for Evaluation
> We need a way to systematically evaluate competing explanations. These **criteria provide a framework for assessing the strength of potential explanations**, helping us select the most viable options from alternatives.
>
> | Criterion | Description | Example in Science |
> |-----------|-------------|---------------------------|
> | Testability | Explanation must generate specific predictions that can be proven false | Einstein's theory predicted light bending around stars during solar eclipse |
> | Mechanism | Must describe a concrete process showing how causes lead to effects | Germ theory explains disease transmission through specific microorganisms |
> | Predictive Power | Should successfully predict phenomena not yet observed when formulated | Mendeleev's periodic table predicted properties of undiscovered elements |
> | Explanatory Scope | Should explain a broad range of related phenomena, not just isolated cases | Maxwell's equations explain electricity, magnetism, and light as one phenomenon |
> | Ockham's Razor | Choose the explanation with fewest assumptions that explains all evidence | Copernican model eliminated need for complex epicycles in planetary motion |
> | Conservatism | New explanation should preserve successful aspects of existing theories | Quantum mechanics reduces to classical mechanics at large scales |
>
> These criteria often trade off against each other - an explanation might excel at some while performing poorly on others.

> [!example] Testing
> 
> Testing means **checking if an explanation can be proven false.** When evaluating explanations, we assess:
> 
> Does the explanation make claims that could be wrong?
> 
> - "All swans are white" can be tested - finding one black swan proves it false
> - "Everything happens for a reason" cannot be tested - no observation could prove it wrong
> 
> General method for testing:
> 
> 1. Deduce specific predictions from the explanation
> 2. Design observations/experiments that could prove these predictions false
> 3. Define what evidence would count as falsification
> 4. Look for cases where predictions fail
> 
> For example, consider the claim "stress causes ulcers":
> 
> - This explanation is testable: we can look for ulcers in stressed vs non-stressed patients
> - We can also check if reducing stress cures ulcers
> - Research following these tests actually showed this explanation was wrong - most ulcers are caused by bacteria
> 
> This demonstrates how testability helps us evaluate explanations - good explanations must risk being proven wrong by making specific, checkable claims.


> [!example] Mechanism
> 
> Mechanism means **explaining HOW something works, not just that it works.** When evaluating explanations, we assess:
> 
> Does the explanation provide a concrete process?
> - "Objects fall because of gravity" states THAT they fall
> - "Objects fall because mass warps spacetime" explains HOW they fall
> 
> General method for evaluating mechanisms:
> 1. Identify what physical/causal process is being claimed
> 2. Check if it explains how each step produces the next
> 3. Verify no "magic" steps are hidden in the explanation
> 4. Ensure the mechanism matches known physics/chemistry/etc.
> 
> For example, explaining how a car moves:
> - Poor mechanism: "The engine makes it go"
> - Good mechanism: "Fuel combustion drives pistons that turn the crankshaft that spins the wheels"
> 
> This demonstrates how mechanism helps evaluate explanations - good explanations must detail the actual process producing the effect, not just claim a connection exists.

