> [!motivation] Selecting Between Explanations
> A detective has three possible suspects for a crime. A scientist examines multiple hypotheses about climate change. A doctor considers different diagnoses for a set of symptoms.
> 
> These situations share a common challenge: **how do we choose between competing explanations?** When multiple explanations could account for our observations, we need systematic criteria to evaluate them.

> [!idea] Criteria for Evaluation
> We need a way to systematically evaluate competing explanations. These **criteria provide a framework for assessing the strength of potential explanations**, helping us select the most viable options from alternatives.
>
> | Criterion | Description | Example in Science |
> |-----------|-------------|---------------------------|
> | Testability | Explanation must generate specific predictions that can be proven false | Einstein's theory predicted light bending around stars during solar eclipse |
> | Mechanism | Must describe a concrete process showing how causes lead to effects | Germ theory explains disease transmission through specific microorganisms |
> | Predictive Power | Should successfully predict phenomena not yet observed when formulated | Mendeleev's periodic table predicted properties of undiscovered elements |
> | Explanatory Scope | Should explain a broad range of related phenomena, not just isolated cases | Maxwell's equations explain electricity, magnetism, and light as one phenomenon |
> | Ockham's Razor | Choose the explanation with fewest assumptions that explains all evidence | Copernican model eliminated need for complex epicycles in planetary motion |
> | Conservatism | New explanation should preserve successful aspects of existing theories | Quantum mechanics reduces to classical mechanics at large scales |
>
> These criteria often trade off against each other - an explanation might excel at some while performing poorly on others.

> [!example] Testing
> 
> Testing means **checking if an explanation can be proven false.** When evaluating explanations, we assess:
> 
> Does the explanation make claims that could be wrong?
> 
> - "All swans are white" can be tested - finding one black swan proves it false
> - "Everything happens for a reason" cannot be tested - no observation could prove it wrong
> 
> General method for testing:
> 
> 1. Deduce specific predictions from the explanation
> 2. Design observations/experiments that could prove these predictions false
> 3. Define what evidence would count as falsification
> 4. Look for cases where predictions fail
> 
> For example, consider the claim "stress causes ulcers":
> 
> - This explanation is testable: we can look for ulcers in stressed vs non-stressed patients
> - We can also check if reducing stress cures ulcers
> - Research following these tests actually showed this explanation was wrong - most ulcers are caused by bacteria
> 
> This demonstrates how testability helps us evaluate explanations - good explanations must risk being proven wrong by making specific, checkable claims.


> [!example] Mechanism
> 
> Mechanism means **explaining HOW something works, not just that it works.** When evaluating explanations, we assess:
> 
> Does the explanation provide a concrete process?
> - "Objects fall because of gravity" states THAT they fall
> - "Objects fall because mass warps spacetime" explains HOW they fall
> 
> General method for evaluating mechanisms:
> 1. Identify what physical/causal process is being claimed
> 2. Check if it explains how each step produces the next
> 3. Verify no "magic" steps are hidden in the explanation
> 4. Ensure the mechanism matches known physics/chemistry/etc.
> 
> For example, explaining how a car moves:
> - Poor mechanism: "The engine makes it go"
> - Good mechanism: "Fuel combustion drives pistons that turn the crankshaft that spins the wheels"
> 
> This demonstrates how mechanism helps evaluate explanations - good explanations must detail the actual process producing the effect, not just claim a connection exists.

> [!example] Predictive Power
> 
> Predictive power means **an explanation should predict phenomena we have not yet observed.** When evaluating explanations, we assess:
> 
> Does the explanation predict new things beyond what it was created to explain?
> 
> - Mendeleev's periodic table predicted new elements
> - "Everything is made of water" makes no new predictions
> 
> General method for evaluating predictive power:
> 
> 1. Identify predictions that go beyond original observations
> 2. Check if these are genuinely new phenomena
> 3. Ensure predictions are not just restating known facts
> 4. Compare predicted vs observed cases
> 
> For example, Einstein's General Relativity:
> 
> - Created to explain gravity and acceleration
> - Predicted light bending around the sun
> - Predicted black holes
> - Predicted gravitational waves
> 
> This demonstrates how predictive power helps evaluate explanations - good explanations should tell us about new phenomena, not just explain what we already know.

> [!example] Explanatory Scope
> 
> Explanatory scope means **an explanation should account for a broad range of related phenomena.** When evaluating explanations, we assess:
> 
> Does the explanation unify seemingly different phenomena?
> 
> - Maxwell's equations unified electricity, magnetism, and light
> - "Plants grow towards light because they like it" only explains one behavior
> 
> General method for evaluating scope:
> 
> 1. List all phenomena the explanation claims to cover
> 2. Check if these phenomena are genuinely related
> 3. Verify no ad-hoc additions are needed for each case
> 4. Look for phenomena it should explain but cannot
> 
> For example, Darwin's natural selection:
> 
> - Explains species diversity
> - Explains adaptation to environments
> - Explains shared traits between species
> - Explains fossil record patterns
> 
> This demonstrates how scope helps evaluate explanations - good explanations should unify many phenomena under a single framework rather than requiring separate explanations for each case.

> [!example] Ockham's Razor
> 
> Ockham's Razor means **choose the simplest explanation that accounts for all evidence.** When evaluating explanations, we assess:
> 
> Does the explanation avoid unnecessary assumptions?
> - Copernican model: planets orbit sun in circles
> - Ptolemaic model: planets orbit earth in circles within circles
> 
> General method for evaluating simplicity:
> 1. List all assumptions the explanation requires
> 2. Check if each assumption is necessary
> 3. Compare number of assumptions between competing explanations
> 4. Look for ways to reduce complexity while maintaining explanatory power
> 
> For example, explaining planetary motion:
> - Complex: Each planet needs unique epicycles and adjustments
> - Simple: All planets follow same physical laws around sun
> 
> This demonstrates how Ockham's Razor helps evaluate explanations - good explanations should not multiply assumptions beyond necessity.

> [!example] Conservatism
> 
> Conservatism means **new explanations should preserve what works in existing theories.** When evaluating explanations, we assess:
> 
> Does the explanation maintain successful aspects of current knowledge?
> 
> - Quantum mechanics reduces to classical mechanics at large scales
> - "Everything we know about physics is wrong" rejects proven successes
> 
> General method for evaluating conservatism:
> 
> 1. Identify what existing theories explain successfully
> 2. Check if new explanation preserves these successes
> 3. Verify changes are only made where needed
> 4. Ensure conflicts with current knowledge are justified
> 
> For example, Einstein's relativity:
> 
> - Keeps Newton's laws for everyday speeds
> - Only differs significantly at very high speeds
> - Explains new phenomena while preserving old successes
> 
> This demonstrates how conservatism helps evaluate explanations - good explanations should build on proven knowledge rather than needlessly replacing it.