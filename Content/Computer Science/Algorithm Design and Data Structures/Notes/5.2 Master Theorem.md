## Divide and Conquer
- Create **a** subproblems, each having size **n/b**
- Call the procedure recursively on each subproblem
- Combine th results from the subproblems

![[docs/Images/Pasted image 20230327110037.png]]


![[docs/Images/Pasted image 20230327110507.png]]
![[docs/Images/Pasted image 20230327110513.png]]

![[docs/Images/Pasted image 20230327110556.png]]

The Master Theorem is a method used in computer science to analyze the running time of recursive algorithms. It provides a simple way to determine the "big O" notation, which describes the upper bound of an algorithm's growth in terms of its input size.

The Master Theorem can be applied to algorithms that follow the form:

T(n) = a * T(n/b) + f(n)

where:

-   T(n) is the running time of the algorithm for an input of size n
-   a is the number of subproblems the algorithm divides the input into
-   n/b represents the size of each subproblem (assuming all subproblems are of equal size)
-   f(n) is the time spent on work outside of the recursive calls, such as combining the results of the subproblems
- d is the degree of the computational complexity of the final result

The Master Theorem compares f(n) to n^(log_b(a)) and, based on their relationship, provides three cases to determine the overall complexity of the algorithm:

1.  If f(n) = O(n^(log_b(a) - e)) for some constant e > 0, then T(n) = O(n^(log_b(a))).
2.  If f(n) = O(n^(log_b(a))), then T(n) = O(n^(log_b(a)) * log(n)).
3.  If f(n) = O(n^(log_b(a) + e)) for some constant e > 0, then T(n) = O(f(n)).

In simpler terms, the Master Theorem allows you to determine the running time of a recursive algorithm by examining the relationship between the time spent on non-recursive work and the time spent on recursive work.
