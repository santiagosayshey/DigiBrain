> [!motivation] The Illusion of Abstraction
> When writing programs, we often operate under a simplified, idealized model of how the underlying hardware works. We **assume dedicated resources, uniform memory access, and serial execution. However, the reality is far more complex.** 
> 
> Consider a basic program that calculates the hypotenuse of a right triangle:
> 
> ```python
> basesquared = base*base
> sidesquare = side*side
> hypotenuse = sqrt(basesquared+sidesquare)
> ```
>
> At first glance, it seems straightforward: calculate the squares of the base and side, then find the square root of their sum. But the actual execution depends on the system's architecture, which can vary greatly from our assumptions.
>
> | Model     | Reality      |
> | --------- | ------------ |
> | Dedicated Hardware | Shared Hardware |
> | Uniform Memory     | Non-Uniform Memory |
> | Serial Execution   | Superscalar Execution |
> 
> This raises a crucial question: **what happens when our virtualization breaks down and our programs are exposed to the mercy of the hardware?** Micro-architectural attacks exploit these discrepancies, undermining the security assumptions we rely on.

> [!idea] Cache-Based Side-Channel Attacks: Exploiting the Gap Between Abstraction and Reality
> Cache-based side-channel attacks, such as Prime+Probe and Flush+Reload, exploit the difference between the abstract view of memory and the reality of how caches work, allowing an attacker to infer sensitive information about other processes.
>
> **Abstraction**: Programs assume a uniform memory model, where all memory appears to be a single, fast storage area. The cache virtualizes fast memory access by storing frequently used data closer to the CPU. Programs operate as if they have only one type of memory, unaware that data comes from multiple levels of cache and main memory.
>
> **Reality**: In actual hardware, the cache sits between the CPU and main memory as a separate, intermediate layer. Data moves between these layers based on usage patterns and access times. The cache is physically distinct from the CPU and main memory.
>
> This distinction can be exploited through various cache-based attacks:
>
> 1. **Prime+Probe**: The attacker fills a cache set with their own data (prime), waits for the victim to access memory, and then measures access times to their data (probe) to infer the victim's cache usage.
>
> 2. **Flush+Reload**: The attacker targets shared memory pages, such as shared libraries. They flush a line from the cache using a special instruction, wait for the victim to access memory, and then measure the time to reload the line. Fast reloads indicate the victim accessed the line.
>
> 3. **Evict+Time**: The attacker measures the execution time of a victim's function with different cache states, inferring sensitive information from timing differences.
>
> These attacks exploit the gap between the abstract, uniform memory model assumed by programs and the reality of a separate, shared cache layer. They allow an attacker to break the expected isolation between processes and infer sensitive data by indirectly observing cache usage patterns.
>
> This highlights the importance of considering hardware-level details and potential side-channel attacks when designing secure systems, as the abstractions we rely on may not always hold in the face of shared hardware resources and clever exploitation techniques.

> [!example] Flush+Reload Attack in Action
> Suppose we have a victim process that uses a shared cryptographic library. The attacker wants to determine which functions in the library are being called, hoping to infer sensitive information about the victim's cryptographic operations.
>
> Here's how a Flush+Reload attack could unfold:
>
> 1. **Identify Shared Library**: The attacker identifies a cryptographic library used by the victim process, which is loaded into memory shared by both the attacker and victim.
>
> 2. **Flush Targeted Lines**: The attacker flushes specific cache lines associated with functions of interest in the shared library, using a special processor instruction like `clflush`.
>
> 3. **Wait for Victim**: The attacker waits for a short period to allow the victim process to execute and potentially call functions from the shared library.
>
> 4. **Reload and Time**: The attacker reloads the previously flushed cache lines and measures the time taken for each reload.
>    - If the victim called a function, its cache line will be fast to reload (cache hit).
>    - If the victim didn't call a function, its cache line will be slow to reload (cache miss).
>
> 5. **Infer Victim's Behavior**: By observing which cache lines are fast to reload, the attacker can infer which functions in the shared library were called by the victim process.
>
> This example demonstrates how the Flush+Reload attack exploits shared memory and the ability to manipulate cache state to break process isolation and infer sensitive information about a victim's behavior.
>
> It highlights the need to consider the security implications of shared resources, such as shared libraries, and the importance of mitigation techniques like address space layout randomization (ASLR) and avoiding the use of shared memory for sensitive data.
