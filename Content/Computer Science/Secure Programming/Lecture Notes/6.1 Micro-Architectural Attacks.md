> [!motivation] The Illusion of Abstraction
> When writing programs, we often operate under a simplified, idealized model of how the underlying hardware works. We **assume dedicated resources, uniform memory access, and serial execution. However, the reality is far more complex.** 
> 
> Consider a basic program that calculates the hypotenuse of a right triangle:
> 
> ```python
> basesquared = base*base
> sidesquare = side*side
> hypotenuse = sqrt(basesquared+sidesquare)
> ```
>
> At first glance, it seems straightforward: calculate the squares of the base and side, then find the square root of their sum. But the actual execution depends on the system's architecture, which can vary greatly from our assumptions.
>
> | Model     | Reality      |
> | --------- | ------------ |
> | Dedicated Hardware | Shared Hardware |
> | Uniform Memory     | Non-Uniform Memory |
> | Serial Execution   | Superscalar Execution |
> 
> This raises a crucial question: **what happens when our virtualization breaks down and our programs are exposed to the mercy of the hardware?** Micro-architectural attacks exploit these discrepancies, undermining the security assumptions we rely on.

> [!idea] Cache-Based Side-Channel Attacks: Exploiting the Gap Between Abstraction and Reality
> Cache-based side-channel attacks, such as Prime+Probe and Flush+Reload, exploit the difference between the abstract view of memory and the reality of how caches work, allowing an attacker to infer sensitive information about other processes.
>
> **Abstraction**: Programs assume a uniform memory model, where all memory appears to be a single, fast storage area. The cache virtualizes fast memory access by storing frequently used data closer to the CPU. Programs operate as if they have only one type of memory, unaware that data comes from multiple levels of cache and main memory.
>
> **Reality**: In actual hardware, the cache sits between the CPU and main memory as a separate, intermediate layer. Data moves between these layers based on usage patterns and access times. The cache is physically distinct from the CPU and main memory.
>
> This distinction can be exploited through various cache-based attacks:
>
> 1. **Prime+Probe**: The attacker fills a cache set with their own data (prime), waits for the victim to access memory, and then measures access times to their data (probe) to infer the victim's cache usage.
>
> 2. **Flush+Reload**: The attacker targets shared memory pages, such as shared libraries. They flush a line from the cache using a special instruction, wait for the victim to access memory, and then measure the time to reload the line. Fast reloads indicate the victim accessed the line.
>
> 3. **Evict+Time**: The attacker measures the execution time of a victim's function with different cache states, inferring sensitive information from timing differences.
>
> These attacks exploit the gap between the abstract, uniform memory model assumed by programs and the reality of a separate, shared cache layer. They allow an attacker to break the expected isolation between processes and infer sensitive data by indirectly observing cache usage patterns.
>
> This highlights the importance of considering hardware-level details and potential side-channel attacks when designing secure systems, as the abstractions we rely on may not always hold in the face of shared hardware resources and clever exploitation techniques.

> [!example] Flush+Reload Attack in Action
> Suppose we have a victim process that uses a shared cryptographic library. The attacker wants to determine which functions in the library are being called, hoping to infer sensitive information about the victim's cryptographic operations.
>
> Here's how a Flush+Reload attack could unfold:
>
> 1. **Identify Shared Library**: The attacker identifies a cryptographic library used by the victim process, which is loaded into memory shared by both the attacker and victim.
>
> 2. **Flush Targeted Lines**: The attacker flushes specific cache lines associated with functions of interest in the shared library, using a special processor instruction like `clflush`.
>
> 3. **Wait for Victim**: The attacker waits for a short period to allow the victim process to execute and potentially call functions from the shared library.
>
> 4. **Reload and Time**: The attacker reloads the previously flushed cache lines and measures the time taken for each reload.
>    - If the victim called a function, its cache line will be fast to reload (cache hit).
>    - If the victim didn't call a function, its cache line will be slow to reload (cache miss).
>
> 5. **Infer Victim's Behavior**: By observing which cache lines are fast to reload, the attacker can infer which functions in the shared library were called by the victim process.
>
> This example demonstrates how the Flush+Reload attack exploits shared memory and the ability to manipulate cache state to break process isolation and infer sensitive information about a victim's behavior.
>
> It highlights the need to consider the security implications of shared resources, such as shared libraries, and the importance of mitigation techniques like address space layout randomization (ASLR) and avoiding the use of shared memory for sensitive data.

> [!idea] Cache Occupancy Attack: Exploiting Limited Cache Capacity
> A cache occupancy attack exploits the limited size of the cache to infer information about the memory usage patterns of other processes running on the same hardware.
>
> **Cache as a Shared Resource**: Caches have a fixed size and are shared among all processes running on a CPU core. When a process accesses memory, it brings data into the cache, potentially evicting data used by other processes.
>
> **Observing Eviction Patterns**: An attacker can fill the cache with their own data and then monitor which parts of their data are evicted over time. If a part of the attacker's data is evicted, it suggests that another process accessed memory that mapped to the same cache location.
>
> **Inferring Memory Usage**: By carefully selecting memory locations to fill the cache and analyzing which locations are evicted, an attacker can infer the memory usage patterns of other processes. This can leak information about the victim's activities, such as which code paths are executed or which data structures are accessed.
>
> The cache occupancy attack exploits the limited size of the cache and its shared nature among processes. It allows an attacker to indirectly observe the memory usage of other processes by monitoring evictions from the cache.
>
> This attack highlights the importance of considering cache side-channel attacks and the potential information leakage through shared hardware resources. Developers should be aware of these risks and take appropriate measures to mitigate them, such as using constant-time algorithms and avoiding secret-dependent memory accesses.

> [!example] Cache Occupancy Attack on Web Browsing
> Suppose we have a victim process that is browsing websites using a web browser. Each website consists of multiple resources (HTML, CSS, JavaScript, images) that are loaded into memory and cached by the browser.
>
> An attacker wants to infer which website the victim is visiting by analyzing the cache usage patterns. Here's how the attack could proceed:
>
> 1. **Profile Websites**: The attacker profiles a set of potential websites by visiting them and measuring the cache footprint of each site. They record which cache sets are used by each website's resources.
>
> 2. **Prime the Cache**: The attacker fills the cache sets that are expected to be used by the target websites, ensuring that any previously cached data is evicted.
>
> 3. **Wait for Victim**: The attacker waits for the victim to browse to one of the profiled websites. As the victim's browser loads the website's resources, it will evict some of the attacker's data from the cache.
>
> 4. **Probe the Cache**: The attacker measures the access times for the cache sets associated with each profiled website.
>    - Cache sets that were used by the victim's website will contain the victim's data, resulting in slower access times (cache misses) for the attacker.
>    - Cache sets not used by the victim's website will still contain the attacker's data, resulting in faster access times (cache hits).
>
> 5. **Infer Visited Website**: By comparing the pattern of cache hits and misses to the profiles recorded in step 1, the attacker can infer which website the victim visited.
>
> This example demonstrates how a cache occupancy attack can be used to break the confidentiality of a user's web browsing history by exploiting the shared, limited nature of the cache.
>
> It highlights the importance of considering cache side-channels in web browsers and the need for mitigation techniques like cache isolation, randomization, and reduced timer precision to prevent attackers from inferring sensitive information through cache usage patterns.

Certainly! Let's create a new consider callout that introduces the concept of conditional speculative execution with branches, using pseudocode to illustrate the problem.

> [!consider] Conditional Speculative Execution with Branches
> Modern processors employ speculative execution to improve performance by predicting the outcome of branches and executing instructions ahead of time. However, this feature can be exploited to leak sensitive information through side channels.
>
> Consider the following pseudocode:
>
> ```
> if (x < array1_size) {
>     y = array2[array1[x] * 256];
> }
> ```
>
> Here's what happens during speculative execution:
>
> 1. The processor predicts the outcome of the branch condition `x < array1_size` based on previous executions and starts speculatively executing the code inside the if statement.
>
> 2. If the predicted outcome is correct (i.e., `x` is indeed less than `array1_size`):
>    - The processor continues executing the speculatively executed instructions.
>    - The value at `array1[x]` is used to calculate the index into `array2`, and the corresponding value is loaded into `y`.
>
> 3. If the predicted outcome is incorrect (i.e., `x` is greater than or equal to `array1_size`):
>    - The processor discards the speculatively executed instructions and their results.
>    - The value of `y` remains unchanged.
>
> The problem arises when the speculatively executed instructions have observable side effects, such as loading data into the cache. An attacker can exploit this by:
>
> 1. Manipulating the values of `x` and `array1_size` to force the processor to speculatively execute the code inside the if statement with an out-of-bounds value of `x`.
>
> 2. Measuring the cache access times to determine which elements of `array2` were loaded into the cache during the speculative execution.
>
> 3. Inferring the value of `array1[x]` based on which elements of `array2` were accessed, even though the speculative execution was ultimately discarded.
>
> This exploits the fact that while the speculative execution is discarded, its side effects on the cache are not reverted, allowing the attacker to leak sensitive information.
>
> Mitigating this vulnerability requires careful design of hardware and software to prevent sensitive data from being accessed or leaked through side channels during speculative execution.
