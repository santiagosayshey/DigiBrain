> [!motivation] The Illusion of Abstraction
> When writing programs, we often operate under a simplified, idealized model of how the underlying hardware works. We **assume dedicated resources, uniform memory access, and serial execution. However, the reality is far more complex.** 
> 
> Consider a basic program that calculates the hypotenuse of a right triangle:
> 
> ```python
> basesquared = base*base
> sidesquare = side*side
> hypotenuse = sqrt(basesquared+sidesquare)
> ```
>
> At first glance, it seems straightforward: calculate the squares of the base and side, then find the square root of their sum. But the actual execution depends on the system's architecture, which can vary greatly from our assumptions.
>
> | Model     | Reality      |
> | --------- | ------------ |
> | Dedicated Hardware | Shared Hardware |
> | Uniform Memory     | Non-Uniform Memory |
> | Serial Execution   | Superscalar Execution |
> 
> This raises a crucial question: **what happens when our virtualization breaks down and our programs are exposed to the mercy of the hardware?** Micro-architectural attacks exploit these discrepancies, undermining the security assumptions we rely on.

> [!idea] Cache Reload Attack: Exploiting Shared Resources
> A cache reload attack exploits the shared nature of the CPU cache to infer sensitive information about other processes running on the same hardware.
>
> In modern systems, the CPU cache is a small, fast memory layer that stores recently accessed data to speed up subsequent accesses. This cache is typically shared among all processes running on a CPU core.
>
> The attack works by measuring the time it takes to access specific memory locations. If the data is already in the cache (a cache hit), the access will be fast. If the data is not in the cache (a cache miss), it must be fetched from slower main memory, resulting in a measurable delay.
>
> By carefully selecting memory locations and repeatedly measuring access times, an attacker can determine which memory locations are being accessed by other processes. This is possible because when a process accesses data, it is loaded into the shared cache, making it faster to access for all processes.
>
> Here's a simplified example of how a cache reload attack might work:
>
> 1. The attacker identifies a memory location that may contain sensitive data used by the target process.
> 2. The attacker measures the time to access this memory location, establishing a baseline for a cache miss.
> 3. The attacker waits for the target process to potentially access the sensitive data.
> 4. The attacker measures the access time again. If it is significantly faster (a cache hit), the attacker can infer that the target process accessed the data, as it is now in the shared cache.
>
> By repeating this process for different memory locations and observing patterns over time, the attacker can gather information about the internal workings and data of the target process, breaking the expected isolation between processes.
>
> The cache reload attack demonstrates how the abstraction of isolated processes can be violated by exploiting the shared nature of hardware resources like the CPU cache. It highlights the need for careful consideration of hardware-level details when reasoning about system security.

This callout aims to strike a balance between the abstraction and the technical details, providing a more concrete example of how a cache reload attack might be carried out while still emphasizing the broader concept of breaking process isolation through shared hardware resources. Let me know if this aligns better with what you had in mind.

