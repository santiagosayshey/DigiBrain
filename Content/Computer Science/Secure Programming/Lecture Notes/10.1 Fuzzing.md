> [!motivation] Why Fuzzing Matters
> - Traditional software testing often **misses edge cases** and vulnerabilities
> - Programs that parse files or process complex input data are particularly vulnerable
> - Any crash indicates a potential bug, though not all bugs are exploitable
> - Need for systematic approaches to find unintended program states


> [!idea] Fuzzing Fundamentals
> Fuzzing is the process of **finding program bugs by feeding random or unexpected data**
> 
> Core Strategies:
> 
> | Strategy | Description | Key Advantage | Main Limitation | Best Use Case | Tools |
> |----------|-------------|---------------|-----------------|---------------|--------|
> | Mutation-based | Takes existing valid inputs and applies random mutations (bit flips, byte changes, boundary values) | Simple to implement, fast to execute, requires minimal understanding of input format | Quality heavily depends on initial corpus, may miss deeply nested bugs, shallow coverage with checksums | File format fuzzing, network protocols with known good inputs | AFL (basic mode), radamsa, zzuf |
> | Generation-based | Creates inputs from scratch using format specifications, grammars, or protocols | Deep coverage, can test complex input validation, finds semantic bugs | Complex setup, requires detailed format knowledge, slower execution | Complex file formats, network protocols, programming languages | Peach Fuzzer, Sulley, Syzkaller |
> | Coverage-guided | Uses code coverage data to guide input generation towards unexplored code paths | Efficiently finds new program states, systematic exploration, combines well with other methods | Resource intensive, requires instrumentation, may miss bugs in covered code | Any target where source/binary instrumentation is possible | AFL++, libFuzzer, honggfuzz |
> 
> **Process Goals**:
> - Explore large parts of program state space
> - Identify unintended states through crashes
> - Find potential security vulnerabilities
> - Test error handling capabilities
> 
> **Key Considerations**:
> - Input format complexity
> - Available program source/binary
> - Testing time constraints
> - Resource availability
> - Security requirements

> [!example] Mutation-Based Fuzzing in Action
> Consider fuzzing a PDF reader:
> 1. Start with collection of valid PDF files
> 2. For each test:
>    - Pick a PDF randomly from collection
>    - Change random bytes (e.g., flip header values, modify object lengths)
>    - Feed to PDF reader
> 3. Monitor for crashes
> 
> Real outcome: Microsoft found major vulnerabilities in Adobe Reader using this approach - changing random bytes in valid PDFs revealed parser bugs that could lead to code execution

> [!example] Generation-Based Fuzzing in Action
> Testing a SQL database server:
> 1. Define SQL query structure (SELECT, FROM, WHERE, etc.)
> 2. Generate queries following proper syntax:
>    - Mix different clause combinations
>    - Create complex nested queries
>    - Include various data types
> 3. Send to database server
> 
> Each query is valid SQL syntax but tests unusual combinations - like deeply nested subqueries or complex joins that might trigger memory issues or logic bugs

> [!example] Coverage-Guided Fuzzing in Action
> Fuzzing an image processing library:
> 1. Start with basic PNG file
> 2. Fuzzer notices most code handles standard PNG chunks
> 3. When a mutation hits unusual chunk type:
>    - Tool detects new code path executed
>    - Keeps and modifies this test case further
>    - Discovers more paths in error handling code
> 4. Eventually finds vulnerability in rarely-used decompression path
> 
> The fuzzer automatically focuses on mutations that trigger new behaviors, rather than repeatedly testing already-covered code paths

> [!example] Basic Fuzzing Implementation
> Simple file fuzzing example:
> ```bash
> cat /dev/random | head -c 512 >> rand.jpeg; open rand.jpeg
> ```
> **How it works**:
> 1. Generates random data stream
> 2. Takes first 512 bytes
> 3. Appends to JPEG file
> 4. Attempts to open resulting file
> 
> **Better Approaches**:
> - Randomly corrupt real JPEG files
> - Reference JPEG spec for "JPEG-looking" data
> - Measure parser coverage during testing

> [!idea] Mutation Based Fuzzing
> **Process**:
> 1. Collect corpus of valid input files
> 2. Apply random mutations:
>    - Bit flips
>    - Integer increments/decrements
>    - Boundary value substitution
>    - Special character insertion
> 
> **Characteristics**:
> - Simple setup and execution
> - Uses off-the-shelf tools
> - Success depends on initial corpus quality
> - May have shallow coverage for formats with checksums
> 
> **Real-World Success**:
> Charlie Miller's 2010 PDF fuzzer found 64 exploitable crashes using simple mutations:
> ```python
> numwrites = random.randrange(math.ceil((float(len(buf)) / FuzzFactor))) + 1
> for j in range(numwrites):
>     rbyte = random.randrange(256)
>     rn = random.randrange(len(buf))
>     buf[rn] = "%c"%(rbyte)
> ```

> [!idea] Generation Based Fuzzing
> **Core Process**:
> - Convert input format specifications into generation procedures
> - Generate test cases with random perturbations
> - Run program and check for crashes
> - Iterate and refine
> 
> **Characteristics**:
> - Deeper coverage through format knowledge
> - Domain-specific implementations
> - Requires significant setup effort
> - Not limited by input format complexity

> [!example] Syzkaller Implementation
> **Key Features**:
> - Kernel system call fuzzer
> - Generates syscall sequences from descriptions
> - Runs tests in VM environment
> - Detects potential LPE vulnerabilities
> 
> ```go
> # Example syscall description
> open$proc(file ptr[in, string[proc_file]], flags flags[open_flags], mode const[0]) fd
> ```

> [!idea] Coverage Based Fuzzing
> **Core Concept**: Use code coverage as feedback for fuzzing
> 
> **Coverage Types**:
> - Basic block coverage
> - Edge coverage
> - Path coverage
> 
> **Benefits**:
> - Finds new program states efficiently
> - Combines well with other strategies
> - Proven track record
> 
> **Limitations**:
> - Can't bypass strong checksums
> - Misses certain bug types (e.g., race conditions)

> [!example] American Fuzzy Lop (AFL)
> **Workflow**:
> 1. Compile with coverage instrumentation
> 2. Trim test cases for efficiency
> 3. Mutate files in queue
> 4. Add cases that find new coverage
> 5. Iterate process
> 
> **Key Innovation**: Uses program behavior feedback to guide fuzzing process

> [!example] Fuzzilli
> **Characteristics**:
> - JavaScript engine fuzzer
> - Uses intermediate language (IL)
> - Fuzzes IL instead of raw JavaScript
> 
> ```javascript
> // Example generated test case
> function v0(v1) { 
>   try { 
>     new ArrayBuffer(v1); 
>   } catch(v2) {} 
> }
> v0(0x1000000000000);
> ```

> [!consider] Software Testing Integration
> Three key testing types that complement fuzzing:
> 
> **Unit Tests**:
> - Test individual components
> - Cover error handling
> - Verify expected behavior
> 
> **Regression Tests**:
> - Prevent bug reintroduction
> - "If you don't run them, attackers will"
> 
> **Integration Tests**:
> - Verify component interactions
> - Test system-level behavior
> 
> **General Tips**:
> - Use memory-safe languages where possible
> - Document threat models early
> - Design APIs for safe usage by default
> - Treat all external input as adversarial
> - Maintain consistent coding style