> [!motivation] The Need for Probabilistic Classification
> 
> Many real-world classification problems require more than just a yes/no decision - they need an assessment of certainty or risk.
> 
> **Limitations of linear models for classification:**
> 
> - Linear models produce unbounded outputs that don't naturally represent probabilities
> - Direct thresholding of raw scores doesn't provide confidence measures
> - Decision-making often requires knowing not just the classification but also its likelihood
> 
> Consider medical diagnosis, fraud detection, or customer churn prediction - in these cases, knowing that a patient has a 95% chance of having a condition provides much more actionable information than simply being told "positive" or "negative" without any confidence measure.
> 
> An ideal classification approach would combine the simplicity and interpretability of linear models with the ability to output well-calibrated probabilities that can inform decision-making and risk assessment.

> [!idea] Logistic Regression
> 
> Logistic Regression transforms a linear model into a probabilistic classifier by applying the sigmoid function to the weighted sum of inputs.
> 
> **Core mechanism:**
> 
> - Computes a linear combination of input features: $z = \theta^T x = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + ... + \theta_n x_n$
> - Transforms this score into a probability using the sigmoid function: $\hat{p} = \sigma(z) = \frac{1}{1 + e^{-z}}$
> - Makes predictions using a threshold (typically 0.5): $\hat{y} = 1$ if $\hat{p} \geq 0.5$, otherwise $\hat{y} = 0$
> 
> **Key properties:**
> 
> - The sigmoid function maps any real number to a value between 0 and 1
> - When input is 0, output is exactly 0.5
> - Positive inputs produce probabilities above 0.5, negative inputs below 0.5
> - The steepness of the function in the middle creates a decision boundary
> 
> **Mathematical interpretation:**
> 
> - The model estimates log-odds (logit) of the positive class
> - The coefficients represent the change in log-odds when a feature increases by one unit
> - Positive coefficients increase the probability of the positive class
> - Negative coefficients decrease the probability of the positive class
> 
> Despite its name, Logistic Regression is a classification model, not a regression model. It serves as the foundation for many probabilistic classification approaches and can be extended to multi-class problems through techniques like one-vs-rest classification.