> [!motivation] Single is Too Simple
>
> Single-layer perceptrons, composed of a single layer of Threshold Logic Units (TLUs), marked an important early development in neural networks. They demonstrated the **ability to learn and classify patterns, provided those patterns were linearly separable**—meaning a single straight line (or hyperplane in higher dimensions) could distinguish between the classes.
>
> However, this fundamental characteristic also exposed a significant limitation:
> - **Linear Separability Constraint**: **Many real-world problems involve data distributions that are not linearly separable**. Single-layer perceptrons are inherently unable to solve these more complex classification tasks.
>
> **The XOR Problem: A Case in Point**
> A classic illustration of this limitation is the XOR (exclusive OR) problem:
> -   **Inputs & Outputs**:
>     -   Input (0, 0) → Output 0
>     -   Input (0, 1) → Output 1
>     -   Input (1, 0) → Output 1
>     -   Input (1, 1) → Output 0
> -   **The Challenge**: If you visualize these four points on a 2D plane, with inputs as coordinates and outputs as class labels, no single straight line can separate the points that output '0' from those that output '1'.
>

> [!idea] Multi Layer Perceptron
>
> The Multilayer Perceptron (MLP) is an advancement from the single-layer perceptron, designed to overcome its limitations. The fundamental architectural difference is the inclusion of one or more **hidden layers** of neurons (which can be TLUs or other types of artificial neurons) between the input and output layers.
>
> -   **Structure**: An MLP typically consists of:
>     1.  An **input layer** that receives the initial features.
>     2.  One or more **hidden layers**. These layers are not directly connected to the external input or output; they process intermediate representations of the data.
>     3.  An **output layer** that produces the final classification or regression result.
>     Each neuron in one layer is typically fully connected to every neuron in the subsequent layer.
>
> ![[Pasted image 20250513042355.png|500]]
>
> **Solving the Motivation (Overcoming Single-Layer Limitations):**
> The introduction of hidden layers is precisely what allows MLPs to address the problem of non-linearly separable data, such as the XOR problem, which single-layer perceptrons cannot solve.
>
> -   **Hierarchical Feature Learning**: Neurons in the hidden layers learn to transform the input data into new, more abstract representations. Each successive layer can build upon the features learned by the previous ones.
> -   **Non-Linear Decision Boundaries**: Through these transformations across multiple layers, an MLP can learn complex, non-linear decision boundaries.
>     -   For the XOR problem, for instance, a hidden layer can learn to map the original inputs (which are not linearly separable) into a new feature space where they *become* linearly separable. The output layer can then easily make the final classification using these transformed features.
> -   **Increased Representational Power**: By adding depth (more layers), MLPs gain significantly more representational power than single-layer perceptrons, enabling them to model intricate patterns and solve a much wider array of complex problems.

> [!consider]- MLPs: Feature Abstraction and the Path to Separability
>
> Multilayer Perceptrons (MLPs) with one or more hidden layers are foundational examples of feedforward neural networks. When these networks possess significant depth due to multiple hidden layers, they embody the core principles of **Deep Neural Networks (DNNs)**. The term "deep" in DNNs refers to this layered architecture.
>
> The power of MLPs largely stems from their ability to perform hierarchical feature abstraction and data transformation:
>
> -   **Hierarchical Feature Abstraction**: Each layer within an MLP processes the output from the preceding layer, learning to transform the data into progressively more abstract and complex representations.
>     -   Initial hidden layers might learn to identify basic patterns or simple features from the raw input data.
>     -   Subsequent layers then combine these elementary features to detect higher-level, more intricate features. For example, in image processing, early layers might detect edges, which are then used by later layers to identify shapes, then parts of objects, and finally, whole objects.
>
> -   **Transformation Towards Separability**: A critical outcome of this layered processing is the transformation of the input data.
>     -   Input data that is not linearly separable in its original form (as seen in problems like XOR) can be mapped by the hidden layers into a new high-dimensional feature space.
>     -   Within this transformed space, the different classes of data often become more readily separable, ideally linearly separable, by the neurons in the subsequent layers, particularly the output layer.
>     -   Thus, the hidden layers effectively work to "untangle" complex data, simplifying the task for the final classification stage.
>
> This capacity for automatic discovery and construction of a relevant feature hierarchy allows MLPs to model complex, non-linear relationships within data, making them significantly more powerful than single-layer perceptrons for a wide range of pattern recognition tasks.

> [!example] Example: DNN Layered Abstraction in Facial Recognition
>
> Deep Neural Networks (DNNs), such as Multilayer Perceptrons with several hidden layers, excel at tasks like facial recognition by processing information through a hierarchy of feature abstractions. Here’s a heavily abstracted view of how this might work when a DNN analyzes an image to recognize a face:
>
> -   **Input Layer: Raw Pixel Data**
>     -   The network first receives the raw image as a grid of pixel values (e.g., color intensities). At this stage, the data is highly detailed but lacks any explicit meaning or structure related to a face.
>
> -   **Early Hidden Layers: Detecting Low-Level Features**
>     -   The initial hidden layers process these pixels. They typically learn to identify very basic elements like:
>         -   Edges (horizontal, vertical, diagonal lines)
>         -   Corners and simple curves
>         -   Basic textures or color gradients
>     -   The output here is a set of "feature maps" highlighting where these elementary patterns occur in the image. This is the first level of abstraction from raw pixels.
>
> -   **Middle Hidden Layers: Assembling Mid-Level Features (Facial Components)**
>     -   These layers take the low-level features (edges, corners) as input.
>     -   They learn to combine these simpler patterns into more complex and recognizable shapes that might correspond to parts of a face, such as:
>         -   An eye shape
>         -   The curve of a nostril or lip
>         -   The general outline of an ear
>     -   The representation becomes more abstract, now dealing with rudimentary facial components rather than just lines and curves.
>
> -   **Later Hidden Layers: Constructing High-Level Features (Facial Structures)**
>     -   Building upon the detected facial components, these deeper layers learn to recognize more complete facial structures or configurations.
>     -   They might identify common arrangements of eyes, a nose, and a mouth that signify a generic face, or even start to capture features unique to specific facial types.
>     -   The abstraction level is now very high, representing an almost complete concept of a "face" or specific facial gestalts.
>
> -   **Output Layer: Final Classification/Identification**
>     -   This final layer takes the highly abstract representation from the last hidden layer.
>     -   Based on this processed information, it makes the final decision:
>         -   For face *detection*: It might output a probability that a face is present.
>         -   For face *identification*: It might output the most likely identity of the recognized face from a set of known individuals.
>
> Through this cascaded process of abstraction, the DNN automatically learns to transform raw sensory data into meaningful, high-level concepts like "a specific person's face," enabling it to perform complex pattern recognition tasks. Each layer refines and builds upon the understanding of the layer before it.