> [!motivation] Generalisation Error
> 
> Machine learning models often perform well on training data but fail to maintain that performance on unseen data. This discrepancy points to various sources of error that prevent models from generalizing effectively to new examples. Understanding these error sources helps **identify targeted improvements in model design, hyperparameter selection, and data collection strategies.**
> 
> - Different sources of error contribute differently to poor generalization
> - Identifying specific error types enables more effective model improvements
> - Error analysis provides insights into whether to collect more data, change model complexity, or adjust training procedures

> [!idea] Variance and Overfitting
> 
> Variance errors occur when models are overly sensitive to fluctuations in the training data, capturing noise rather than underlying patterns.
> 
> - **Overfitting**: Model performs well on training data but poorly on unseen data due to learning noise
> - **High model complexity** often increases variance error (too many parameters relative to data amount)
> - **Irreducible error**: Random noise in the data that no model can predict
> 
> |Variance Indicators|Potential Solutions|
> |---|---|
> |Large gap between training and validation error|Regularization techniques (L1, L2)|
> |Model performs perfectly on training data|Early stopping|
> |Performance worsens with more complex models|Reduce model complexity|
> |Error increases with feature count|Feature selection/reduction|

> [!idea] Bias and Systematic Errors
> 
> Bias errors represent systematic deviations preventing models from capturing the true relationships in the data.
> 
> - **Underfitting**: Model is too simple to capture the underlying patterns
> - **Suboptimal model selection**: Using linear models for non-linear relationships
> - **Poor hyperparameter choices**: Learning rates too high/low or incorrect regularization strength
> - **Data representativeness issues**: Training data doesn't reflect the true data distribution
> 
> Bias errors typically manifest as poor performance on both training and validation sets, indicating the model lacks the capacity to learn the underlying pattern.
> 
> |Bias Sources|Detection Methods|
> |---|---|
> |Model architecture|Similar errors across training/validation|
> |Hyperparameters|Performance plateaus early in training|
> |Training procedure|Consistently high error metrics|
> |Data quality/coverage|Poor performance on specific subgroups|

> [!example] Bias and Variance in Practice
> 
> **High Variance (Overfitting) Examples:**
> 
> - **Decision Trees**: A deep, unpruned decision tree perfectly classifies each training example but fails on new data by creating extremely specific decision boundaries.
>     - Error pattern: Near-zero training error, high validation error
> - **Neural Networks**: An overparameterized neural network memorizes training examples instead of learning generalizable features.
>     - Signs: Training loss approaches zero while validation loss increases
> 
> **High Bias (Underfitting) Examples:**
> 
> - **Linear Regression on Non-linear Data**: Using linear regression to model housing prices that have exponential relationships with square footage.
>     - Error pattern: Both training and test errors remain high
> - **Simple Classifiers on Complex Problems**: Attempting to use logistic regression for image classification tasks.
>     - Signs: Performance plateaus at mediocre levels on all datasets
> 
