> [!motivation] Generalisation Error
> 
> Machine learning models often perform well on training data but fail to maintain that performance on unseen data. This discrepancy points to various sources of error that prevent models from generalizing effectively to new examples. Understanding these error sources helps **identify targeted improvements in model design, hyperparameter selection, and data collection strategies.**
> 
> - Different sources of error contribute differently to poor generalization
> - Identifying specific error types enables more effective model improvements
> - Error analysis provides insights into whether to collect more data, change model complexity, or adjust training procedures

> [!idea] Variance and Overfitting
> 
> Variance errors occur when models are overly sensitive to fluctuations in the training data, capturing noise rather than underlying patterns.
> 
> - **Overfitting**: Model performs well on training data but poorly on unseen data due to learning noise
> - **High model complexity** often increases variance error (too many parameters relative to data amount)
> - **Irreducible error**: Random noise in the data that no model can predict
> 
> |Variance Indicators|Potential Solutions|
> |---|---|
> |Large gap between training and validation error|Regularization techniques (L1, L2)|
> |Model performs perfectly on training data|Early stopping|
> |Performance worsens with more complex models|Reduce model complexity|
> |Error increases with feature count|Feature selection/reduction|

> [!idea] Bias and Systematic Errors
> 
> Bias errors represent systematic deviations preventing models from capturing the true relationships in the data.
> 
> - **Underfitting**: Model is too simple to capture the underlying patterns
> - **Suboptimal model selection**: Using linear models for non-linear relationships
> - **Poor hyperparameter choices**: Learning rates too high/low or incorrect regularization strength
> - **Data representativeness issues**: Training data doesn't reflect the true data distribution
> 
> Bias errors typically manifest as poor performance on both training and validation sets, indicating the model lacks the capacity to learn the underlying pattern.
> 
> |Bias Sources|Detection Methods|
> |---|---|
> |Model architecture|Similar errors across training/validation|
> |Hyperparameters|Performance plateaus early in training|
> |Training procedure|Consistently high error metrics|
> |Data quality/coverage|Poor performance on specific subgroups|

> [!example] Bias and Variance in Practice
> 
> **High Variance (Overfitting) Examples:**
> 
> - **Decision Trees**: A deep, unpruned decision tree perfectly classifies each training example but fails on new data by creating extremely specific decision boundaries.
>     - Error pattern: Near-zero training error, high validation error
> - **Neural Networks**: An overparameterized neural network memorizes training examples instead of learning generalizable features.
>     - Signs: Training loss approaches zero while validation loss increases
> 
> **High Bias (Underfitting) Examples:**
> 
> - **Linear Regression on Non-linear Data**: Using linear regression to model housing prices that have exponential relationships with square footage.
>     - Error pattern: Both training and test errors remain high
> - **Simple Classifiers on Complex Problems**: Attempting to use logistic regression for image classification tasks.
>     - Signs: Performance plateaus at mediocre levels on all datasets
> 

> [!idea] Regularization: Controlling Overfitting
> 
> Regularization techniques **prevent models from becoming too complex by adding constraints that discourage overly specific patterns.**
> 
> - **Penalizes complexity**: Adds a "cost" to the model for using complex patterns or large parameter values
> - **Favors simpler explanations**: Encourages the model to find general patterns rather than memorizing training examples
> - **Reduces sensitivity to noise**: Makes the model more resilient to random fluctuations in training data
> 
> Regularization works like training wheels â€“ it restricts the model's freedom to perfectly fit the training data, forcing it to focus on robust patterns that are more likely to generalize to new examples.
> 
> |Regularization Technique|How It Controls Overfitting|What It Tries to Accomplish|
> |---|---|---|
> |**L1 (Lasso)**|Pushes less important parameters to exactly zero, creating sparse models|**Feature selection**: Identifies the most important features while eliminating others entirely. By zeroing out weights for irrelevant features, L1 creates simpler, more interpretable models that focus only on the variables with genuine predictive power|
> |**L2 (Ridge)**|Shrinks all parameters toward zero, reducing their overall magnitude|**Weight distribution**: Prevents any single feature from having too much influence by penalizing large weights. Unlike L1, it rarely eliminates features completely but instead encourages the model to use all features with moderation, which works particularly well when features are correlated|
> |**Elastic Net**|Combines L1 and L2 penalties to get benefits of both approaches|**Balanced regularization**: Performs feature selection like L1 while maintaining the stability benefits of L2, particularly useful for datasets with many correlated features where pure L1 might select only one feature from each correlated group|
> 
> The goal of all these techniques is to find the optimal balance between **underfitting** (model is too simple to capture important patterns) and **overfitting** (model captures noise instead of true patterns), leading to models that generalize well to new, unseen data.

> [!example] Regularization in Practice
> 
> **House Price Prediction Example**
> 
> Imagine we're predicting house prices with these features:
> 
> - Square footage
> - Number of bedrooms
> - Year built
> - Distance to city center
> - School district rating
> 
> **L1 (Lasso)** would:
> 
> - Keep strong predictors like square footage and school rating
> - Zero out weak predictors like year built
> - Result: A simpler model using only 2-3 key features
> 
> **L2 (Ridge)** would:
> 
> - Keep all 5 features but reduce their influence
> - Prevent square footage from dominating the prediction
> - Result: A balanced model using all features moderately
> 
> **Elastic Net** would:
> 
> - Zero out the weakest predictor
> - Reduce the influence of the remaining features
> - Result: A model using 3-4 features with balanced weights