
> [!example] Standard Machine Learning Workflow
> 
> Let's walk through a complete machine learning project to predict housing prices:
> 
> **1. Check and clean data**
> 
> - Remove duplicate entries in housing dataset
> - Handle missing values (e.g., impute missing square footage)
> - Normalize numerical features (price, square footage)
> - Convert categorical features (neighborhood, style) to numerical
> 
> **2. Choose candidate models based on data and task**
> 
> - Linear Regression: good baseline for price prediction
> - Random Forest: handles non-linear relationships
> - Gradient Boosting: often performs well on structured data
> 
> **3. Split data into training and test sets**
> 
> - Training set (80%): 4,000 housing examples
> - Test set (20%): 1,000 housing examples kept completely separate
> 
> **4. Split training data into (reduced) training and validation sets**
> 
> - Method chosen: 5-fold cross validation
> - Divides training data into 5 equal parts
> - Each model trains on 4 parts and validates on the 5th
> - Rotates through all 5 combinations
> 
> **5. Train candidate models on (reduced) training sets**
> 
> - Train Linear Regression with default parameters
> - Train Random Forest with 100 trees
> - Train Gradient Boosting with learning rate of 0.1
> 
> **6. Select best model based on validation set errors**
> 
> - Cross-validation results (Mean Absolute Error):
>     - Linear Regression: $45,200
>     - Random Forest: $32,800
>     - Gradient Boosting: $29,500
> - Choose Gradient Boosting as the best performing model
> 
> **7. Retrain best model on the full training set**
> 
> - Retrain Gradient Boosting using all 4,000 training examples
> - Fine-tune hyperparameters based on validation performance
> 
> **8. Apply best model to test data**
> 
> - Evaluate on the untouched 1,000 test examples
> - Final Mean Absolute Error: $31,200
> - This gives an unbiased estimate of the generalization error
> - Model demonstrates good performance on unseen data


