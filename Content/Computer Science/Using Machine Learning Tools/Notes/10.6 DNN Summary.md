> [!motivation] The Overfitting Challenge
>
> Deep Neural Networks (DNNs), with their potentially millions of parameters, possess an incredible capacity to model complex data. However, this great flexibility also makes them particularly susceptible to **overfitting**.
> - Overfitting occurs when a model learns the training data too well, capturing not only the underlying patterns but also the noise and specific quirks of that particular dataset.
> - Consequently, an overfit model performs poorly on new, unseen data, as it fails to generalize beyond the training examples.
> - To combat this and improve a model's ability to generalize, various **regularization** techniques are employed.
>
> While methods like **Early Stopping** and even **Batch Normalization** (which also offers a regularizing effect) are valuable tools against overfitting, this note will explore other dedicated regularization techniques commonly used in neural networks.

> [!idea] L1 & L2 Regularization
>
> L1 and L2 regularization are common techniques used to reduce overfitting by adding a penalty to the model's loss function based on the magnitude of its connection weights. This discourages the learning algorithm from assigning excessively large weights, thereby constraining model complexity.
>
> - **L2 Regularization (Ridge):**
>   - **Mechanism:** Adds a penalty term proportional to the sum of the *squares* of all the connection weights (the ℓ2 norm of the weights).
>   - **Effect:** Encourages weights to be small and distributed. It doesn't typically force weights to become exactly zero but penalizes large individual weights, leading to a "smoother" model that is less sensitive to any single input feature.
>   - **Keras Usage:** `kernel_regularizer=tf.keras.regularizers.l2(lambda_value)`
>     (e.g., `lambda_value=0.01`).
>
> - **L1 Regularization (Lasso):**
>   - **Mechanism:** Adds a penalty term proportional to the sum of the *absolute values* of all the connection weights (the ℓ1 norm of the weights).
>   - **Effect:** Can shrink some weights to become exactly zero. This leads to a *sparse model*, effectively performing feature selection by ignoring some input features.
>   - **Keras Usage:** `kernel_regularizer=tf.keras.regularizers.l1(lambda_value)`
>
> - **Combined L1 & L2 Regularization (Elastic Net):**
>   - It's also possible to use both L1 and L2 penalties simultaneously.
>   - **Keras Usage:** `kernel_regularizer=tf.keras.regularizers.l1_l2(l1=lambda_l1, l2=lambda_l2)`
>
> To apply the same regularizer consistently across multiple layers, you can use Python's `functools.partial` to create a pre-configured layer type:
> ```python
> from functools import partial
> import tensorflow as tf
>
> RegularizedDenseL2 = partial(tf.keras.layers.Dense,
>                              activation="relu",
>                              kernel_initializer="he_normal",
>                              kernel_regularizer=tf.keras.regularizers.l2(0.01))
> # model.add(RegularizedDenseL2(100))
> ```

> [!consider] L2 Regularization & Adam
>
> While L2 regularization's goal is broadly to penalize large weights and encourage simpler models to improve generalization, its interaction with certain optimizers, particularly Adam and its variants, requires careful consideration.
> - **L2 Regularization vs. Weight Decay:**
>   - L2 regularization adds a penalty term (sum of squared weights) to the loss function.
>   - **Weight decay** is a different mechanism where weights are directly reduced by a small factor at each training step (e.g., `weight = weight * decay_factor`).
>   - For optimizers like SGD, Momentum, and Nesterov Accelerated Gradient (NAG), applying L2 regularization has an effect that is mathematically equivalent to applying weight decay.
>
> - **The Issue with Adam & L2 Regularization:**
>   - With adaptive optimizers like Adam, standard L2 regularization (as a loss penalty) does *not* achieve the same effect as true weight decay. This is due to how Adam adapts learning rates based on first and second moments of the gradients, which can interfere with the intended effect of L2 regularization as a direct weight decay mechanism.
>   - Using Adam with L2 regularization might not provide the same generalization benefits as true weight decay and can sometimes lead to suboptimal performance.
>
> - **AdamW for True Weight Decay:**
>   - If the intention is to apply weight decay with an Adam-style optimizer, the **AdamW** optimizer is preferred. AdamW decouples the weight decay step from the adaptive gradient updates, applying it more directly as intended, which often leads to better model generalization.

> [!idea] Dropout Regularization
>
> Dropout is a highly effective and widely used regularization technique for deep neural networks that helps prevent overfitting by introducing a form of noise during training.
> - **Core Concept & Mechanism:**
>   - **During Training:** At each training step, every neuron (excluding output neurons, and sometimes input neurons) has a probability `p` (the "dropout rate") of being temporarily "dropped out." This means the neuron is ignored during this particular forward and backward pass—it outputs zero and its weights are not updated.
>   - **Weight Scaling:** To compensate for the fact that fewer neurons are active during training, the outputs of the remaining active neurons are typically scaled up by a factor of `1 / (1 - p)` (where `1-p` is the "keep probability"). This ensures that the expected sum of inputs to the next layer remains roughly the same during training as it will be during inference.
>   - **During Inference (After Training):** All neurons are active (dropout is turned off). The scaling applied during training ensures that no further modifications are needed at inference time.
>
> - **Why Dropout Works:**
>   - **Reduces Co-adaptation:** Neurons cannot rely on specific other neurons being present, as any neuron can disappear. This forces them to learn more robust and independent features.
>   - **Ensemble Effect:** Training with dropout can be seen as training a large number of different "thinned" networks (networks with different subsets of neurons removed) simultaneously. The final network effectively acts like an average of these many smaller networks, which typically improves generalization.
>
> - **Keras Implementation:**
>   - Implemented using the `tf.keras.layers.Dropout` layer, specifying the `rate` (the probability `p` of dropping a unit).
>     `layer = tf.keras.layers.Dropout(rate=0.5)`