> [!motivation] Static Programs
> 
> Traditional software development relies on rigid, rule-based programs with explicitly coded logic.
> 
> When requirements change:
> 
> - Developers must manually update code
> - New edge cases require additional rules
> - Complexity increases exponentially with program size
> - Testing and validation cycles become lengthy
> 
> This approach becomes unsustainable as applications scale or operate in dynamic environments. **Systems break when encountering scenarios not explicitly programmed for,** leading to maintenance debt and reduced adaptability.

> [!idea] Machine Learning
> 
> Machine learning enables computers to **learn patterns from data without being explicitly programmed for every scenario.**
> 
> **Core concept:** Systems **derive rules automatically from examples rather than following pre-defined instructions.**
> 
> How it addresses static program limitations:
> 
> - Adapts to new patterns without code rewrites
> - Generalizes to unseen examples
> - Handles complexity through probabilistic approaches
> - Updates behavior by training on new data
> 
> Machine learning shifts the paradigm from "tell the computer what to do" to **"show the computer what good outcomes look like"** and letting it determine the optimal approach.

> [!consider] The "Teach a Man to Fish" Analogy
> 
> The proverb "Give a man a fish, and you feed him for a day. Teach a man to fish, and you feed him for a lifetime" parallels the shift from static programming to machine learning.
> 
> **Static Programming** = Giving a fish
> 
> - Solves specific problems with direct solutions
> - Requires new code for each new scenario
> 
> **Machine Learning** = Teaching to fish
> 
> - Provides frameworks for solving classes of problems
> - System continues to improve with experience
> - Adapts to changing conditions without constant intervention
> 
> This analogy highlights why machine learning offers more sustainable solutions for complex, evolving problem spaces where explicit programming would be impractical.

> [!idea] Supervised Learning
> 
> Supervised learning **trains models on labeled data (input-output pairs) to predict outputs for new inputs.**
> 
> **Two primary types:**
> 
> |Type|Purpose|Output|Example|
> |---|---|---|---|
> |Classification|Predicts which discrete category an input belongs to|Discrete label from a finite set (e.g., "yes"/"no", "cat"/"dog"/"bird")|Email filter that decides if a message belongs to "spam," "primary," or "promotions" categories based on content and sender information|
> |Regression|Predicts a continuous numerical value on a scale|Any real number within a range (e.g., $250,321 or 98.6Â°F)|House price predictor that takes features like location, square footage, and age to output an exact dollar amount ($472,890) rather than a price category|
> 
> **Key difference:**
> 
> - Classification divides inputs into separate, distinct groups (like sorting objects into labeled boxes)
> - Regression places inputs on a continuous spectrum (like measuring position on a number line)
> 
> 
> **Process:**
> 
> - Model is trained on labeled examples
> - Learning algorithm finds patterns connecting inputs to outputs
> - Model performance is evaluated on held-out test data

> [!idea] Unsupervised Learning
> 
> Unsupervised learning **finds patterns in data without labeled outputs or predefined categories.** The algorithm must discover structure on its own.
> 
> **Three main types:**
> 
> |Type|Purpose|Example|
> |---|---|---|
> |Clustering|Groups similar data points based on inherent similarities|Customer segmentation system that analyzes purchase history and browsing behavior to identify natural customer groups (like "budget shoppers," "luxury buyers," and "seasonal purchasers") without predefined categories|
> |Dimension Reduction|Compresses data to fewer dimensions while preserving important information|Image processing system that takes 1000-pixel images and reduces them to 50 key features that capture the same visual information, making pattern recognition faster without significant loss of accuracy|
> |Anomaly Detection|Identifies unusual patterns that don't conform to expected behavior|Credit card fraud detection system that learns normal spending patterns and flags transactions that deviate significantly, like unusual locations or purchase amounts, without being explicitly told what fraud looks like|
> 
> **Key characteristics:**
> 
> - Works with unlabeled data where "correct answers" aren't provided
> - Discovers hidden structures or relationships autonomously
> - Often used as a preprocessing step or for exploratory data analysis
> 
> **Common algorithms:**
> 
> - Clustering: K-means, Hierarchical Clustering, DBSCAN
> - Dimension Reduction: Principal Component Analysis (PCA), t-SNE
> - Anomaly Detection: Isolation Forest, One-Class SVM, Autoencoders

