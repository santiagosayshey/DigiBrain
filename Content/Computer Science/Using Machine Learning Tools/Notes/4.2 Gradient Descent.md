> [!idea] Gradient Descent - Simply Explained
> 
> Gradient descent is a method to find the best values for a model's parameters (like slope and intercept in a line).
> 
> **What it does**:
> 
> - It's like finding the lowest point in a valley by taking small steps downhill
> - Each step uses information about how steep the slope is in each direction
> 
> **How to do it**:
> 
> 1. Start with any parameter values (often zeros or random numbers)
> 2. Calculate how wrong your model is with these values
> 3. Figure out which direction to change each parameter to reduce the error
> 4. Take a small step in that direction
> 5. Repeat until you stop improving
> 
> **Practical implementation**:
> 
> - The "gradient" is just how much the error changes if you adjust each parameter
> - The "learning rate" is how big each step should be
> - Each "iteration" is one complete step in the process
> 
> **Real-world analog**: Imagine you're in a hilly area with fog, trying to find the lowest point. You can only feel the ground right around you to tell which way is downhill. You take a small step downhill, then reassess, over and over until you reach the bottom.

> [!example] Gradient Descent - A Simple Walkthrough
> 
> Let's train a model to predict house prices with gradient descent:
> 
> **Step 1**: Start with simple values
> 
> - Model: price = intercept + slope × sqft
> - Initial values: intercept = 0, slope = 100
> 
> **Step 2**: Try these values on our data
> 
> - For a 1000 sqft house: predicted price = 0 + 100 × 1000 = $100,000
> - But the actual price is $150,000, so we're off by $50,000
> - We do this for all houses and find we're consistently predicting too low
> 
> **Step 3**: Determine how to improve
> 
> - Since we're predicting too low, we need to increase both our intercept and slope
> - The calculations tell us exactly how much to change each
> 
> **Step 4**: Update our values
> 
> - New intercept = old intercept + small adjustment
> - New slope = old slope + small adjustment
> 
> **Step 5**: Repeat until our predictions are good
> 
> - With each iteration, our predictions get better
> - Eventually, we find that intercept ≈ $30,000 and slope ≈ $130 per sqft works best
> 
> **That's it!** Gradient descent just automates this process of making small, intelligent adjustments to find the best parameter values.

> [!consider] Gradient Descent - The Math
> 
> Mathematically, gradient descent minimizes a cost function $J(\theta)$ by iteratively updating parameters.
> 
> **Cost function for linear regression** (Mean Squared Error):
> 
> $J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2$
> 
> Where:
> 
> - $m$ is the number of training examples
> - $h_\theta(x^{(i)})$ is the prediction $\theta_0 + \theta_1 x^{(i)} + ... + \theta_n x_n^{(i)}$
> - $y^{(i)}$ is the actual value
> 
> **Gradient calculation**:
> 
> The gradient is the vector of partial derivatives:
> 
> $\nabla J(\theta) = \begin{bmatrix} \frac{\partial J}{\partial \theta_0} \ \frac{\partial J}{\partial \theta_1} \ \vdots \ \frac{\partial J}{\partial \theta_n} \end{bmatrix}$
> 
> For linear regression, these derivatives are:
> 
> $\frac{\partial J}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}$
> 
> (Note: for $\theta_0$, $x_0^{(i)} = 1$)
> 
> **Update rule**:
> 
> $\theta_j := \theta_j - \alpha \frac{\partial J}{\partial \theta_j}$
> 
> **Convergence criteria**:
> 
> Training stops when one of these is met:
> 
> - $|J^{(t+1)} - J^{(t)}| < \epsilon$ (cost change is very small)
> - $||\theta^{(t+1)} - \theta^{(t)}|| < \epsilon$ (parameter change is very small)
> - Maximum iterations reached