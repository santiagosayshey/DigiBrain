> [!idea] Gradient Descent
> 
> Gradient descent is an optimization algorithm that **finds the minimum of a function by iteratively moving in the direction of steepest decrease.**
> 
> **Key concepts**:
> 
> - **Gradient**: The slope of the cost function in every direction. It tells us which way is "uphill" and which way is "downhill" on our cost surface. We want to go downhill to find the minimum.
>     
>     - For one parameter: The gradient is simply the slope of the cost curve at that point
>     - For multiple parameters: The gradient is a vector showing how much the cost changes if we adjust each parameter
> - **Learning rate** ($\alpha$): A small positive number that controls step size. Too small means slow convergence, too large may overshoot the minimum and cause divergence.
>     
> - **Iteration**: One complete cycle of calculating the gradient and updating all parameters. Multiple iterations are required to reach the minimum.
>     
> 
> **How it works**:
> 
> 1. Initialize parameters with random or zero values
> 2. Compute the gradient of the cost function with respect to each parameter
> 3. Update each parameter using the formula: $\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)$
> 4. Repeat steps 2-3 until convergence (when changes become very small)
> 
> **Variants**:
> 
> - **Batch gradient descent**: Uses all training examples for each update
> - **Stochastic gradient descent**: Uses one random example per update
> - **Mini-batch gradient descent**: Uses a small random subset of examples
> 
> ```image_goes_here
> A contour plot showing level curves of a cost function with two parameters. Draw arrows showing the gradient direction at various points, and show the zigzag path that gradient descent would take from a starting point toward the minimum at the center of the contours.
> ```
> 
> **Simple explanation**: Gradient descent works like rolling a ball down a hill - it follows the steepest path downward until it reaches the bottom (minimum).

> [!example] Gradient Descent in Practice
> 
> Let's work through gradient descent step-by-step to truly understand how it optimizes our housing price model.
> 
> **Our data**:
> 
> |Square Footage (x)|Actual Price (y)|
> |---|---|
> |1000|$150,000|
> |1500|$210,000|
> |2000|$290,000|
> |2500|$350,000|
> 
> **Model**: $\text{price} = \theta_0 + \theta_1 \times \text{sqft}$
> 
> **Initial state**:
> 
> - Starting parameters: $\theta_0 = 0, \theta_1 = 100$
> - Learning rate: $\alpha = 0.00000001$ (small because our values are large)
> 
> **Iteration 1 - Detailed calculation**:
> 
> 1. **Calculate predictions with current parameters**:
>     - House 1 (1000 sqft): $0 + 100 \times 1000 = 100,000$
>     - House 2 (1500 sqft): $0 + 100 \times 1500 = 150,000$
>     - House 3 (2000 sqft): $0 + 100 \times 2000 = 200,000$
>     - House 4 (2500 sqft): $0 + 100 \times 2500 = 250,000$
> 2. **Calculate errors** (prediction - actual):
>     - House 1: $100,000 - 150,000 = -50,000$
>     - House 2: $150,000 - 210,000 = -60,000$
>     - House 3: $200,000 - 290,000 = -90,000$
>     - House 4: $250,000 - 350,000 = -100,000$
> 3. **Calculate gradients**:
>     - $\frac{\partial J}{\partial \theta_0} = \frac{1}{4}((-50,000) + (-60,000) + (-90,000) + (-100,000)) = -75,000$
>     - $\frac{\partial J}{\partial \theta_1} = \frac{1}{4}((-50,000 \times 1000) + (-60,000 \times 1500) + (-90,000 \times 2000) + (-100,000 \times 2500))$
>     - $\frac{\partial J}{\partial \theta_1} = \frac{1}{4}(-50M - 90M - 180M - 250M) = -142.5M$
> 4. **Update parameters** using formula $\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)$:
>     - $\theta_0 = 0 - (0.00000001 \times -75,000) = 0 + 0.75 = 0.75$
>     - $\theta_1 = 100 - (0.00000001 \times -142,500,000) = 100 + 1.425 = 101.425$
> 
> **What happened in this iteration**:
> 
> - All predictions were too low (negative errors)
> - Gradient for $\theta_0$ was negative, so we increased $\theta_0$ (shifted line up)
> - Gradient for $\theta_1$ was negative, so we increased $\theta_1$ (made line steeper)
> - Cost decreased from $4.125B$ to $3.98B$
> 
> **Iteration 2**:
> 
> 1. **New predictions**:
>     - House 1: $0.75 + 101.425 \times 1000 = 102,175$
>     - House 2: $0.75 + 101.425 \times 1500 = 152,888$
>     - ...etc.
> 2. **New errors, gradients, and parameter updates**:
>     - (calculations similar to above)
>     - Updated parameters: $\theta_0 \approx 1.48, \theta_1 \approx 102.82$
> 
> **After many iterations**:
> 
> The process continues, with each step:
> 
> - Making small adjustments to both parameters
> - Moving down the cost surface
> - Slowing down as gradients get smaller near the minimum
> 
> Eventually parameters converge to $\theta_0 \approx 30,000, \theta_1 \approx 130$, giving these predictions:
> 
> - House 1: $30,000 + 130 \times 1000 = 160,000$ (close to actual $150,000)
> - House 2: $30,000 + 130 \times 1500 = 225,000$ (close to actual $210,000)
> - House 3: $30,000 + 130 \times 2000 = 290,000$ (exact match!)
> - House 4: $30,000 + 130 \times 2500 = 355,000$ (close to actual $350,000)
> 
> **Why this works**:
> 
> - Errors tell us which direction to adjust parameters
> - Gradient considers all training examples simultaneously
> - Small learning rate ensures we don't overshoot the minimum
> - Process naturally slows down as we approach the optimal solution
> 
> ```image_goes_here
> Two side-by-side visualizations: 
> 1. Left: The housing data points with regression lines at three stages - initial (far off), intermediate, and final (best fit)
> 2. Right: A contour plot showing the path of parameters during gradient descent, starting far from minimum and spiraling inward
> ```