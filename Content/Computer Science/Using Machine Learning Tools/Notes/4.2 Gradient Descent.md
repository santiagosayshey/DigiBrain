> [!idea] Gradient Descent
> 
> Gradient descent is an optimization algorithm that finds the minimum of a function by iteratively moving in the direction of steepest decrease.
> 
> **How it works**:
> 
> - Computes the gradient (partial derivatives) of the cost function with respect to each parameter
> - Updates parameters in the opposite direction of the gradient
> - Formula: $\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)$
> 
> **Key components**:
> 
> - **Learning rate** ($\alpha$): Controls step size; too small means slow convergence, too large may overshoot
> - **Gradient** ($\nabla J$): Direction of steepest increase; negative gradient points downhill
> - **Iterations**: Multiple steps required to reach minimum
> 
> **Variants**:
> 
> - **Batch gradient descent**: Uses all training examples for each update
> - **Stochastic gradient descent**: Uses one random example per update
> - **Mini-batch gradient descent**: Uses a small random subset of examples
> 
> ```image_goes_here
> A contour plot showing level curves of a cost function with two parameters. Draw arrows showing the gradient direction at various points, and show the zigzag path that gradient descent would take from a starting point toward the minimum at the center of the contours.
> ```
> 
> **Simple explanation**: Gradient descent works like rolling a ball down a hill - it follows the steepest path downward until it reaches the bottom (minimum).