> [!motivation] The Overfitting Challenge
>
> Deep Neural Networks (DNNs), with their potentially millions of parameters, possess an incredible capacity to model complex data. However, this great flexibility also makes them particularly susceptible to **overfitting**.
> - Overfitting occurs when a model learns the training data too well, capturing not only the underlying patterns but also the noise and specific quirks of that particular dataset.
> - Consequently, an overfit model performs poorly on new, unseen data, as it fails to generalize beyond the training examples.
> - To combat this and improve a model's ability to generalize, various **regularization** techniques are employed.
>
> While methods like **Early Stopping** and even **Batch Normalization** (which also offers a regularizing effect) are valuable tools against overfitting, this note will explore other dedicated regularization techniques commonly used in neural networks.

> [!idea] L1 & L2 Regularization
>
> L1 and L2 regularization are common techniques used to reduce overfitting by adding a penalty to the model's loss function based on the magnitude of its connection weights. This discourages the learning algorithm from assigning excessively large weights, thereby constraining model complexity.
>
> - **L2 Regularization (Ridge):**
>   - **Mechanism:** Adds a penalty term proportional to the sum of the *squares* of all the connection weights (the ℓ2 norm of the weights).
>   - **Effect:** Encourages weights to be small and distributed. It doesn't typically force weights to become exactly zero but penalizes large individual weights, leading to a "smoother" model that is less sensitive to any single input feature.
>   - **Keras Usage:** `kernel_regularizer=tf.keras.regularizers.l2(lambda_value)`
>     (e.g., `lambda_value=0.01`).
>
> - **L1 Regularization (Lasso):**
>   - **Mechanism:** Adds a penalty term proportional to the sum of the *absolute values* of all the connection weights (the ℓ1 norm of the weights).
>   - **Effect:** Can shrink some weights to become exactly zero. This leads to a *sparse model*, effectively performing feature selection by ignoring some input features.
>   - **Keras Usage:** `kernel_regularizer=tf.keras.regularizers.l1(lambda_value)`
>
> - **Combined L1 & L2 Regularization (Elastic Net):**
>   - It's also possible to use both L1 and L2 penalties simultaneously.
>   - **Keras Usage:** `kernel_regularizer=tf.keras.regularizers.l1_l2(l1=lambda_l1, l2=lambda_l2)`
>
> To apply the same regularizer consistently across multiple layers, you can use Python's `functools.partial` to create a pre-configured layer type:
> ```python
> from functools import partial
> import tensorflow as tf
>
> RegularizedDenseL2 = partial(tf.keras.layers.Dense,
>                              activation="relu",
>                              kernel_initializer="he_normal",
>                              kernel_regularizer=tf.keras.regularizers.l2(0.01))
> # model.add(RegularizedDenseL2(100))
> ```

> [!consider] L2 Regularization & Adam
>
> While L2 regularization's goal is broadly to penalize large weights and encourage simpler models to improve generalization, its interaction with certain optimizers, particularly Adam and its variants, requires careful consideration.
> - **L2 Regularization vs. Weight Decay:**
>   - L2 regularization adds a penalty term (sum of squared weights) to the loss function.
>   - **Weight decay** is a different mechanism where weights are directly reduced by a small factor at each training step (e.g., `weight = weight * decay_factor`).
>   - For optimizers like SGD, Momentum, and Nesterov Accelerated Gradient (NAG), applying L2 regularization has an effect that is mathematically equivalent to applying weight decay.
>
> - **The Issue with Adam & L2 Regularization:**
>   - With adaptive optimizers like Adam, standard L2 regularization (as a loss penalty) does *not* achieve the same effect as true weight decay. This is due to how Adam adapts learning rates based on first and second moments of the gradients, which can interfere with the intended effect of L2 regularization as a direct weight decay mechanism.
>   - Using Adam with L2 regularization might not provide the same generalization benefits as true weight decay and can sometimes lead to suboptimal performance.
>
> - **AdamW for True Weight Decay:**
>   - If the intention is to apply weight decay with an Adam-style optimizer, the **AdamW** optimizer is preferred. AdamW decouples the weight decay step from the adaptive gradient updates, applying it more directly as intended, which often leads to better model generalization.

> [!idea] Dropout Regularization
>
> Dropout is a highly effective and widely used regularization technique for deep neural networks that helps prevent overfitting by introducing a form of noise during training.
> - **Core Concept & Mechanism:**
>   - **During Training:** At each training step, every neuron (excluding output neurons, and sometimes input neurons) has a probability `p` (the "dropout rate") of being temporarily "dropped out." This means the neuron is ignored during this particular forward and backward pass—it outputs zero and its weights are not updated.
>   - **Weight Scaling:** To compensate for the fact that fewer neurons are active during training, the outputs of the remaining active neurons are typically scaled up by a factor of `1 / (1 - p)` (where `1-p` is the "keep probability"). This ensures that the expected sum of inputs to the next layer remains roughly the same during training as it will be during inference.
>   - **During Inference (After Training):** All neurons are active (dropout is turned off). The scaling applied during training ensures that no further modifications are needed at inference time.
>
> - **Why Dropout Works:**
>   - **Reduces Co-adaptation:** Neurons cannot rely on specific other neurons being present, as any neuron can disappear. This forces them to learn more robust and independent features.
>   - **Ensemble Effect:** Training with dropout can be seen as training a large number of different "thinned" networks (networks with different subsets of neurons removed) simultaneously. The final network effectively acts like an average of these many smaller networks, which typically improves generalization.
>
> - **Keras Implementation:**
>   - Implemented using the `tf.keras.layers.Dropout` layer, specifying the `rate` (the probability `p` of dropping a unit).
>     `layer = tf.keras.layers.Dropout(rate=0.5)`

> [!consider] Dropout Best Practices
>
> While Dropout is a powerful regularizer, its effective use involves several practical considerations:
> - **Typical Dropout Rates:** The dropout rate `p` (the fraction of neurons to drop) is a hyperparameter typically set between 0.1 (10%) and 0.5 (50%). Rates closer to 0.2-0.3 are common for recurrent neural networks, while 0.4-0.5 might be used for convolutional neural networks.
> - **Layer Placement:** Dropout is often applied to the hidden layers, particularly the larger ones or the top one to three hidden layers (excluding the output layer). Some architectures may only apply dropout after the last hidden layer.
> - **Impact on Convergence:** Dropout tends to slow down the convergence of the training process because the learning signal for each neuron is more noisy. However, it often leads to a more robust model if tuned properly.
> - **Training vs. Validation Loss:** Since dropout is active only during training, comparing the training loss directly with the validation loss can be misleading. A model might appear to have similar training and validation losses even if it's overfitting. It's advisable to evaluate the training loss with dropout turned off (e.g., after training is complete) for a more accurate comparison.
> - **Adjusting the Rate:**
>   - If the model is overfitting, you can try increasing the dropout rate.
>   - If the model is underfitting (not learning well even on the training set), you might need to decrease the dropout rate or ensure the network has enough capacity.
> - **Alpha Dropout for Self-Normalizing Networks:** If you are using SELU (Scaled Exponential Linear Unit) activation functions, which aim for self-normalization, standard dropout can disrupt this property. **Alpha Dropout** is a variant specifically designed to work with SELU networks by preserving the mean and standard deviation of its inputs.

> [!idea] Monte Carlo (MC) Dropout
>
> Monte Carlo (MC) Dropout is a technique that leverages a neural network already trained with dropout layers to not only potentially improve its predictions but also to estimate the model's uncertainty.
> - **Core Concept & Mechanism:**
>   - Instead of deactivating dropout layers during inference (as is standard), MC Dropout keeps them active.
>   - To make a prediction for an input instance, multiple forward passes are performed through the network with dropout active. Each pass will have a different random set of neurons "dropped out."
>   - The predictions from these multiple passes are then aggregated (e.g., by averaging the predicted probabilities for classification tasks).
>
> - **Benefits:**
>   - **Improved Prediction Accuracy:** The aggregated prediction from multiple dropout samples can often be more robust and accurate than a single prediction with dropout disabled.
>   - **Uncertainty Estimation:** The variance or standard deviation across the different predictions provides a measure of the model's uncertainty. High variance indicates low confidence, which is crucial for risk-sensitive applications.
>
> - **Implementation Notes:**
>   - In Keras, this can be achieved by calling the model with the `training=True` argument during inference (e.g., `model(inputs, training=True)`).
>   - If other layers (like Batch Normalization) have distinct training-time behaviors that are undesirable during MC Dropout inference, custom dropout layers (like an `MCDropout` class) might be needed to force `training=True` only for the dropout logic.
>   - The number of Monte Carlo samples (forward passes) is a hyperparameter that trades off between prediction/uncertainty accuracy and inference time.

> [!idea] Max-Norm Regularization
>
> Max-Norm regularization is a technique that constrains the connection weights of a neural network directly, rather than by adding a penalty term to the loss function.
> - **Core Concept & Mechanism:**
>   - For each neuron, the ℓ2 norm (magnitude) of its vector of incoming connection weights (`w`) is constrained to be less than or equal to a specified hyperparameter `r` (the "max-norm" value).
>   - After each training step (weight update), if the ℓ2 norm of a neuron's weight vector `∥w∥₂` exceeds `r`, the weight vector is rescaled: `w ← w * (r / ∥w∥₂)`.
>   - This ensures that the magnitude of incoming weights for any neuron does not grow excessively large.
>
> - **Benefits:**
>   - **Reduces Overfitting:** By keeping the weights bounded, it helps prevent the model from becoming too complex and overfitting the training data.
>   - **Can Alleviate Unstable Gradients:** It can also contribute to more stable training, especially if Batch Normalization is not used, by preventing weights from exploding.
>
> - **Keras Implementation:**
>   - Applied by setting the `kernel_constraint` argument in a layer to an instance of `tf.keras.constraints.max_norm(r)`.
>     `layer = tf.keras.layers.Dense(100, kernel_constraint=tf.keras.constraints.max_norm(1.0))`
>   - The `axis` argument within `max_norm` specifies how the constraint is applied (e.g., independently to each neuron's weight vector in a Dense layer).

> [!summary] Regularization Techniques Recap
>
> To prevent deep neural networks from overfitting the training data and to improve their ability to generalize to new data, several regularization techniques can be employed:
> - **L1 & L2 Regularization**: These methods add a penalty to the loss function based on the size of the model's weights. L1 regularization (Lasso) encourages sparsity (many weights become zero), while L2 regularization (Ridge) encourages smaller, more distributed weights.
> - **Dropout**: This technique randomly deactivates a fraction of neurons during each training step, forcing neurons to learn more robust features independently and creating an ensemble effect that improves generalization.
> - **Monte Carlo (MC) Dropout**: An extension of dropout where it's kept active during inference across multiple passes. This can enhance prediction accuracy and provides valuable estimates of the model's uncertainty.
> - **Max-Norm Regularization**: This method directly constrains the magnitude (ℓ2 norm) of each neuron's incoming connection weights, preventing them from becoming too large and thus helping to control model complexity.