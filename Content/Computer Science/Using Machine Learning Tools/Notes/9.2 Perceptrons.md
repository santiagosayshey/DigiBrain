> [!motivation] Evolving Neurons: The Need for Adaptability and Learning
>
> The early McCulloch-Pitts model of an artificial neuron demonstrated how simple, interconnected units could, in principle, perform any logical computation. This was a foundational insight, linking biological inspiration to computational theory.
>
> However, these pioneering neurons had fixed operations and lacked a crucial aspect of true intelligence: the ability to *learn* from experience. Biological neurons adapt by strengthening or weakening connections (synapses) over time. To build machines that can genuinely learn from data—to recognize complex patterns, make nuanced classifications, and improve their performance—we require an artificial neuron model that can:
> - Handle a richer range of input values, not just binary signals.
> - Assign different levels of importance, or 'weights', to its various inputs.
> - Crucially, possess a mechanism to *adjust these weights* based on feedback or errors encountered during a training process.


> [!idea] TLUs
>
> Threshold Logic Units (TLUs) are an advancement from the basic McCulloch-Pitts neuron. They introduce more refined computational capabilities by incorporating numerical inputs, weights, and a bias.
>
> Key features of TLUs include:
> - **Numerical Inputs & Weights**: Unlike the binary-only inputs of their predecessors, TLUs process numerical inputs. Each input ($x_i$) is multiplied by a corresponding weight ($w_i$), which signifies that input's relative importance.
> - **Bias Term**: A bias ($b$) is added to the weighted sum. This term allows the TLU to adjust its activation threshold, offering greater flexibility in its decision-making.
>
> The computation in a TLU proceeds in two stages:
> 1.  **Weighted Sum Calculation**: First, the TLU computes a linear combination of its inputs and their weights, adding the bias. This sum ($z$) is calculated as:
>     $$
>     z = (w_1 x_1 + w_2 x_2 + \dots + w_n x_n) + b
>     $$
> 2.  **Step Function Application**: The sum $z$ is then processed by a step function to produce the TLU's final output.
>
> **Understanding Step Functions:**
> A step function transforms a numerical input (the weighted sum $z$) into a discrete output, typically one of two values (e.g., 0 or 1).
> - **Purpose**: Its role is to make a decision. It converts the continuous sum $z$ into a definitive output, determining if the neuron "fires" or not. This mimics a classification process where an input is assigned to a specific category based on whether a threshold is met.
> - **Example: Heaviside Step Function**: A common example is the Heaviside step function, $H(z)$, defined as:
>     $$
>     H(z) = \begin{cases} 0 & \text{if } z < 0 \\ 1 & \text{if } z \ge 0 \end{cases}
>     $$
>     This function outputs 0 if the weighted sum is negative and 1 if it is zero or positive.
>
> **Use in Binary Classification:**
> The output of a TLU using a Heaviside step function effectively performs binary classification. It categorizes inputs into one of two classes based on whether the weighted sum of inputs surpasses the implicit threshold set by the function.

> [!example] Training TLUs
>
> A Threshold Logic Unit (TLU) can be trained to classify data, such as distinguishing Iris flower species using features like petal length and width.
>
> -   **Objective of Training**: The core of training a TLU is to determine the optimal numerical values for its weights ($w_i$) and bias ($b$). These parameters define how the TLU separates data.
>
> -   **Training Process (Conceptual)**:
>     -   Inputs are specific features (e.g., petal length $x_1$, petal width $x_2$).
>     -   Known labels (e.g., 1 for *Iris setosa*, 0 for others) are provided for training samples. This setup inherently frames the task for a single TLU as binary classification.
>     -   An algorithm (not detailed here) adjusts weights and bias so the TLU's output—derived from the weighted sum $z = w_1x_1 + w_2x_2 + b$ followed by a step function—increasingly matches these known labels.
>
> -   **Classification Post-Training**:
>     -   Once optimal weights and bias are found, the TLU can classify new, unseen Iris flowers based on the binary task it was trained for.
>     -   It calculates $z$ using the new flower's measurements and the learned weights/bias.
>     -   The step function applied to $z$ then yields the classification (e.g., 1 for *Iris setosa* or 0 for not *Iris setosa*).
>
> In essence, training equips the TLU with the right parameters to draw a decision line (or plane in higher dimensions) that separates data for its specific binary classification task. To address multiclass problems, such as identifying all three Iris species simultaneously, one would typically combine multiple TLUs (e.g., using a one-vs-rest strategy).

> [!idea] Perceptrons
>
> A Perceptron is a neural network built from one or more Threshold Logic Units (TLUs). These TLUs are organized in a single layer that directly processes input features to produce outputs.
>
> Key architectural characteristics:
> - **Composition**: It consists of one or more TLUs. Each TLU operates as described previously, computing a weighted sum of its inputs and applying a step function.
> - **Single Layer**: All TLUs in a Perceptron are arranged in a single layer. This layer is referred to as the output layer, as its TLUs provide the Perceptron's final results.
> - **Full Connectivity to Inputs**: Every TLU in this single layer is connected to every input feature from the dataset. There is no intermediate "hidden" layer of neurons.
> - **Outputs**: The output of each TLU in the layer contributes to the final output of the Perceptron. If there are multiple TLUs, the Perceptron can produce multiple outputs simultaneously, often used for multiclass classification (e.g., via a one-vs-rest strategy where each TLU handles one class).
>
> Below is a conceptual diagram of a simple Perceptron with 2 input features ($x_1, x_2$) and an output layer composed of 3 TLUs, producing 3 outputs ($y_1, y_2, y_3$):
>
> ![[Pasted image 20250513033743.png|500]]
>
> - In this structure, each TLU ($TLU_1, TLU_2, TLU_3$) would independently calculate its own weighted sum of *both* inputs $x_1$ and $x_2$ (each with distinct weights per TLU, e.g., $TLU_1$ uses $w_{11}x_1 + w_{21}x_2 + b_1$) and then apply its step function to produce its respective output ($y_1, y_2,$ or $y_3$).
> - Its important to note here that a perceptron is not limited to a single positive output from 1 TLU - there can be multiple outputs (for example identifying two classes in a picture - a dog and a tree, but not a cat)


> [!consider]- Perceptron Math: An Analogy
>
> The calculation of outputs for a layer of artificial neurons (like the TLUs in a Perceptron) across multiple input instances can be performed very efficiently using matrix operations, as described by the equation:
> $$
> h_{W,b}(X) = \phi(XW + b)
> $$
> Let's break this down with an analogy to make it more intuitive. Imagine you're a chef (the Perceptron) trying to decide on several dishes (outputs) for many different customers (input instances) at once based on their preferences (input features).
>
> **The "Ingredients" and "Tools":**
>
> -   **$X$ (Your Customer Orders Matrix)**:
>     -   Think of $X$ as a large order sheet. Each row represents a different customer (an "instance"). Each column represents a specific preference or piece of information about the customer (a "feature"), like "prefers spicy," "allergic to nuts," or "requested vegetarian."
>     -   So, $X$ has one row per customer and one column per feature.
>
> -   **$W$ (The Master Recipe Adjustments Matrix)**:
>     -   $W$ is like your set of master instructions for how each customer preference influences each potential dish (each TLU/neuron).
>     -   It has one row for every input feature (customer preference) and one column for every TLU/neuron (potential dish).
>     -   The value $W_{ij}$ (at row $i$, column $j$) tells you how important feature $i$ is for dish $j$. For example, a high positive weight might mean "prefers spicy" strongly contributes to deciding on "Dish A (Spicy Curry TLU)."
>
> -   **$b$ (The Dish Base Flavor Vector)**:
>     -   $b$ is a list of initial "flavor scores" or "base inclinations" for each dish (TLU/neuron), before considering any specific customer preferences.
>     -   There's one bias term in $b$ for each TLU/dish. For instance, "Dish B (Mild Stew TLU)" might have a generally high base inclination if it's a popular default.
>
> -   **$\phi$ (The Final "Go/No-Go" Decision Function)**:
>     -   This is your activation function. For TLUs, it's a step function.
>     -   After combining all preferences and base inclinations, $\phi$ makes the final call for each dish for each customer: "prepare this dish" (output 1) or "don't prepare" (output 0).
>
> **The "Cooking" Process (Equation Steps):**
>
> 1.  **$XW$ (Calculating Initial Dish Suitability Scores)**:
>     -   This matrix multiplication is like taking each customer's order sheet ($X$) and, for each potential dish ($W$'s columns), calculating an initial "suitability score."
>     -   For a specific customer and a specific dish, you multiply each of the customer's feature values by the corresponding weights for that dish and sum them up.
>     -   The result is a new table where rows are still customers, but columns are now dishes (TLUs), and each cell $(XW)_{ij}$ contains the initial suitability score of dish $j$ for customer $i$, based purely on their weighted preferences.
>
> 2.  **$XW + b$ (Adjusting Scores with Base Flavors)**:
>     -   Now, you take the "Dish Base Flavor" vector $b$ and add it to the suitability scores.
>     -   The "broadcasting" mentioned means that for every customer, the base flavor score for "Dish A" is added to their initial suitability score for "Dish A," the base score for "Dish B" is added to their score for "Dish B," and so on.
>     -   This gives you the final "readiness-to-prepare score" for each dish for each customer.
>
> 3.  **$\phi(XW + b)$ (Making the Final Go/No-Go Decisions)**:
>     -   Finally, the decision function $\phi$ (the step function) is applied to every single readiness-to-prepare score in your table.
>     -   If a score for a particular dish and customer is above a certain threshold (e.g., $\ge 0$), the TLU "fires," and you decide to prepare that dish for that customer (output 1). Otherwise, you don't (output 0).
>     -   The result is your final production plan: a table showing which dishes are prepared (1s) or not (0s) for each customer.
>
> **Efficiency**: The "magic of linear algebra" is that specialized software can perform these matrix multiplications ($XW$) and additions ($+b$) incredibly fast, even for thousands of customers (instances) and hundreds of features or dishes (neurons) simultaneously, making Perceptrons (and more complex neural networks) computationally feasible.

> [!example] Example: Training a Perceptron
>
> Perceptron training is inspired by Hebb's idea ("cells that fire together, wire together") but with a key adaptation: it reinforces connections that help *reduce prediction errors*. The network learns by adjusting its weights based on the mistakes it makes.
>
> **The Learning Process:**
> -   The Perceptron processes one training instance at a time.
> -   For each instance, it makes a prediction.
> -   If an output neuron (TLU) produces an incorrect prediction, its connection weights are adjusted. The Perceptron learning rule guides this:
>     $$
>     w_{i,j}^{(\text{next step})} = w_{i,j} + \eta (y_j - \hat{y}_j)x_i
>     $$
>     -   $w_{i,j}$ is the weight from input $i$ to output neuron $j$.
>     -   $\eta$ (eta) is the learning rate, controlling the size of the adjustment.
>     -   $(y_j - \hat{y}_j)$ is the error for output neuron $j$: the difference between the target output ($y_j$) and the predicted output ($\hat{y}_j$). If the prediction is correct, this term is zero, and no weights are changed for that neuron.
>     -   $x_i$ is the value of the $i$-th input for the current instance. The adjustment is proportional to this input.
> -   This rule effectively means: if an input $x_i$ contributed to a wrong prediction, its weight $w_{i,j}$ is changed to make the neuron more likely to produce the correct prediction ($y_j$) in the future.
>
> If the training data is linearly separable (meaning a line or plane can separate the classes), the Perceptron algorithm is guaranteed to find a set of weights that correctly classifies all training instances (Perceptron convergence theorem).
>
> **Scikit-Learn Implementation:**
> Here's how you can train a Perceptron using Scikit-Learn, for example, to classify Iris setosa flowers based on petal length and width:
>
> ```python
> import numpy as np
> from sklearn.datasets import load_iris
> from sklearn.linear_model import Perceptron
>
> # Load the Iris dataset
> iris = load_iris(as_frame=True)
> # Use only petal length and petal width as features
> X = iris.data[["petal length (cm)", "petal width (cm)"]].values
> # Create labels: True if Iris setosa (target==0), False otherwise
> y = (iris.target == 0)
>
> # Initialize and train the Perceptron classifier
> per_clf = Perceptron(random_state=42)
> per_clf.fit(X, y)
>
> # Make predictions on new data
> X_new = [[2, 0.5], [3, 1]] # Two new flower instances
> y_pred = per_clf.predict(X_new)
> # y_pred might be, for example, [True, False]
> ```
>
> This code trains a `Perceptron` model. The `fit` method performs the iterative weight adjustments. The model can then predict whether new flower instances (like those in `X_new`) are Iris setosa.
>

