
> [!consider] Problems with Data
> 
> **Data quality and characteristics significantly impact machine learning model performance,** often creating challenges that technical improvements alone cannot solve.
> 
> **Quantity issues:**
> 
> - The "how much is enough?" question depends on problem complexity and model type
> - Simple linear models might need hundreds of examples, while deep neural networks require millions
> - Example: A speech recognition system trained on 10 hours of audio might recognize basic commands but fail at conversational speech, while one trained on 10,000 hours works across accents and environments
> 
> **Representativeness problems:**
> 
> - Training data must reflect the full distribution of future cases
> - Example: A facial recognition system trained primarily on young adult faces will perform poorly on elderly or child faces
> - Example: A loan approval model trained on historical data may perpetuate existing biases if protected attributes correlate with approval decisions
> 
> |Data Issue|Impact|Mitigation Strategy|
> |---|---|---|
> |Class imbalance|Model biases toward majority class|Oversampling minority class, synthetic data generation|
> |Concept drift|Model performance degrades over time|Continuous monitoring, periodic retraining|
> |Selection bias|Model learns patterns specific to how data was collected|Careful sampling design, external validation|
> 
> **Real-world data complications:**
> 
> - Noise: Random variation in measurements (e.g., sensor fluctuations in IoT devices)
> - Missing values: Incomplete records requiring imputation or special handling
> - Outliers: Extreme values that may represent errors or legitimate rare cases
> - Irrelevant features: Attributes that introduce noise rather than signal
> - Multicollinearity: Highly correlated features that complicate model interpretation

> [!consider] Problems with Models
> 
> Machine learning models can go wrong in two main ways - they can be too simple or too complex for the problem.
> 
> **Overfitting:**
> 
> - Model tries to memorize training examples instead of learning general patterns
> - Signs: Works perfectly on training data but fails on new examples
> - Example: A model that memorizes that "John Smith always buys coffee on Tuesdays" rather than learning that "people often buy coffee in the morning"
> 
> **Underfitting:**
> 
> - Model is too simple to capture important patterns in the data
> - Signs: Performs poorly even on the training data
> - Example: Using a straight line to predict house prices when size, location, and age all matter in complex ways
> 
> |Problem|Simple Explanation|How to Fix|
> |---|---|---|
> |Overfitting|The model is overthinking - like memorizing test answers without understanding the subject|Use simpler models; get more training data; focus on the most important features|
> |Underfitting|The model is too simplistic - like using only addition when calculus is needed|Try more complex models; add more relevant features; remove restrictions on the model|
> 
> **Finding the right balance:**
> 
> - Too simple = misses important patterns
> - Too complex = gets distracted by noise and irrelevant details
> - Just right = captures true patterns that generalize to new situations
> 
> A good model is like a good summary - it captures the important points without including every minor detail.
