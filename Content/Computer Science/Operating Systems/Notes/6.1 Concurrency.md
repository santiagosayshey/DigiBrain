> [!motivation] The Need for Concurrency
> So far, we have primarily considered machines that **execute single processes from start to finish.** However, this sequential execution model has limitations:
> 
> - **Underutilized Resources**: When a process is blocked or waiting for I/O operations, the CPU remains idle, leading to underutilized system resources.
> - **Limited Performance**: Sequential execution can limit the overall performance, especially when multiple tasks could be executed independently.
> - **Lack of Responsiveness**: Long-running processes can make the system unresponsive, affecting user experience and the execution of other processes.
> 
> To address these limitations, we want to introduce **concurrency, where multiple CPU threads or cores interleave their execution to form processes.** Concurrency allows for more efficient resource utilization, improved performance, and enhanced responsiveness.

> [!consider] Ensuring Correctness in Concurrent Programs
> Introducing concurrency raises concerns about ensuring the correctness of program execution, particularly when multiple threads access shared resources. Consider the following example:
> 
> ```
> balance = balance + 1
> ```
> 
> In a concurrent environment, **multiple threads might attempt to execute this statement simultaneously**. If not properly managed, this **can lead to race conditions** and incorrect results.
> 
> To ensure correctness, **instructions accessing shared memory need to be atomic**, meaning they must execute as an uninterruptible unit. Atomicity guarantees that the effects of an instruction are visible to other threads only after it has completed.
> 
> Achieving atomicity requires the concept of mutual exclusion. **If process A is executing a critical section (a block of code that accesses shared resources), then no other process, such as process C, should be allowed to enter that same critical section simultaneously.**

> [!exercise]+ Critical Section
> ```c
> // Critical Section
> balance = balance + depositAmount;
> totalDeposits = totalDeposits + 1;
> // End Critical Section
> ```
> 
> In this case, the code block updating the `balance` and `totalDeposits` variables should be treated as a critical section. Only one thread should execute this block at a time to avoid inconsistencies.
> 
> To enforce mutual exclusion and ensure correctness, programmers can use synchronization mechanisms such as **locks, semaphores, or mutexes**. These mechanisms coordinate access to shared resources and prevent multiple threads from concurrently executing critical sections.
> 
> Ensuring correctness in concurrent programs is crucial to maintain data integrity and avoid unexpected behavior. Programmers must carefully design and implement synchronization mechanisms to guarantee the atomicity of critical sections and prevent race conditions.

idea - locks (the basic idea)
- ensure that any critical section executes as if it were a single atomic section