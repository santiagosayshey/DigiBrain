> [!motivation] Minimizing Page Faults
> Page faults can be **costly and difficult to recover from**, as we saw in the previous discussion. They introduce overhead and can significantly impact system performance. Therefore, it is crucial to **minimize the number of page faults** that occur during program execution. By reducing page faults, we can improve overall system efficiency and responsiveness.

> [!idea] Page Selection
> Page selection refers to the process of deciding **when to bring a page into memory**. Typically, pages are brought into memory when a page fault occurs, indicating that the requested page is not currently present in physical memory.
>
> - **On-demand paging**: Pages are loaded into memory only when they are accessed and found to be missing, triggering a page fault. This approach is **reactive** and does not attempt to predict future page usage.
> - **Prepaging**: To improve performance, some systems employ prepaging techniques, where pages are loaded into memory **before they are actually referenced**. Prepaging aims to **predict which pages are likely to be used in the near future** and bring them into memory proactively, reducing the likelihood of page faults.
>
> Prepaging strategies can be based on various factors, such as:
> - **Spatial locality**: If a page is accessed, nearby pages are likely to be accessed soon.
> - **Temporal locality**: Recently accessed pages are likely to be accessed again in the near future.
> - **Application-specific knowledge**: Certain pages may be known to be frequently used by a particular application.
>
> By carefully selecting pages to bring into memory, either through on-demand paging or prepaging, we can minimize the occurrence of page faults and improve overall system performance.

> [!idea] Page Replacement
> When the physical memory is full and a new page needs to be brought in, the operating system must decide **which page to remove (or replace) to make room for the incoming page**. The page replacement algorithm determines which page is selected for removal.
>
> The process of page replacement typically involves the following steps:
>
> 1. **Selecting a victim page**: The operating system chooses a page to be removed from memory based on the page replacement algorithm in use.
> 2. **Checking the dirty bit**: If the selected page has been modified (i.e., the dirty bit is set), it needs to be written back to disk to ensure data consistency. If the dirty bit is not set, the page can be discarded without any disk I/O.
> 3. **Replacing the page**: The selected page is removed from memory, and the new page is brought in to take its place.
>
> Several page replacement algorithms exist, each with its own strategy for selecting the victim page. Some common algorithms include:
>
> - **Optimal page replacement**: Replaces the page that will not be used for the longest time in the future. This algorithm is theoretically optimal but requires knowledge of future page references, which is not practical in real systems.
> - **First-In-First-Out (FIFO)**: Replaces the page that was brought into memory the earliest, regardless of its recent usage.
> - **Least Recently Used (LRU)**: Replaces the page that has not been used for the longest time, based on the assumption that pages that have been recently used are more likely to be used again soon.

> [!example] Basic Page Replacement
> Consider a scenario where a process has a working set of 4 pages, and the physical memory can hold only 3 pages. Let's assume the page reference string is: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5.
>
> Using the FIFO page replacement algorithm, the page faults would occur as follows:
>
> | Page Reference | Memory State         | Page Fault? (Is it NOT in memory?) |
> |----------------|----------------------|-------------|
> | 1              | [ ] → [1]            | Yes         |
> | 2              | [1] → [1, 2]         | Yes         |
> | 3              | [1, 2] → [1, 2, 3]   | Yes         |
> | 4              | [1, 2, 3] → [4, 2, 3]| Yes         |
> | 1              | [4, 2, 3] → [4, 1, 3]| Yes         |
> | 2              | [4, 1, 3] → [4, 1, 2]| No          |
> | 5              | [4, 1, 2] → [5, 1, 2]| Yes         |
> | 1              | [5, 1, 2]            | No          |
> | 2              | [5, 1, 2]            | No          |
> | 3              | [5, 1, 2] → [3, 1, 2]| Yes         |
> | 4              | [3, 1, 2] → [3, 4, 2]| Yes         |
> | 5              | [3, 4, 2] → [3, 4, 5]| Yes         |
>
> In this example, the FIFO algorithm results in a total of 9 page faults. The performance of the page replacement algorithm can significantly impact the number of page faults and, consequently, the overall system performance.
>
> By selecting an appropriate page replacement algorithm and carefully managing the pages in memory, we can minimize the number of page faults and improve the efficiency of memory utilization.

> [!idea] FIFO (First-In-First-Out) Page Replacement
> - **Replaces the page that was brought into memory the earliest**
> - Simple to implement and understand
> - Does not consider the frequency or recency of page usage
> - May replace important pages that are frequently used

> [!idea] LRU (Least Recently Used) Page Replacement
> - **Replaces the page that has not been used for the longest time**
> - Exploits the principle of temporal locality
> - Assumes that recently used pages are more likely to be used again in the near future
> - Requires hardware support or software simulation to track page usage

> [!idea] Optimal Page Replacement
> - **Replaces the page that will not be used for the longest time in the future**
> - Theoretically the best algorithm, minimizing the number of page faults
> - Requires knowledge of future page references, which is not practical in real systems
> - Used as a benchmark for evaluating other algorithms

> [!consider] Comparison of FIFO, LRU, and Optimal Page Replacement
> Advantages:
> - FIFO: Simple to implement, low overhead
> - LRU: Takes into account the recent usage of pages, exploits temporal locality
> - Optimal: Achieves the minimum number of page faults
>
> Disadvantages:
> - FIFO: May replace important pages, does not consider usage frequency or recency
> - LRU: Requires hardware support or software overhead to track page usage
> - Optimal: Not implementable in practice, as it requires future knowledge
>
> Real-life implementations:
> - FIFO: Used in some operating systems due to its simplicity
> - LRU: Approximated using the "clock" algorithm or other heuristics
> - Optimal: Used as a theoretical benchmark for comparing other algorithms
>
> Implementation:
> - FIFO: Maintain a queue of pages in the order they were brought into memory
> - LRU: Use a stack or a data structure to keep track of page usage order
> - Optimal: Not implementable, as it requires future knowledge of page references

> [!example] No Locality Workload
> Consider a scenario where a process accesses pages in a completely random order, exhibiting no locality. In this case, the choice of page replacement algorithm has little impact on the number of page faults.
>
![[Pasted image 20240828055529.png|800]]

> [!example] 80-20 Workload
> Consider a scenario where 80% of the page references are made to 20% of the pages, exhibiting a high degree of locality. In this case, the choice of page replacement algorithm has a significant impact on the number of page faults.
>
![[Pasted image 20240828055549.png|800]]
>
> In an 80-20 workload, the LRU and Optimal algorithms perform significantly better than FIFO because they take advantage of the locality of reference. LRU keeps the frequently used pages in memory, while Optimal replaces the pages that will not be used for the longest time. FIFO, on the other hand, may replace frequently used pages just because they were brought into memory earlier.
>
> As the cache size increases, the number of page faults decreases for all algorithms, but the relative performance difference between the algorithms remains. The Optimal algorithm always achieves the minimum number of page faults, followed by LRU, and then FIFO.

> [!idea] LRU Implementation
> LRU (Least Recently Used) is a popular page replacement algorithm that aims to replace the page that has not been used for the longest time. However, **implementing a perfect LRU algorithm can be challenging and expensive** in terms of hardware or software overhead. There are several approaches to implementing LRU or approximating its behavior:
>
> 1. **Perfect LRU**: 
>    - Maintains a timestamp or a counter for each page, indicating the last time it was accessed.
>    - Requires updating the timestamp or counter for every memory reference, which can be costly.
>    - Needs a sorted list or a priority queue to efficiently find the least recently used page.
>    - Expensive to implement in hardware due to the need for a large number of comparators and registers.
>
> 2. **Clock Algorithm (Approximation of LRU)**:
>    - Uses a circular list of pages and a pointer (clock hand) to keep track of page usage.
>    - Each page has a reference bit that is set to 1 when the page is accessed.
>    - When a page fault occurs, the pointer moves clockwise, examining the reference bits.
>    - If the reference bit is 1, it is set to 0, and the pointer moves to the next page.
>    - If the reference bit is 0, the page is replaced, and the pointer stays on that page.
>    - Approximates LRU behavior with less overhead than perfect LRU.
>
> 3. **Second Chance Algorithm (Approximation of LRU)**:
>    - Similar to the Clock algorithm but uses an additional modify bit for each page.
>    - The modify bit is set to 1 when a page is modified (written to).
>    - When a page fault occurs, the algorithm checks both the reference bit and the modify bit.
>    - If the reference bit is 0 and the modify bit is 0, the page is replaced.
>    - If the reference bit is 1, it is set to 0, and the pointer moves to the next page.
>    - If the reference bit is 0 but the modify bit is 1, the page is marked as modified and moved to the back of the list, giving it a "second chance."
>    - Provides better performance than the Clock algorithm by considering both the recency of access and the modification status of pages.
>
> These implementations trade off between accuracy and efficiency. Perfect LRU provides the best performance in terms of minimizing page faults but is expensive to implement. The Clock and Second Chance algorithms approximate LRU behavior with less overhead, making them more practical choices in real systems.

> [!example] Clock Algorithm Example
> Let's consider a scenario where the memory has a capacity of 4 pages, and the page reference string is: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5.
>
> | Page Reference | Memory State (Reference Bits) | Page Fault? | Action |
> |----------------|-------------------------------|-------------|--------|
> | 1              | [1(1)]                        | Yes         | Page 1 is brought into memory |
> | 2              | [1(1), 2(1)]                  | Yes         | Page 2 is brought into memory |
> | 3              | [1(1), 2(1), 3(1)]            | Yes         | Page 3 is brought into memory |
> | 4              | [1(1), 2(1), 3(1), 4(1)]      | Yes         | Page 4 is brought into memory |
> | 1              | [1(1), 2(0), 3(0), 4(0)]      | No          | Reference bit of page 1 is set to 1 |
> | 2              | [1(1), 2(1), 3(0), 4(0)]      | No          | Reference bit of page 2 is set to 1 |
> | 5              | [1(0), 2(0), 5(1), 4(0)]      | Yes         | Page 3 is replaced by page 5 |
> | 1              | [1(1), 2(0), 5(0), 4(0)]      | No          | Reference bit of page 1 is set to 1 |
> | 2              | [1(1), 2(1), 5(0), 4(0)]      | No          | Reference bit of page 2 is set to 1 |
> | 3              | [1(0), 2(0), 5(0), 3(1)]      | Yes         | Page 4 is replaced by page 3 |
> | 4              | [4(1), 2(0), 5(0), 3(0)]      | Yes         | Page 1 is replaced by page 4 |
> | 5              | [4(0), 2(0), 5(1), 3(0)]      | No          | Reference bit of page 5 is set to 1 |
>
> In this example, the Clock algorithm approximates the LRU behavior by using reference bits. When a page fault occurs, the algorithm moves the pointer (clock hand) clockwise, examining the reference bits. If the reference bit is 1, it is set to 0, and the pointer moves to the next page. If the reference bit is 0, the page is replaced, and the pointer stays on that page.
>
> The Clock algorithm provides a good approximation of LRU while being simpler to implement compared to perfect LRU. It requires less overhead in terms of hardware or software resources and can be efficiently implemented in real systems.