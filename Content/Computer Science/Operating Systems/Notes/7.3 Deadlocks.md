> [!example] Dining Lawyers Problem
> Five lawyers sit around a circular table, each with a plate of spaghetti and a single fork between each pair of lawyers. To eat, a lawyer needs two forks.
> 
> ![[Pasted image 20240910050914.png|400]]
> 
> The problem unfolds as follows:
> 1. Each lawyer follows this routine:
>    - Think (don't need forks)
>    - Pick up left fork
>    - Pick up right fork
>    - Eat
>    - Put down right fork
>    - Put down left fork
> 
> 2. Deadlock scenario:
>    - If all lawyers simultaneously pick up their left forks, none can pick up their right forks.
>    - All lawyers are now holding one fork and waiting for another, creating a circular wait.
> 
> 3. This demonstrates all four conditions for deadlock:
>    - **Mutual Exclusion**: Only one lawyer can use a fork at a time.
>    - **Hold and Wait**: Lawyers hold one resource (left fork) while waiting for another (right fork).
>    - **No Preemption**: Forks cannot be forcibly taken from lawyers.
>    - **Circular Wait**: Each lawyer is waiting for the fork held by the next lawyer.
> 
> Possible solutions:
> - Allow only four lawyers to sit at the table at once.
> - Instruct an odd-numbered lawyer to pick up the right fork first, then the left.
> - Use a semaphore to limit the number of lawyers who can simultaneously attempt to pick up forks.

> [!example] Factorio Trains Deadlock
> Consider our Factorio railway system from before. If we add 1 more train to the network, we experience a deadlock. Each train is trying to move to a station that is mutually blocked by another train. A train in the top left is trying to get to the bottom right, but cant because a train is there. That train is trying to get to the bottom left, because there is a train there also!
> 
> ![[Pasted image 20240910050428.png]]
> 
> 
> This scenario mirrors the deadlock conditions:
> 1. **Mutual Exclusion**: Each track segment can only be used by one train at a time.
> 2. **Hold and Wait**: Each train holds one track while waiting for the other.
> 3. **No Preemption**: Trains can't be forcibly removed from tracks.
> 4. **Circular Wait**: Train A-B is waiting for Train C-D, which is waiting for Train A-B.

> [!idea] Deadlock
> A deadlock is a concurrent systems problem where **two or more processes are unable to proceed because each is waiting for the other to release a resource.**
> 
> Key characteristics of a deadlock:
> - **Mutual Exclusion**: A resource is exclusively owned by a single process.
> - **Hold and Wait**: A process must be holding at least one resource while waiting to acquire additional resources held by other processes.
> - **No Preemption**: Resources cannot be forcibly taken away; they must be released voluntarily by the process holding them.
> - **Circular Wait**: A circular chain of two or more processes, each waiting for a resource held by the next process in the chain.
> 
> **Key Idea**: If you remove any one of these characteristics, you remove the deadlock!

> [!idea] Possible Solution: Wait-Free Algorithms
> Wait-free algorithms are a **concurrent programming technique** that ensures every operation can complete in a finite number of steps, regardless of the actions of other threads.
> 
> Key characteristics:
> - **Progress Guarantee**: Every thread makes progress in a finite number of steps, regardless of other threads' actions.
> - **Non-Blocking**: No thread can be prevented from making progress by the failure or suspension of other threads.
> - **Bounded Time**: Operations complete within a bounded number of steps.
> 
> Benefits:
> - **Deadlock Prevention**: By design, wait-free algorithms eliminate the possibility of deadlocks.
> - **Improved Responsiveness**: Ensures that all threads make progress, enhancing system responsiveness.
> - **Fault Tolerance**: System continues to function even if some threads fail or are delayed indefinitely.
> 
> Implementation Challenges:
> - **Complexity**: Often more complex to design and implement than lock-based algorithms.
> - **Performance Overhead**: May introduce some performance overhead in low-contention scenarios.
> 
> Common Techniques:
> - **Atomic Operations**: Utilize hardware-supported atomic operations (e.g., Compare-and-Swap).
> - **Helping Mechanism**: Threads may help complete other threads' operations.
> - **Version Counters**: Use version numbers to detect and handle conflicts.
> 
> While not suitable for all scenarios, wait-free algorithms provide a powerful tool for creating robust, deadlock-free concurrent systems in critical applications where progress guarantees are essential.

> [!idea] Solution: Atomic Lock Acquisition
> One strategy to prevent deadlocks is to eliminate the "Hold and Wait" condition by **requiring processes to acquire all needed resources atomically in a single operation.**
> 
> **Implementation**:
> - Processes must request and be allocated all their required resources before execution.
> - If all resources are not available, the process must release any acquired resources and try again later.
> 
> **Advantages**:
> - **Deadlock Prevention**: Eliminates one of the necessary conditions for deadlock, effectively preventing it.
> - **Simplicity**: Conceptually straightforward and easier to implement than some other deadlock prevention techniques.
> - **Predictability**: Resource allocation becomes more predictable, as processes either get all resources or none.
> 
> **Disadvantages**:
> - **Reduced Concurrency**: May lead to lower resource utilization as processes must wait for all resources to be available simultaneously.
> - **Starvation Risk**: Processes requiring many resources might be repeatedly denied, leading to starvation.
> - **Resource Underutilization**: Resources allocated to a process may remain idle while waiting for other resources.
> - **Increased Complexity for Dynamic Resource Needs**: Difficult to implement for processes that don't know all their resource requirements in advance.
> 
> **Example**:
> ```python
> def acquire_resources(required_resources):
>     with global_lock:
>         if all(resource.available for resource in required_resources):
>             for resource in required_resources:
>                 resource.allocate()
>             return True
>         return False
> 
> # Usage
> if acquire_resources([resource1, resource2, resource3]):
>     # Use resources
>     # ...
>     # Release resources
> else:
>     # Wait and try again later
> ```
> 
> While effective at preventing deadlocks, this approach may not be suitable for all systems, especially those with high concurrency requirements or dynamic resource needs.

> [!idea] Solution: Preemption
> This strategy prevents deadlocks by **allowing resources to be forcibly released if a process can't acquire all the resources it needs**, effectively removing the "No Preemption" condition.
> 
> **Implementation**:
> - If a process holding some resources requests another resource that cannot be immediately allocated, all resources currently held are preempted (released).
> - These released resources are added to the list of resources for which the process is waiting.
> - The process will be restarted only when it can regain its old resources, as well as the new ones it is requesting.
> 
> **Advantages**:
> - **Deadlock Prevention**: Eliminates one of the necessary conditions for deadlock.
> - **Progress Guarantee**: Ensures that high-priority processes can acquire needed resources.
> - **Flexibility**: Allows for more dynamic resource allocation strategies.
> 
> **Disadvantages**:
> - **Overhead**: Frequent preemption and resource reallocation can lead to significant system overhead.
> - **Complexity**: Implementing preemption mechanisms can be complex, especially for resources that are not easily preemptable (e.g., printers).
> - **Potential for Livelocks**: If not implemented carefully, processes might repeatedly acquire and release resources without making progress.
> - **State Management**: Processes must be able to save and restore their state when preempted, which can be challenging for some types of resources.
> 
> **Example**:
> ```python
> def acquire_resource(process, resource):
>     if resource.available:
>         resource.allocate(process)
>         return True
>     elif resource.owner.priority < process.priority:
>         preempted_process = resource.owner
>         resource.release(preempted_process)
>         resource.allocate(process)
>         preempted_process.restart()  # Will try to reacquire resources later
>         return True
>     return False
> 
> # Usage
> if not acquire_resource(current_process, needed_resource):
>     for resource in current_process.held_resources:
>         resource.release(current_process)
>     current_process.restart()  # Try again later
> ```
> 
> This approach can be effective in preventing deadlocks, but it requires careful implementation to manage process states and avoid livelocks. It's particularly useful in systems where resources can be easily saved and restored, such as in virtual memory management.
