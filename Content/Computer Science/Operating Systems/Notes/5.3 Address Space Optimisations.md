> [!motivation] Optimizing Address Space Translation
> Address space translation is a demanding process that requires significant attention to ensure the efficient operation of computer systems. It plays a crucial role in memory management and has a direct impact on system performance. **Optimizing address space translation mechanisms is essential** to enhance the overall efficiency and responsiveness of computers.

> [!idea] Clock Algorithm Extensions
> 1. **Replacing Multiple Pages at Once**:
>    - Instead of replacing only one page at a time, the clock algorithm can be extended to replace multiple pages in a single iteration.
>    - This approach can reduce the overhead associated with page replacement and improve performance in scenarios with high page fault rates.
>
> 2. **Last Chance (Minute Hand)**:
>    - In addition to the reference bit (hour hand), a software counter can be added to keep track of the time since a page was last used.
>    - This counter acts as a minute hand, providing finer granularity in determining the least recently used pages.
>    - Pages with a higher counter value (less recently used) are given priority for replacement.
>    - The minute hand helps in making more accurate replacement decisions, especially in cases where the reference bits alone may not provide enough information.

> [!idea] Eviction Extensions
> 1. **Retention Preference for Dirty Pages**:
>    - The dirty bit can be used to give preference to retaining dirty pages in memory.
>    - When a page fault occurs, and a victim page needs to be selected, the algorithm can choose to evict clean pages over dirty pages.
>    - This extension aims to avoid the overhead of writing dirty pages back to disk, as they have been modified and would require additional I/O operations.
>
> 2. **Write-Back List**:
>    - A write-back list can be maintained to keep track of dirty pages that need to be written back to disk.
>    - Instead of immediately writing a dirty page to disk when it is evicted, it can be added to the write-back list.
>    - The pages in the write-back list can be written to disk asynchronously or during periods of low system activity.
>    - This approach helps in reducing the performance impact of write operations and allows for more efficient disk I/O management.
>
> 3. **Demand Zero List**:
>    - A demand zero list can be used to optimize the allocation of new pages.
>    - When a process requests a new page, instead of immediately allocating and initializing it with zeros, the page can be added to the demand zero list.
>    - The pages in the demand zero list are marked as not present in the page table.
>    - When a page from the demand zero list is accessed, a page fault occurs, and the operating system allocates and initializes the page on-demand.
>    - This lazy allocation approach reduces the overhead of initializing pages that may not be immediately used.

> [!consider] Global vs. Local Replacement
> When a victim page needs to be selected for replacement, it is important to consider whether the page belongs to a single process or multiple processes.
>
> - **Fixed Space Allocation**:
>   - In a fixed space allocation scheme, each process is allocated a fixed number of pages.
>   - When a process needs to replace a page, it can only choose from its own set of allocated pages.
>   - This approach ensures fairness and prevents one process from monopolizing memory resources.
>
> - **Variable Space Allocation**:
>   - In a variable space allocation scheme, processes can share the available memory space.
>   - When a page fault occurs, the replacement algorithm can choose a victim page from any process.
>   - This approach allows for more flexibility in memory allocation but may lead to issues like one process impacting the performance of others.
>
> The choice between global and local replacement policies depends on factors such as system requirements, fairness, and overall performance goals.

> [!idea] Thrashing
> Thrashing occurs **when a system spends more time swapping pages in and out of memory than executing useful work**. It happens when the available physical memory is insufficient to meet the demands of the running processes.
>
> - **Symptoms of Thrashing**:
>   - High page fault rate: The system experiences a large number of page faults, indicating frequent swapping of pages between memory and disk.
>   - Low CPU utilization: The CPU spends most of its time waiting for memory operations to complete, resulting in reduced overall system performance.
>   - Sluggish system response: The system becomes unresponsive or slow due to excessive swapping activity.
>
> - **Improving Thrashing Situations**:
>   - Increase physical memory: Adding more physical memory to the system can alleviate thrashing by providing more space for processes to reside in memory.
>   - Reduce memory demand: Optimizing processes to use memory efficiently and minimizing the number of concurrently running processes can help reduce memory pressure.
>   - Employ better paging algorithms: Using more sophisticated paging algorithms that consider factors like working set size and locality of reference can help in making better page replacement decisions.
>   - Implement memory compression: Compressing memory pages can effectively increase the available memory capacity without adding physical memory.
>   - Utilize disk caching: Employing disk caching techniques, such as read caching and write buffering, can help reduce the impact of disk I/O operations during thrashing.
>
> Thrashing is a critical performance issue that requires careful consideration and tuning of memory management mechanisms to ensure optimal system performance.



ideas - advanced optimisations
- guard pages
- debugging support
	- not sure what this is about: Debugger may support Watchpoint on memory  
		• Debugger, breaks, or monitors changes on a variable  
		How?  
		• Protect page the variable is on  
		• Upon access exception, check the exception address  
		• If it is the required variable:  
		• Unprotect page  
		• perform debug action (break, count, record value etc)  
		• Then - allow access to proceed (one instruction)  
		• Reprotect page  
		Exact sequence depends  
		on debug action  
		Not efficient – but this  
		is for debugging  
		Watching stack is  
		horrendously
- file mapping
- shared memory
- copy on write
- fast fork and exec
- snapshots and checkpoints
- persistent state
- distributed shared memory

idea - external pager - Mach / Dawrwin