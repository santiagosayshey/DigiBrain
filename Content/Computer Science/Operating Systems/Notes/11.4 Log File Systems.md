> [!motivation] Beyond Traditional File Systems
> Modern storage systems face challenges that make FFS-style designs less optimal:
> 
> **Technology Shifts**:
> - RAM sizes increased dramatically (MB â†’ GB)
> - Large RAM caches make read performance less critical
> - Write performance becomes the bottleneck
> - SSDs change access pattern assumptions
> 
> **FFS Limitations**:
> - Random writes require multiple disk accesses:
>   - Update data blocks
>   - Modify inode
>   - Update bitmaps
>   - Write journal entries
> - Each write operation causes disk head movement
> - Write amplification impacts SSD lifetime
> 
> These factors led to rethinking file system design, focusing on sequential writes and write optimization rather than read optimization.

> [!idea] Log-Structured File System (LFS)
> LFS reimagines the entire disk as a continuous log where new data is always written sequentially at the "head." Instead of updating files in place, LFS always writes a new copy at the log's end.
> 
> ![[Pasted image 20241031075245.png|500]]
> 
> **Core Architecture**:
> The disk is divided into large **segments** (typically 1MB), serving as the basic unit of write operations. Each segment contains:
> - Data blocks
> - Inodes
> - Imap pieces
> - Segment summary
> 
> **Key Structures**:
> - **Imap**: Maps inode numbers to their locations in the log
> - **Segment Summary**: Records what's written in each segment
> - **Checkpoint Region**: Points to latest imap pieces

ye