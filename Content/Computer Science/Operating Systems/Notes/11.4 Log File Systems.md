> [!motivation] Beyond Traditional File Systems
> Modern storage systems face challenges that make FFS-style designs less optimal:
> 
> **Technology Shifts**:
> - RAM sizes increased dramatically (MB â†’ GB)
> - Large RAM caches make read performance less critical
> - Write performance becomes the bottleneck
> - SSDs change access pattern assumptions
> 
> **FFS Limitations**:
> - Random writes require multiple disk accesses:
>   - Update data blocks
>   - Modify inode
>   - Update bitmaps
>   - Write journal entries
> - Each write operation causes disk head movement
> - Write amplification impacts SSD lifetime
> 
> These factors led to rethinking file system design, focusing on sequential writes and write optimization rather than read optimization.

> [!idea] Log-Structured File System (LFS)
> LFS treats the disk as a **circular log**, writing all data sequentially at the log's "head". The log is divided into fixed-size regions called **segments** (typically 1MB each). Each segment is the basic unit of:
> - Writing: System buffers writes until a full segment
> - Cleaning: Old segments recycled when space needed
> - Storage management: Space allocated in segment units
> 
> **Segment Structure**:
> Each segment contains four parts:
> - **Data Blocks**: New file contents
> - **Inodes**: File metadata
> - **Imap Pieces**: Maps inode numbers to locations
> - **Segment Summary**: Tracks segment contents
> 
> **Key Insight**:
> By treating the disk as a circular buffer of segments and always writing full segments sequentially at the head:
> - Writes become sequential and fast
> - Old versions remain until space is needed
> - Cleaning process reclaims space from old segments
