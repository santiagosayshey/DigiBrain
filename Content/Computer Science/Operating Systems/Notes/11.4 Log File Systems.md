> [!motivation] Beyond Traditional File Systems
> Modern storage systems face challenges that make FFS-style designs less optimal:
> 
> **Technology Shifts**:
> - RAM sizes increased dramatically (MB â†’ GB)
> - Large RAM caches make read performance less critical
> - Write performance becomes the bottleneck
> - SSDs change access pattern assumptions
> 
> **FFS Limitations**:
> - Random writes require multiple disk accesses:
>   - Update data blocks
>   - Modify inode
>   - Update bitmaps
>   - Write journal entries
> - Each write operation causes disk head movement
> - Write amplification impacts SSD lifetime
> 
> These factors led to rethinking file system design, focusing on sequential writes and write optimization rather than read optimization.

> [!idea] Log-Structured File System (LFS)
> LFS treats the disk as a **circular log**, writing all data sequentially at the log's "head". The log is divided into fixed-size regions called **segments** (typically 1MB each). Each segment is the basic unit of:
> - Writing: System buffers writes until a full segment
> - Cleaning: Old segments recycled when space needed
> - Storage management: Space allocated in segment units
> 
> ![[Pasted image 20241031081643.png|700]]
> 
> **Segment Structure**:
> Each segment contains four parts:
> - **Data Blocks**: New file contents
> - **Inodes**: File metadata
> - **Imap Pieces**: Maps inode numbers to locations
> - **Segment Summary**: Tracks segment contents
> 
> **Segment Cleaning**:
> The cleaning process runs based on available free space:
> - **Threshold-based**: Starts when free segments drop below threshold
> - **Background Processing**: Runs during idle periods
> 
> **Block Liveness**:
> A block in a segment is "dead" (cleanable) when:
> - File is deleted
> - Block is overwritten (new version exists elsewhere)
> - Inode points to newer version
> LFS uses segment summary blocks and imap to determine block status.
> 
> **Key Insight**:
> By treating the disk as a circular buffer of segments and always writing full segments sequentially at the head:
> - Writes become sequential and fast
> - Old versions remain until space is needed
> - Cleaning process reclaims space from old segments

> [!example] LFS Operations
> Consider a user updating a small file '/home/user/config.txt':
> 
> **Initial State**: 
> ```
> Segment 5: 
>   - Data: config.txt (original 2KB)
>   - Inode 127 points to this location
> ```
> 
> **After Update**:
> ```
> Segment 5: (Now contains dead blocks)
>   - Data: old config.txt (dead)
>   - Old inode 127 (dead)
> 
> Current Segment: 
>   - Data: new config.txt
>   - Updated inode 127
>   - Updated imap (points to new inode location)
>   - Segment summary (records new block locations)
> ```
> 
> **During Cleaning**:
> When segment 5 is selected for cleaning:
> 1. Check segment summary and imap
> 2. Determine config.txt blocks are dead (inode points elsewhere)
> 3. Mark segment as free
> 4. No live data to copy (in this case)

Would you like me to add more examples showing different scenarios, like directory operations or large file handling?










> [!idea] Log-Structured File System (LFS)
> - Core Architecture
> - Sequential Writing Strategy
> - Data Structure Design
>   - Inode Management
>   - Imap Structure
>   - Directory Organization

> [!example] LFS Implementation Examples
> - Write Buffering
> - Checkpoint Creation
> - Garbage Collection Process
> - Block Liveness Verification

> [!consider] LFS Key Considerations
> - Crash Recovery Mechanisms
> - Garbage Collection Policies
> - Performance Tradeoffs
> - Space Management

Would you like me to start creating the detailed notes for either file system based on this plan?