> [!idea] RAID 4: Dedicated Parity
> RAID 4 uses **block-level striping with a dedicated parity disk**:
> 
> **Core Concept**: Distribute data across multiple disks with one disk dedicated to parity
> 
> **Parity Definition**: 
> Parity is a form of redundancy that uses **a calculated value to reconstruct lost data**. In RAID:
> - It's typically a single bit or byte derived from a set of data bits or bytes
> - Calculated using the XOR (exclusive OR) operation on corresponding bits across data disks
> - Allows recovery of data from any single disk failure without storing complete copies
> 
> **Implementation**: 
> - Minimum of 3 disks; one for parity, others for data
> - Parity is calculated for each stripe (corresponding blocks across data disks)
> 
> ```mermaid
> graph TD
>     L["Logical Disk"] --> D1["Data Disk 1"]
>     L --> D2["Data Disk 2"]
>     L --> D3["Data Disk 3"]
>     P["Parity Disk"]
>     D1 -.-> |"XOR"| P
>     D2 -.-> |"XOR"| P
>     D3 -.-> |"XOR"| P
> ```
> 
> **Key Characteristics**:
> - Parity allows reconstruction of data if a single disk fails
> - Parity disk can become a bottleneck for write operations
> - Offers a balance between storage efficiency and fault tolerance


> [!example] RAID 4 in Action
> Consider a RAID 4 setup with four 1TB disks (3 data, 1 parity):
> 
> **Scenario**: Writing a 128KB file
> 
> 1. **Data Distribution**:
>    - 48KB written to Disk 1
>    - 48KB written to Disk 2
>    - 32KB written to Disk 3
> 
> 2. **Parity Calculation**:
>    Let's take a small sample of data (in binary) to illustrate:
>    - Disk 1: 1 0 1 1 0 1 0 1
>    - Disk 2: 0 1 1 0 1 0 1 1
>    - Disk 3: 1 1 0 1 0 1 1 0
>    - Parity:  0 0 0 0 1 0 0 0 (XOR of all bits in each column)
> 
>    Calculation: For each bit position,
>    Parity = 0 if # 1's is even, 1 if # 1's is odd
> 
>    **Explanation**:
>    - Column 1: Two 1s (even)   → Parity = 0
>    - Column 2: Two 1s (even)   → Parity = 0
>    - Column 3: Two 1s (even)   → Parity = 0
>    - Column 4: Two 1s (even)   → Parity = 0
>    - Column 5: One 1 (odd)     → Parity = 1
>    - Column 6: Two 1s (even)   → Parity = 0
>    - Column 7: Two 1s (even)   → Parity = 0
>    - Column 8: Two 1s (even)   → Parity = 0
> 
> 3. **Parity Update**:
>    - Calculated parity written to Parity Disk
> 
> **Read Scenario**: Reading the same 128KB file
> - Data read simultaneously from Disks 1, 2, and 3
> - Parity disk not involved in read operation
> 
> **Disk Failure Scenario**:
> 1. Data Disk 2 fails
> 2. System continues to operate using remaining disks
> 3. Read requests for Data Disk 2 are fulfilled by:
>    - Reading data from Disks 1 and 3
>    - Reading parity from Parity Disk
>    - Reconstructing Data Disk 2's data:
>      Disk2 = Disk1 XOR Disk3 XOR Parity
>      e.g., 0 1 1 0 1 0 1 1 = 1 0 1 1 0 1 0 1 XOR 1 1 0 1 0 1 1 0 XOR 0 0 0 0 1 0 0 0
> 
> This example demonstrates:
> 1. How parity is calculated using XOR (resulting in 1 for odd number of 1s, 0 for even)
> 2. RAID 4's ability to balance storage efficiency with fault tolerance
> 3. The process of data reconstruction in case of a disk failure
> 4. The potential write performance impact due to parity updates on every write operation


> [!idea] RAID 4 Analysis
> **Capacity**: 
> - Total usable capacity: $C = (n - 1) * c$
>   - $n$ = total number of disks
>   - $c$ = capacity of one disk
> 
> **Fault Tolerance**:
> - Disks that can fail without data loss: 1
> - Probability of data loss: $1 - (1-p)^n - np(1-p)^{n-1}$
>   - $p$ = probability of single disk failure
> 
> **Latency**:
> - Read: $L_r \approx L_{disk}$
> - Write: $L_w \approx 2 * L_{disk}$ (due to parity update)
> 
> **Throughput**:
> - Sequential read: $T_{sr} \approx (n-1) * t_{disk}$
> - Sequential write: $T_{sw} \approx \min(t_{parity}, (n-1) * t_{disk})$
> - Random read: $T_{rr} \approx (n-1) * t_{disk}$
> - Random write: $T_{rw} \approx t_{parity}$
>   - $t_{disk}$ = throughput of a single disk
>   - $t_{parity}$ = throughput of parity disk (often the bottleneck)





