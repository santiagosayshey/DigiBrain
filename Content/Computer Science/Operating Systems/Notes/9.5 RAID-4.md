> [!idea] RAID 4: Dedicated Parity
> RAID 4 uses **block-level striping with a dedicated parity disk**:
> 
> **Core Concept**: Distribute data across multiple disks with one disk dedicated to parity
> 
> **Parity Definition**: 
> Parity is a method of **data protection through mathematical relationships**, not a backup:
> - It's a calculated value that represents the relationship between data bits
> - Allows recovery of lost data by solving a mathematical equation
> - Does not store a copy of the data, but rather information about the data
> 
> **Parity Concept**:
> Think of parity as maintaining a balance. If you know the total weight of a group and the individual weights of all but one member, you can calculate the missing weight. Similarly, parity allows reconstruction of missing data from a failed disk.
> 
> **Implementation**: 
> - Minimum of 3 disks; one for parity, others for data
> - Parity is calculated for each stripe (corresponding blocks across data disks)
> - In practice, this calculation is achieved using the XOR (exclusive OR) operation
> 
> ```mermaid
> graph TD
>     L["Logical Disk"] --> D1["Data Disk 1"]
>     L --> D2["Data Disk 2"]
>     L --> D3["Data Disk 3"]
>     P["Parity Disk"]
>     D1 -.-> |"Mathematical Relationship"| P
>     D2 -.-> |"Mathematical Relationship"| P
>     D3 -.-> |"Mathematical Relationship"| P
> ```
> 
> **Key Characteristics**:
> - Parity allows reconstruction of data if a single disk fails
> - Not a backup: cannot recover data if more than one disk fails
> - Parity disk can become a bottleneck for write operations
> - Offers a balance between storage efficiency and fault tolerance

> [!example] Parity Concept: The Weight Analogy
> Imagine we have a RAID 4 system with three data disks and one parity disk, represented by weights on a balance scale:
> 
> **Setup**:
> - Data Disk 1: 5 kg
> - Data Disk 2: 3 kg
> - Data Disk 3: 7 kg
> - Parity Disk: Stores the "balancing weight"
> 
> **Parity Calculation**:
> 1. Total weight of data disks: 5 + 3 + 7 = 15 kg
> 2. Parity value: 15 kg (represents the total system weight)
> 
> **Normal Operation**:
> - System maintains knowledge of individual disk weights and total weight
> 
> **Disk Failure Scenario**:
> Let's say Data Disk 2 (3 kg) fails:
> 
> 1. Known information:
>    - Total weight (from Parity): 15 kg
>    - Data Disk 1: 5 kg
>    - Data Disk 3: 7 kg
> 
> 2. Reconstruction:
>    - Missing weight = Total weight - (Weight of Disk 1 + Weight of Disk 3)
>    - Missing weight = 15 kg - (5 kg + 7 kg) = 3 kg
> 
> 3. Result:
>    - System can determine that the failed Disk 2 had a "weight" of 3 kg
> 
> **Key Points**:
> - Parity (total weight) allows reconstruction of any single lost value
> - No direct copy of data is stored, only the mathematical relationship
> - System fails if more than one disk is lost, as the equation becomes unsolvable
> 
> This analogy demonstrates how RAID 4 can recover data from a single disk failure using parity information, without storing a complete backup of the data.

> [!idea] RAID 4 Analysis
> **Capacity**: 
> - Total usable capacity: $C = (n - 1) * c$
>   - $n$ = total number of disks
>   - $c$ = capacity of one disk
> 
> **Fault Tolerance**:
> - Disks that can fail without data loss: 1
> - Probability of data loss: $1 - (1-p)^n - np(1-p)^{n-1}$
>   - $p$ = probability of single disk failure
> 
> **Latency**:
> - Read: $L_r \approx L_{disk}$
> - Write: $L_w \approx 2 * L_{disk}$ (due to parity update)
> 
> **Throughput**:
> - Sequential read: $T_{sr} \approx (n-1) * t_{disk}$
> - Sequential write: $T_{sw} \approx \min(t_{parity}, (n-1) * t_{disk})$
> - Random read: $T_{rr} \approx (n-1) * t_{disk}$
> - Random write: $T_{rw} \approx t_{parity}$
>   - $t_{disk}$ = throughput of a single disk
>   - $t_{parity}$ = throughput of parity disk (often the bottleneck)

> [!example] RAID 4 in Action (With XOR)
> Consider a RAID 4 setup with four 1TB disks (3 data, 1 parity):
> 
> **Scenario**: Writing a 128KB file
> 
> 1. **Data Distribution**:
>    - 48KB written to Disk 1
>    - 48KB written to Disk 2
>    - 32KB written to Disk 3
> 
> 2. **Parity Calculation**:
>    Let's take a small sample of data (in binary) to illustrate:
>    - Disk 1: 1 0 1 1 0 1 0 1
>    - Disk 2: 0 1 1 0 1 0 1 1
>    - Disk 3: 1 1 0 1 0 1 1 0
>    - Parity:  0 0 0 0 1 0 0 0 (XOR of all bits in each column)
> 
>    Calculation: For each bit position,
>    Parity = 0 if # 1's is even, 1 if # 1's is odd
> 
>    **Explanation**:
>    - Column 1: Two 1s (even)   → Parity = 0
>    - Column 2: Two 1s (even)   → Parity = 0
>    - Column 3: Two 1s (even)   → Parity = 0
>    - Column 4: Two 1s (even)   → Parity = 0
>    - Column 5: One 1 (odd)     → Parity = 1
>    - Column 6: Two 1s (even)   → Parity = 0
>    - Column 7: Two 1s (even)   → Parity = 0
>    - Column 8: Two 1s (even)   → Parity = 0
> 
> 3. **Parity Update**:
>    - Calculated parity written to Parity Disk
> 
> **Read Scenario**: Reading the same 128KB file
> - Data read simultaneously from Disks 1, 2, and 3
> - Parity disk not involved in read operation
> 
> **Disk Failure Scenario**:
> 1. Data Disk 2 fails
> 2. System continues to operate using remaining disks
> 3. Read requests for Data Disk 2 are fulfilled by:
>    - Reading data from Disks 1 and 3
>    - Reading parity from Parity Disk
>    - Reconstructing Data Disk 2's data:
>      Disk2 = Disk1 XOR Disk3 XOR Parity
>      e.g., 0 1 1 0 1 0 1 1 = 1 0 1 1 0 1 0 1 XOR 1 1 0 1 0 1 1 0 XOR 0 0 0 0 1 0 0 0
> 
> This example demonstrates:
> 1. How parity is calculated using XOR (resulting in 1 for odd number of 1s, 0 for even)
> 2. RAID 4's ability to balance storage efficiency with fault tolerance
> 3. The process of data reconstruction in case of a disk failure
> 4. The potential write performance impact due to parity updates on every write operation