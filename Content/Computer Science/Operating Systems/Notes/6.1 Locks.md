> [!motivation] The Need for Concurrency
> So far, we have primarily considered machines that **execute single processes from start to finish.** However, this sequential execution model has limitations:
> 
> - **Underutilized Resources**: When a process is blocked or waiting for I/O operations, the CPU remains idle, leading to underutilized system resources.
> - **Limited Performance**: Sequential execution can limit the overall performance, especially when multiple tasks could be executed independently.
> - **Lack of Responsiveness**: Long-running processes can make the system unresponsive, affecting user experience and the execution of other processes.
> 
> To address these limitations, we want to introduce **concurrency, where multiple CPU threads or cores interleave their execution to form processes.** Concurrency allows for more efficient resource utilization, improved performance, and enhanced responsiveness.

> [!consider] Ensuring Correctness in Concurrent Programs
> Introducing concurrency raises concerns about ensuring the correctness of program execution, particularly when multiple threads access shared resources. Consider the following example:
> 
> ```
> balance = balance + 1
> ```
> 
> In a concurrent environment, **multiple threads might attempt to execute this statement simultaneously**. If not properly managed, this **can lead to race conditions** and incorrect results.
> 
> To ensure correctness, **instructions accessing shared memory need to be atomic**, meaning they must execute as an uninterruptible unit. Atomicity guarantees that the effects of an instruction are visible to other threads only after it has completed.
> 
> Achieving atomicity requires the concept of mutual exclusion. **If process A is executing a critical section (a block of code that accesses shared resources), then no other process, such as process C, should be allowed to enter that same critical section simultaneously.**

> [!exercise]+ Critical Section
> ```c
> // Critical Section
> balance = balance + depositAmount;
> totalDeposits = totalDeposits + 1;
> // End Critical Section
> ```
> 
> In this case, the code block updating the `balance` and `totalDeposits` variables should be treated as a critical section. Only one thread should execute this block at a time to avoid inconsistencies.
> 
> To enforce mutual exclusion and ensure correctness, programmers can use synchronization mechanisms such as **locks, semaphores, or mutexes**. These mechanisms coordinate access to shared resources and prevent multiple threads from concurrently executing critical sections.
> 
> Ensuring correctness in concurrent programs is crucial to maintain data integrity and avoid unexpected behavior. Programmers must carefully design and implement synchronization mechanisms to guarantee the atomicity of critical sections and prevent race conditions.

> [!idea] Locks: Ensuring Mutual Exclusion
> Locks ensure **only one thread** can access a shared resource at a time. They have two states:
>
> - **Available**: Lock is free to be acquired
> - **Acquired**: Lock is held by a thread
>
> Key concepts:
> - **Mutex**: Common lock type for **mutual exclusion**
> - **Acquisition**: Thread **acquires** available lock before entering critical section
> - **Blocking**: Other threads **wait** if lock is acquired
> - **Release**: Thread **releases** lock after exiting critical section, making it available
> - **Atomicity**: Lock operations use **atomic instructions** at low level
>
> ```c
> lock_t mutex;  // Declare a lock variable (initially available)
> 
> void update_balance() {
>     lock(&mutex);  // Acquire lock
>     balance = balance + 1;  // Critical section
>     unlock(&mutex);  // Release lock
> }
> ```

> [!consider] Locks: The "Speaking Ball" Analogy
> Locks can be compared to a classroom game where **only the person holding a ball can speak**.
> 
> - **Lock = Ball**: Only the thread with the lock (ball) can enter the critical section (speak)
> - **Critical Section = Speaking Time**: Exclusive access to shared resources
> - **Waiting Threads = Silent Students**: Other threads wait for the lock to be released
> 
> This analogy illustrates **mutual exclusion** in concurrent programming, showing how locks manage access to shared resources.


