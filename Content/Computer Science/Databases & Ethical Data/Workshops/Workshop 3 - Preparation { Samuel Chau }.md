## Question 1

```
Why is the volatility of data an issue?
```

Data storage - we might want to store the same field of data for multiple time periods, and with data that constantly changes, this becomes more of an issue, the more comprehensive we want to model this change in data.

Data consistency - On the opposite end, we might only want to grab data once and never update it again. If the source is volatile, this single data point might be completely innacurate to the actual data its representing

## Question 2

```
Sorted files have an advantage that "key order adjacent records will most likely be in the same block". Explain why this is the case and then what advantage this yields.
```


Data is written to drives sequentially. This means that one record is added after another in the order of the sorting key, and as a result, adjacent records get written to the same or nearby blocks. 

This allows for efficient and reduced disc I/O. By keeping adjacent records in similar or nearby blocks, for example all the records from key value 1-10, then we only need to read that 1 block to get all of those values. 


## Question 3 

```
A clustering index can use separate blocks for each cluster value, to improve performance for both the insertion and deletion of records. Explain, with diagrams if required, why this works and use a comparison with another index to indicate how it is more efficient.
```

Often, we want to assign unique blocks to clustering indexes. This allows for efficient insertion and deletion. When we want to add a new record, it's placed in its appropritate block without rearrangement. In the case that it is full, we only need to adjust surrounding blocks. With deletion, only its specific block needs adjustment. 

-------------------------       -------------------------
|  Genre: Mystery    |  ---->  | Book1 | Book2 | Book3 |
-------------------------       -------------------------
|  Genre: Fantasy    |  ---->  | Book4 | Book5 | Book6 |

Compared to a primary index, where every record is unique. This leads to innefficient insertions / deletions where the entire index needs to be sorted after every operation. 

-------------------------       -------------------------
|  BookID: 1         |  ---->  | Book1 |
-------------------------       -------------------------
|  BookID: 2         |  ---->  | Book2 |


## Question 4 

```
You are told that the string CLAIMED was generated by employing a post-order traversal on a binary tree. Draw the tree that generated this text.
```

![[docs/Images/Pasted image 20230821163627.png]]

## Question 5

```
You are building a new application that scans published cookbooks to provide a list of all of the ingredients used in each recipe. The app then allows users to search for recipe and cookbook names that use certain ingredients. Explain, in detail, if you would build an index (or multiple indexes) for this application and what kinds of index you would employ. You should describe the behaviour of the data over time and likely impact on the index as part of your solution.
```
### 2. Primary Index:
Every recipe and cookbook should have a unique identifier (e.g., `recipeID` and `cookbookID`). This unique identifier can be used to create a primary index for fast direct access. This will especially be useful when updating or deleting specific recipes.

### 3. Secondary Indexes:

#### a) Ingredient-based Index:
The most crucial index for this application will be ingredient-based since users will search recipes based on ingredients.

For instance:
```
Salt -> [recipeID1, recipeID4, recipeID15, ...]
Eggs -> [recipeID3, recipeID7, recipeID12, ...]
```

When a user searches for "Salt," the system can quickly fetch all the recipes associated with it using this index.

#### b) Cookbook Name Index:
Users might want to search for a specific cookbook. Having an index based on the cookbook name will facilitate this.

### 4. Impact on Index Over Time:

#### a) Insertions:
For every new recipe, the system would need to update the ingredient-based index by adding the new recipe's ID to the list of each ingredient it contains. For entirely new ingredients, a new entry would be created.

#### b) Deletions:
When a recipe is deleted, the system needs to remove its ID from every ingredient list it's associated with in the ingredient-based index. If an ingredient no longer has any recipes associated with it (rare but possible), that ingredient can be removed from the index.

#### c) Updates:
If an ingredient is added/removed from a recipe, the ingredient-based index needs to be updated accordingly, either by adding or removing the recipe ID from the associated ingredient lists.

### 6. Index Storage and Retrieval:
Given that the ingredient-based index could grow quite large, using efficient storage and retrieval structures like B-trees or hash indexes is essential. B-trees, in particular, are suitable for range queries and can remain balanced, ensuring search, insert, and delete operations run in logarithmic time.

### 7. Caching:
Commonly searched ingredients and their associated recipes can be cached to further speed up retrieval times.

### Conclusion:
For the described application, a combination of primary and secondary indexes will be beneficial. Regular maintenance and the use of efficient data structures can ensure that the system remains responsive and accurate over time.

## Question 6

```
We want to write software to find two 8 character strings that have the same CRC32 hash value. (CRC32 is a hash function that generates a much smaller range of values than MD5 - why am I using this?) 

You may assume that:

- the string is all lower case and only contains the characters from a-z
- both strings are exactly 8 characters long
- you can use the **binascii** python library, and pass strings to it in binary form to calculate the checksum using, for example:
- import binascii  
    binascii.crc32(b"hello-wo")
    

Your program can start from a pre-programmed string and look for matches or do it however you want. You should count how many iterations it took to find the result. Output should look like this. Feel free to display the matching strings if you want to! The ones I've put here are not real output from my program.

Looking for matches  
Running...  
Found two strings that match in 179,654 iterations.  
unearned and leiuwnsh 

Have you found all of the matches?
```

```python
import binascii
import random
import string

def generate_random_string(length=8):
    return ''.join(random.choice(string.ascii_lowercase) for _ in range(length))

def find_collision():
    hash_table = {}
    iterations = 0

    while True:
        current_string = generate_random_string()
        iterations += 1
        
        hash_value = binascii.crc32(current_string.encode('utf-8'))

        # If hash value is found in hash table, we found a collision.
        if hash_value in hash_table:
            return (iterations, hash_table[hash_value], current_string)

        # Otherwise, store the current string and its hash value in the hash table.
        hash_table[hash_value] = current_string

print("Looking for matches")
print("Running...")
iterations, first_match, second_match = find_collision()
print(f"Found two strings that match in {iterations} iterations.")
print(first_match, "and", second_match)
```

```shell
PS Z:\echo360-1> python hash.py
Looking for matches
Running...
Found two strings that match in 137920 iterations.
ztzqmfad and qmeaigzp

PS Z:\echo360-1> python hash.py
Looking for matches
Running...
Found two strings that match in 89798 iterations.
mgonnlfz and hxfhmfcb

PS Z:\echo360-1> python hash.py
Looking for matches
Running...
Found two strings that match in 62941 iterations.
lbqpbrdp and bkuwynbe

PS Z:\echo360-1> python hash.py
Looking for matches
Running...
Found two strings that match in 51422 iterations.
ieycnrhi and vgsaohwv

PS Z:\echo360-1> python hash.py
Looking for matches
Running...
Found two strings that match in 102700 iterations.
pfhiqmed and zdbbyhae
```
